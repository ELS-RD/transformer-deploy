{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A recipe to perform Nvidia GPU int-8 quantization on most transformers model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantization is one of the most effective and generic approach to make model inference faster.\n",
    "Basically it replaces float numbers generally encoded in 16 or 32 bits by integers encoded in 8 bits or less:\n",
    "\n",
    "* it takes less memory\n",
    "* computation is easier / faster\n",
    "\n",
    "**GPU quantization is a way to double the inference speed of your GPU**.\n",
    "It can be applied to any model in theory, and unlike distillation, if done well, it should not decrease your model accuracy.\n",
    "\n",
    "The purpose of this tutorial is to show 2 processes to perform quantization on most `transformer` architecture.\n",
    "\n",
    "## What is int-8 quantization?\n",
    "\n",
    "Basic idea behind the expression int-8 quantization is that instead of doing deep learning computations with `float` numbers (usually encoded on 32 bits), you use integers (encoded on 8 bits). On a large matrix multiplication it has 2 effects:\n",
    "\n",
    "* it reduces by a large margin the size in memory, making **memory transfer faster** (on GPU, many operations are very fast to compute, and memory transfer is the main bottleneck, they are called memory bound)\n",
    "* it also makes **computation faster** accelerating the slowest operations (in transformer, mainly big matrix multiplication during the self attention comptutation)\n",
    "\n",
    "A 8-bit integer can encode values from -128 to +127, and no decimal (as it's an integer).\n",
    "So a 8-bit integer can't encode values like `1280.872654`.\n",
    "\n",
    "However we can use our integer if it's associated to a scale (a FP32 scale). For instance, for a scale of 20, I can set my integer to 64 (64*20=1280), it's not exactly `1280.872654` but it's close enough.\n",
    "\n",
    "That's why we need to perform a step called `calibration` during which the range of values and the scale (encoded as a FP32 float) will be computed.\n",
    "\n",
    "Basically, we know that by converting a FP32 to an int-8 and its scale, we will lose some information, and the goal of the calibration is to minimize this loss.\n",
    "\n",
    "If in a matrix, values go from -1.5 to +2, it may be encoded as an integer taking value from -127 to +127, associated to a scale of 64 (2*64=128)\n",
    "\n",
    "\n",
    "[A good documentation on quantization](https://on-demand.gputechconf.com/gtc/2017/presentation/s7310-8-bit-inference-with-tensorrt.pdf)\n",
    "\n",
    "\n",
    "## Why a dedicated tutorial?\n",
    "\n",
    "CPU quantization is supported out of the box by `Pytorch` or ONNX Runtime.\n",
    "GPU quantization on the other side requires specific tools and process to be applied.\n",
    "\n",
    "In the specific case of `transformer` models, right now (december 2021), the only way shown by Nvidia is to build manually the graph of your model in `TensorRT`. This is a low level approach, based on GPU capacity knowledge (which operator are supported, etc.). It's certainly out of reach of most NLP practitioners.\n",
    "\n",
    "Hopefully, Nvidia recently added to Hugging Face `transformer` library a new model called `QDQBert`.\n",
    "Basically, it's a vanilla `Bert` architecture which supports int-8 quantization.\n",
    "It doesn't support any other architecture out of the box, like `Albert`, `Roberta`, or `Electra`.\n",
    "The Nvidia demo is dedicated to SQuaD task.\n",
    "\n",
    "The code from Nvidia only supports out of the box vanilla `Bert` model (and not similar models, like RoBerta & co).\n",
    "The demo from Nvidia is on the SQuaD task, it's cool but it makes the code a lot less clear that needed.\n",
    "\n",
    "To be both simple and cover most use cases, in this tutorial we will see:\n",
    "\n",
    "* how to perform GPU quantization on **any** transformer model (not just Bert) using a simple trick\n",
    "* how to to apply quantization to a common task like classification (which is easier to understand than question answering)\n",
    "* measure performance gain (latency)\n",
    "\n",
    "## ToC\n",
    "\n",
    "### [Dependencies](#Dependencies-installation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project setup\n",
    "\n",
    "### Dependencies installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We install `master` branch of `transfomers` library to use a new model: **QDQBert** and `transformer-deploy` to leverage `TensorRT` models (TensorRT API is not something simple to master, it's highly advised to use a wrapper)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "MOsHUjgdIrIW"
   },
   "outputs": [],
   "source": [
    "#! pip install git+https://github.com/huggingface/transformers\n",
    "#! pip install git+https://github.com/ELS-RD/transformer-deploy\n",
    "#! pip install sklearn datasets -U\n",
    "#! pip install pytorch-quantization --extra-index-url https://pypi.ngc.nvidia.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the GPU is enabled and usable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2OzrD4f-3ydk",
    "outputId": "54cc2ea6-6969-4e01-f9f9-78c5fc91ff85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Dec  6 17:39:28 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 495.29.05    Driver Version: 495.29.05    CUDA Version: 11.5     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:03:00.0  On |                  N/A |\r\n",
      "| 70%   55C    P8    47W / 350W |    304MiB / 24267MiB |     15%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A      1636      G   /usr/lib/xorg/Xorg                162MiB |\r\n",
      "|    0   N/A  N/A      7876      G   /usr/bin/gnome-shell               45MiB |\r\n",
      "|    0   N/A  N/A     21136      G   ...AAAAAAAAA= --shared-files       20MiB |\r\n",
      "|    0   N/A  N/A    129021      G   ...AAAAAAAAA= --shared-files       38MiB |\r\n",
      "|    0   N/A  N/A   2438985      G   ...359197.log --shared-files       33MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "ac14ba24dcf3404db9fd303dbb24d7a5",
      "4e91efae49b64f038fd3fbfcfd2be510",
      "17b83e0d0fb947d7bf20319ff930e8fc",
      "1da1d80871f545bbb21bf5a84d2120a0",
      "c593f2e45e244637821cc5721788bf2c",
      "cbbb20b5d01a4450bfb8dfbf8048d64f",
      "854cfd13416543fba8221093b903658b",
      "7ec6da801d0d45c4bb80eeab5518e124",
      "8585eab4b3fe4992bd7e7c4596e2483b",
      "990482eebca2424bb5ecbd114007e02c",
      "c92a19dfa84142af91522bc22f21fca6",
      "78601982b0e04b80adaa502db2ef685a",
      "167874df55014291be95cd390b1e60d3",
      "d6426fea2eda41dd9a31cb3f35b0877e",
      "163146c2f23440bcbf782116a35b5684",
      "0dab554959dc44b3b313ee8ae91ca88d",
      "f651eecbb6d44c24820cf6fe5ab92e7b",
      "a51b461c062f4636bfa4b48823d0709b",
      "cced5f1cccc2400a8fbfd7a6eaedc666",
      "cf9597523c024514b9b3e66bc77e3fa8",
      "f01fdef82047471e8c1b780cae5379cc",
      "e1f08cf954ae4aea818c90d893486c77"
     ]
    },
    "id": "KPMoLPBn_1vN",
    "outputId": "58dca4e7-fc5c-4fd1-a8d4-755aa1e956cb"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from typing import Dict, OrderedDict, List\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    PreTrainedModel,\n",
    "    QDQBertForSequenceClassification,\n",
    "    BertForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    IntervalStrategy,\n",
    ")\n",
    "from transformer_deploy.QDQModels.QDQRoberta import QDQRobertaForSequenceClassification\n",
    "import pytorch_quantization.nn as quant_nn\n",
    "from pytorch_quantization.tensor_quant import QuantDescriptor\n",
    "from pytorch_quantization import calib\n",
    "import logging\n",
    "import transformers\n",
    "import datasets\n",
    "from transformer_deploy.backends.trt_utils import build_engine, get_binding_idxs, infer_tensorrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pycuda._driver import Stream\n",
    "import tensorrt as trt\n",
    "from tensorrt.tensorrt import IExecutionContext, Logger, Runtime\n",
    "import pycuda.autoinit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set logging to `error` to make the `notebook` more readable on Github."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_level = logging.ERROR\n",
    "logging.getLogger().setLevel(log_level)\n",
    "datasets.utils.logging.set_verbosity(log_level)\n",
    "transformers.utils.logging.set_verbosity(log_level)\n",
    "transformers.utils.logging.enable_default_handler()\n",
    "transformers.utils.logging.enable_explicit_format()\n",
    "trt_logger: Logger = trt.Logger(trt.Logger.ERROR)\n",
    "transformers.logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rEJBSTyZIrIb"
   },
   "source": [
    "### Download data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part is inspired from an [official Notebooks from Hugging Face](https://github.com/huggingface/notebooks/blob/master/examples/text_classification.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "zVvslsfMIrIh"
   },
   "outputs": [],
   "source": [
    "task = \"mnli\"\n",
    "num_labels = 3\n",
    "model_checkpoint = \"roberta-base\"\n",
    "batch_size = 32\n",
    "max_seq_len = 256\n",
    "validation_key = \"validation_matched\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W7QYTpxXIrIl"
   },
   "source": [
    "We will use the [ðŸ¤— Datasets](https://github.com/huggingface/datasets) library to download the data and get the metric we need to use for evaluation (to compare our model to the benchmark). This can be easily done with the functions `load_dataset` and `load_metric`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "IreSlFmlIrIm"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18466bdd0e5b4e819e3bdadfa574eaa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
       "        num_rows: 392702\n",
       "    })\n",
       "    validation_matched: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
       "        num_rows: 9815\n",
       "    })\n",
       "    validation_mismatched: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
       "        num_rows: 9832\n",
       "    })\n",
       "    test_matched: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
       "        num_rows: 9796\n",
       "    })\n",
       "    test_mismatched: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
       "        num_rows: 9847\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset, load_metric\n",
    "\n",
    "dataset = load_dataset(\"glue\", task)\n",
    "metric = load_metric('glue', task)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n9qywopnIrJH"
   },
   "source": [
    "### Preprocessing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YVx71GdAIrJH"
   },
   "source": [
    "Before we can feed those texts to our model, we need to preprocess them. This is done by a ðŸ¤— Transformers `Tokenizer` which will (as the name indicates) tokenize the inputs (including converting the tokens to their corresponding IDs in the pretrained vocabulary) and put it in a format the model expects, as well as generate the other inputs that model requires.\n",
    "\n",
    "To do all of this, we instantiate our tokenizer with the `AutoTokenizer.from_pretrained` method, which will ensure:\n",
    "\n",
    "- we get a tokenizer that corresponds to the model architecture we want to use,\n",
    "- we download the vocabulary used when pretraining this specific checkpoint.\n",
    "\n",
    "That vocabulary will be cached, so it's not downloaded again the next time we run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "referenced_widgets": [
      "b6be028de2ae4ff691538eedb33793af",
      "a3e2c73d393d4e58a371f3da3dd80e6d",
      "b4d3f284fc4c4061b58d43a738f9bc78",
      "8a11c8fed672470b8335dc575a4a220e",
      "08286a6371584b4186014ecb5d5f164d",
      "68c4c867096d41a78740fdee30edcadb",
      "7d520bdde27742abb42803843721d101",
      "f8a0053903c64e75ac25eab5b24d5871",
      "93dbcc6d23a743bab0da8af6ee5e2825",
      "d1ecc3d380fc4758b03190b23686a2f1",
      "2d3a08166846438db79b0f89314fe76a",
      "5e2185bd6e4f4a10b89ac606868a43bd",
      "f44d2beebfe44186b0ac8016e89e4b49",
      "2eac6b4817e14d7fae396e6458b940fa",
      "af16284f77594397a69ad0e322b5e736",
      "a20579a9e7364fb485d79bdc4feb54dc",
      "cae29b9c6d45412fab70977fcd0f3234",
      "927ad6ade85a402594074fa90ab558c2",
      "30646fa2c0dc494e9dbcbd4dc598410e",
      "7a75099f99054645bf3fc1b778dac7e6",
      "d5d015711ae04d2f801577fc50af6c15",
      "4b13c3b3435f4689b29d48e0a35bebd6",
      "be4affe852b348de8fe1362582b08da9",
      "c6c100b71f26405fb960598feb5eee03",
      "99e94791043b4499b06601f7524f9b14",
      "26bc2038bed74279813ab5af09a2724c",
      "9bc6e14b912249e3b7d02f31bcc74667",
      "196ffc99ad5a40109d9b1cfe12032b62",
      "d5c8ff9e3bd849059fa7b30eab5fc940",
      "7ff32d18c9f0473893a6a6b2941c54b0",
      "0022faf286b44e858e638ccd5ded38b0",
      "6e54ce781ca54ad283911fa4774e3361",
      "969b6fdac1d6418d89a683db1e6ec6b2",
      "092db03992f24951b494fbb81da5b9d6",
      "023900ca566446eab5905b25b16a3de7",
      "994cf2338c7c4899952e25723445693c",
      "6aa2f5d46f1f454198d8e69517549ff1",
      "72b8f11065254e5ca488cd346b5add54",
      "c7bd52ef524c4d279dfcaa3aebe4a2c5",
      "d9a0852554284d36b6b121f579b06b41",
      "4320b12de9d14c459cc88319e2d7622a",
      "7b483d17d1d14fdd922600f0c906fc2f",
      "14648b8262944f5faac134a7c0184e47",
      "10678736bd534c63aebda414da01b4db"
     ]
    },
    "id": "eXNLu_-nIrJI",
    "outputId": "10b2f739-6277-44c2-fd31-0de3a9ab9fa8"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2C0hcmp9IrJQ"
   },
   "source": [
    "We can them write the function that will preprocess our samples. We just feed them to the `tokenizer` with the argument `truncation=True`. This will ensure that an input longer that what the model selected can handle will be truncated to the maximum length accepted by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "vc0BSBLIIrJQ"
   },
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"premise\"], examples[\"hypothesis\"], truncation=True, padding=\"max_length\", max_length=max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "referenced_widgets": [
      "65017db07d7f4e798ede741cc92488f0",
      "6fa74604c68543a38392fa0e1587f707",
      "86cc326e574a4fada7224e6f0c209e9a",
      "af5b646f89024c139c695a1f058fb772",
      "37cda4cae81a4d94aa831fb40b5c3b26",
      "28b7346a9b8c4b198dd9dbea1be013b6",
      "561b1ede331a40c1a2bff9422e8eea0e",
      "aecf7f063234416abf3f24766481cb89",
      "21ef195fa88f49c4a2c057f8028177a2",
      "5b1ad9f5d02c4b298a02ce6041692057",
      "56fd7584b0844590936519ec3851922e",
      "bbe3a471efb04ea8b5aabc4be819d585",
      "59418bbeb20547e5b5e1a5728262c757",
      "a61d366d91c34697a55f62b754e1f3a5",
      "1bea379404df429b9852b62a938661ae",
      "c801e1727de44b67aa7cb1c3d970e1fe",
      "b8722dc10d4447fe9630cbf169260cc8",
      "a9b98fd93fcd4fc4a2b2aa88c82835d0",
      "300f01e3547648f3983a83d3d3118c54",
      "a4c444f06c0847c09a44917084d3908d",
      "7c875ecd9cb54405a6c45969bcb4b4c6",
      "4552ee8ca6bd4a0b956651cc23f4ff3c",
      "3bfff454943b4b04a12ec29bbe28e0aa",
      "154200a8bc0b44fe8d0419fd56c6539d",
      "cedca6e55b84443e82f3d01471d61048",
      "a7d355f456eb4d3995dd91c5917a72c1",
      "b264b220d9c444bd9da46a7e6c8fd5ed",
      "4fae966b76844c869cdea1e53891e26f",
      "a0a2918e9772475cac51124b3b83fcaf",
      "a02624219ee84f50b1a3032eaa030a39",
      "5f032f56105f463a8680aa2482d0b162",
      "7701ec898fd443f1b35b187aea3651e9",
      "8399339998564d21ba5db6f0514c02c6"
     ]
    },
    "id": "DDtsaJeVIrJT",
    "outputId": "0eeb1cb2-e308-493b-807e-532eeae5f4fe",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encoded_dataset = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "545PP3o8IrJV"
   },
   "source": [
    "## Fine-tuning model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FBiW8UpKIrJW"
   },
   "source": [
    "Now that our data are ready, we can download the pretrained model and fine-tune it.\n",
    "\n",
    "We will also prepare some export function right now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def convert_to_onnx(model_pytorch: PreTrainedModel, output_path: str, inputs_pytorch: Dict[str, torch.Tensor]) -> None:\n",
    "    with torch.no_grad():\n",
    "        torch.onnx.export(\n",
    "            model_pytorch,  # model to optimize\n",
    "            args=(inputs_pytorch[\"input_ids\"], inputs_pytorch[\"attention_mask\"]),  # tuple of multiple inputs , inputs_pytorch[\"token_type_ids\"]\n",
    "            f=output_path,  # output path / file object\n",
    "            opset_version=13,  # the ONNX version to use, 13 is the first to support QDQ nodes\n",
    "            do_constant_folding=True,  # simplify model (replace constant expressions)\n",
    "            input_names=[\"input_ids\", \"attention_mask\"],  # input names \"token_type_ids\"\n",
    "            output_names=[\"model_output\"],  # output name\n",
    "            dynamic_axes={  # declare dynamix axis for each input / output (dynamic axis == variable length axis)\n",
    "                \"input_ids\": {0: \"batch_size\", 1: \"sequence\"},\n",
    "                \"attention_mask\": {0: \"batch_size\", 1: \"sequence\"},\n",
    "                #\"token_type_ids\": {0: \"batch_size\", 1: \"sequence\"},\n",
    "                \"model_output\": {0: \"batch_size\"},\n",
    "            },\n",
    "            verbose=False,\n",
    "        )\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    if task != \"stsb\":\n",
    "        predictions = np.argmax(predictions, axis=1)\n",
    "    else:\n",
    "        predictions = predictions[:, 0]\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "\n",
    "def calibrate(model: PreTrainedModel, encoded_dataset, nb_sample: int=128) -> None:\n",
    "    # Find the TensorQuantizer and enable calibration\n",
    "    for name, module in tqdm(model.named_modules()):\n",
    "        if isinstance(module, quant_nn.TensorQuantizer):\n",
    "            if module._calibrator is not None:\n",
    "                module.disable_quant()\n",
    "                module.enable_calib()\n",
    "            else:\n",
    "                module.disable()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for start_index in tqdm(range(0, nb_sample, batch_size)):\n",
    "            end_index = start_index + batch_size\n",
    "            data = encoded_dataset[\"train\"][start_index:end_index]\n",
    "            input_torch = {k: torch.tensor(list(v), dtype=torch.long, device=\"cpu\")\n",
    "                           for k, v in data.items() if k in [\"input_ids\", \"attention_mask\", \"token_type_ids\"]}\n",
    "            model(**input_torch)\n",
    "\n",
    "\n",
    "    # Finalize calibration\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, quant_nn.TensorQuantizer):\n",
    "            if module._calibrator is not None:\n",
    "                if isinstance(module._calibrator, calib.MaxCalibrator):\n",
    "                    module.load_calib_amax()\n",
    "                else:\n",
    "                    module.load_calib_amax(\"percentile\", percentile=99.99)\n",
    "                module.enable_quant()\n",
    "                module.disable_calib()\n",
    "            else:\n",
    "                module.enable()\n",
    "\n",
    "    model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime: Runtime = trt.Runtime(trt_logger)\n",
    "profile_index = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Default parameters to be used for the training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_step = 1000\n",
    "strategy = IntervalStrategy.STEPS\n",
    "args = TrainingArguments(\n",
    "    f\"{model_checkpoint}-finetuned-{task}\",\n",
    "    evaluation_strategy = strategy,\n",
    "    eval_steps=nb_step,\n",
    "    logging_steps=nb_step,\n",
    "    save_steps=nb_step,\n",
    "    save_strategy = strategy,\n",
    "    learning_rate=1e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size*2,\n",
    "    num_train_epochs=1,\n",
    "    fp16=True,\n",
    "    group_by_length=True,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=[],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1: `Transplantation` of weights from a source model to an optimized architecture\n",
    "\n",
    "Transplantation idea is to export weights from one model and use them in another one.\n",
    "In our case, the source are `Roberta` weights and the target is `Bert` archtecture which is highly optimized on `TensorRT` for GPU quantization.\n",
    "\n",
    "Indeed, not all models are quantization compliant. The optimization engine (`TensorRT`) search for some patterns and will fail to opimize the model if it doesn't find them. It requires the Pytorch code to be written in a certain way and use certain operations. For that reason, it's a good idea to reuse an architecture highly optimized.\n",
    "\n",
    "We will leverage the fact that since `Bert` have been released, very few improvements have been brought to the transformer architecture (at least for encoder only models).\n",
    "Better models appeared, and most of the work has been done to improve the pretraining step (aka the weights).\n",
    "So the idea will be to take the weights from those new models and put them inside `Bert` architecture.\n",
    "\n",
    "The process described below should work for most users.\n",
    "\n",
    "**steps**:\n",
    "\n",
    "* load `Bert` model\n",
    "* retrieve layer/weight names\n",
    "* load target model (here `Roberta`)\n",
    "* replace weight/layer names with those from `Roberta`\n",
    "* override the architecture name in model configuration\n",
    "\n",
    "If there is no 1 to 1 correspondance (it happens), try to keep at least embeddings and self attention. Of course, it's possible that if a model is very different, the transplant may cost some accuracy. In our experience, if your trainset is big enough it should not happen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_bert: PreTrainedModel = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=num_labels)\n",
    "bert_keys = list(model_bert.state_dict().keys())\n",
    "del model_bert\n",
    "\n",
    "model_roberta: PreTrainedModel = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels)\n",
    "model_roberta.save_pretrained(\"roberta-in-bert\")\n",
    "del model_roberta\n",
    "model_weights: OrderedDict[str, Tensor] = torch.load(\"roberta-in-bert/pytorch_model.bin\")\n",
    "\n",
    "# Roberta -> Bert, there is 1 to 1 correspondance, for other models, you may need to create your own mapping.\n",
    "for bert_key in bert_keys:\n",
    "    # pop remove the first weights from the Ordered dict ...\n",
    "    _, weight = model_weights.popitem(last=False)\n",
    "    # ... and we re-insert them, in order, with a new key\n",
    "    model_weights[bert_key] = weight\n",
    "\n",
    "# we re-export the weights\n",
    "torch.save(model_weights, \"roberta-in-bert/pytorch_model.bin\")\n",
    "del model_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We override the architecture name to make `transformers` believe it is `Bert`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====> change architecture to bert base <======\n",
    "import json\n",
    "\n",
    "with open(\"roberta-in-bert/config.json\") as f:\n",
    "    content = json.load(f)\n",
    "    content['architectures'] = [\"bert\"]\n",
    "\n",
    "with open(\"roberta-in-bert/config.json\", mode=\"w\") as f:\n",
    "    json.dump(content, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training\n",
    "\n",
    "\n",
    "When you create a classification model from a pretrained one, the last layer are randomly initialized.\n",
    "We don't want to take these totally random values to compute the calibration of tensors.\n",
    "Moreover, our trainset is a bit small, and it's easy to overfit.\n",
    "\n",
    "Therefore, we train our `Roberta into Bert` model on 1/6 of the train set.\n",
    "The goal is to slightly update the weights to the new architecture, not to get the best score.\n",
    "\n",
    "> another approach is to fully train your model, perform calibration, and then retrain it on a small part of the data with a low learning rate (usually 1/10 of the original one).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:437] 2021-12-06 17:39:49,638 >> Using amp half precision backend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7303, 'learning_rate': 9.1875814863103e-06, 'epoch': 0.08}\n",
      "{'eval_loss': 0.5143516659736633, 'eval_accuracy': 0.8018339276617422, 'eval_runtime': 18.9153, 'eval_samples_per_second': 518.892, 'eval_steps_per_second': 8.142, 'epoch': 0.08}\n",
      "{'loss': 0.5419, 'learning_rate': 8.373533246414604e-06, 'epoch': 0.16}\n",
      "{'eval_loss': 0.4696938693523407, 'eval_accuracy': 0.8183392766174223, 'eval_runtime': 19.0652, 'eval_samples_per_second': 514.813, 'eval_steps_per_second': 8.078, 'epoch': 0.16}\n",
      "{'loss': 0.5056, 'learning_rate': 7.558670143415907e-06, 'epoch': 0.24}\n",
      "{'eval_loss': 0.4684630036354065, 'eval_accuracy': 0.819969434538971, 'eval_runtime': 18.5425, 'eval_samples_per_second': 529.326, 'eval_steps_per_second': 8.305, 'epoch': 0.24}\n",
      "{'loss': 0.4806, 'learning_rate': 6.744621903520209e-06, 'epoch': 0.33}\n",
      "{'eval_loss': 0.42402705550193787, 'eval_accuracy': 0.8364747834946511, 'eval_runtime': 18.5925, 'eval_samples_per_second': 527.901, 'eval_steps_per_second': 8.283, 'epoch': 0.33}\n",
      "{'loss': 0.4637, 'learning_rate': 5.929758800521513e-06, 'epoch': 0.41}\n",
      "{'eval_loss': 0.41743752360343933, 'eval_accuracy': 0.8404482934284259, 'eval_runtime': 18.5681, 'eval_samples_per_second': 528.596, 'eval_steps_per_second': 8.294, 'epoch': 0.41}\n",
      "{'loss': 0.4501, 'learning_rate': 5.1148956975228174e-06, 'epoch': 0.49}\n",
      "{'eval_loss': 0.4184797704219818, 'eval_accuracy': 0.8368823229750382, 'eval_runtime': 18.5308, 'eval_samples_per_second': 529.658, 'eval_steps_per_second': 8.31, 'epoch': 0.49}\n",
      "{'loss': 0.4488, 'learning_rate': 4.3008474576271195e-06, 'epoch': 0.57}\n",
      "{'eval_loss': 0.397051602602005, 'eval_accuracy': 0.8456444218033622, 'eval_runtime': 18.5969, 'eval_samples_per_second': 527.776, 'eval_steps_per_second': 8.281, 'epoch': 0.57}\n",
      "{'loss': 0.4404, 'learning_rate': 3.4859843546284226e-06, 'epoch': 0.65}\n",
      "{'eval_loss': 0.39308467507362366, 'eval_accuracy': 0.8465613856342333, 'eval_runtime': 18.582, 'eval_samples_per_second': 528.201, 'eval_steps_per_second': 8.288, 'epoch': 0.65}\n",
      "{'loss': 0.4311, 'learning_rate': 2.6711212516297265e-06, 'epoch': 0.73}\n",
      "{'eval_loss': 0.39400529861450195, 'eval_accuracy': 0.8489047376464595, 'eval_runtime': 18.5238, 'eval_samples_per_second': 529.86, 'eval_steps_per_second': 8.314, 'epoch': 0.73}\n",
      "{'loss': 0.4226, 'learning_rate': 1.8562581486310302e-06, 'epoch': 0.81}\n",
      "{'eval_loss': 0.38930612802505493, 'eval_accuracy': 0.8527763627101376, 'eval_runtime': 18.5207, 'eval_samples_per_second': 529.948, 'eval_steps_per_second': 8.315, 'epoch': 0.81}\n",
      "{'loss': 0.4239, 'learning_rate': 1.0413950456323338e-06, 'epoch': 0.9}\n",
      "{'eval_loss': 0.38341203331947327, 'eval_accuracy': 0.85206316861946, 'eval_runtime': 18.552, 'eval_samples_per_second': 529.052, 'eval_steps_per_second': 8.301, 'epoch': 0.9}\n",
      "{'loss': 0.4242, 'learning_rate': 2.2816166883963498e-07, 'epoch': 0.98}\n",
      "{'eval_loss': 0.3831214904785156, 'eval_accuracy': 0.8536933265410087, 'eval_runtime': 18.5149, 'eval_samples_per_second': 530.113, 'eval_steps_per_second': 8.318, 'epoch': 0.98}\n",
      "{'train_runtime': 2654.3429, 'train_samples_per_second': 147.947, 'train_steps_per_second': 4.623, 'train_loss': 0.4790087224918052, 'epoch': 1.0}\n",
      "{'eval_loss': 0.3831214904785156, 'eval_accuracy': 0.8536933265410087, 'eval_runtime': 18.5645, 'eval_samples_per_second': 528.697, 'eval_steps_per_second': 8.295, 'epoch': 1.0}\n",
      "{'eval_loss': 0.3831214904785156, 'eval_accuracy': 0.8536933265410087, 'eval_runtime': 18.5645, 'eval_samples_per_second': 528.697, 'eval_steps_per_second': 8.295, 'epoch': 1.0}\n"
     ]
    }
   ],
   "source": [
    "transformers.logging.set_verbosity_error()\n",
    "model_bert = BertForSequenceClassification.from_pretrained(\"roberta-in-bert\", num_labels=num_labels)\n",
    "model_bert = model_bert.cuda()\n",
    "\n",
    "trainer = Trainer(\n",
    "    model_bert,\n",
    "    args,\n",
    "    train_dataset=encoded_dataset[\"train\"],\n",
    "    eval_dataset=encoded_dataset[validation_key],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "transformers.logging.set_verbosity_error()\n",
    "trainer.train()\n",
    "print(trainer.evaluate())\n",
    "model_bert.save_pretrained(\"roberta-in-bert-trained\")\n",
    "del trainer\n",
    "del model_bert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we will start the quantization process.\n",
    "It follow those steps:\n",
    "\n",
    "* perform the calibration\n",
    "* perform a quantization aware training\n",
    "\n",
    "By passing validation values to the model, we will calibrate it, meaning it will get the right range / scale to convert FP32 weights to int-8 ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activate histogram calibration\n",
    "\n",
    "There are several kinds of calbrators, below we use the percentile one (99.99p) (`histogram`), basically, its purpose is to just remove the most extreme values before computing range / scale.\n",
    "The other option is `max`, it's much faster but expect lower accuracy.\n",
    "\n",
    "Second calibration option, choose between calibration done at the tensor level or per channel (more fine grained, slower)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can also use \"max\" instead of \"historgram\"\n",
    "input_desc = QuantDescriptor(num_bits=8, calib_method=\"histogram\")\n",
    "# below we do per-channel quantization for weights, set axis to None to get a per tensor calibration\n",
    "weight_desc = QuantDescriptor(num_bits=8, axis=(0,))\n",
    "quant_nn.QuantLinear.set_default_quant_desc_input(input_desc)\n",
    "quant_nn.QuantLinear.set_default_quant_desc_weight(weight_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform calibration\n",
    "\n",
    "During this step we will enable the calibration nodes, and pass some representative data to the model.\n",
    "It will then be used to compute the scale/range.\n",
    "\n",
    "Official recommendations from Nvidia is to calibrate over thousands of examples from the validation set.\n",
    "Here we use 40*32 examples, because it's a slow process. It's enough to be close from the original accuracy, on your use case, follow Nvidia process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ed1b47f25084ffb98165b5a5ba60d22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27b6e88f50be4e229bdcd4e992a83467",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "QDQBertForSequenceClassification(\n",
       "  (bert): QDQBertModel(\n",
       "    (embeddings): QDQBertEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): QDQBertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): QDQBertLayer(\n",
       "          (attention): QDQBertAttention(\n",
       "            (self): QDQBertSelfAttention(\n",
       "              (query): QuantLinear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=4.3825 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=(0,) amax=[0.2278, 0.7138](768) calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (key): QuantLinear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=4.3825 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=(0,) amax=[0.2136, 0.8620](768) calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (value): QuantLinear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=4.3825 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=(0,) amax=[0.0559, 0.3011](768) calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (matmul_q_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=20.8514 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (matmul_k_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=19.0919 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (matmul_v_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=2.8985 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (matmul_a_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=0.9990 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            )\n",
       "            (output): QDQBertSelfOutput(\n",
       "              (dense): QuantLinear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=1.6973 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=(0,) amax=[0.0893, 0.8268](768) calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (add_local_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=1.7937 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (add_residual_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=4.3825 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): QDQBertIntermediate(\n",
       "            (dense): QuantLinear(\n",
       "              in_features=768, out_features=3072, bias=True\n",
       "              (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=14.6473 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (_weight_quantizer): TensorQuantizer(8bit fake axis=(0,) amax=[0.0784, 0.9981](3072) calibrator=MaxCalibrator scale=1.0 quant)\n",
       "            )\n",
       "          )\n",
       "          (output): QDQBertOutput(\n",
       "            (dense): QuantLinear(\n",
       "              in_features=3072, out_features=768, bias=True\n",
       "              (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=5.0149 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (_weight_quantizer): TensorQuantizer(8bit fake axis=(0,) amax=[0.1539, 1.0117](768) calibrator=MaxCalibrator scale=1.0 quant)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (add_local_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=10.3320 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (add_residual_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=14.6473 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (1): QDQBertLayer(\n",
       "          (attention): QDQBertAttention(\n",
       "            (self): QDQBertSelfAttention(\n",
       "              (query): QuantLinear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=14.9149 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=(0,) amax=[0.1719, 0.5387](768) calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (key): QuantLinear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=14.9149 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=(0,) amax=[0.1739, 0.7034](768) calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (value): QuantLinear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=14.9149 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=(0,) amax=[0.0692, 0.3668](768) calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (matmul_q_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=9.8894 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (matmul_k_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=11.1935 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (matmul_v_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=4.4753 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (matmul_a_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=0.9980 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            )\n",
       "            (output): QDQBertSelfOutput(\n",
       "              (dense): QuantLinear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=2.0571 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=(0,) amax=[0.0568, 0.8128](768) calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (add_local_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=2.8345 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (add_residual_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=14.9149 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): QDQBertIntermediate(\n",
       "            (dense): QuantLinear(\n",
       "              in_features=768, out_features=3072, bias=True\n",
       "              (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=23.7561 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (_weight_quantizer): TensorQuantizer(8bit fake axis=(0,) amax=[0.0939, 0.9761](3072) calibrator=MaxCalibrator scale=1.0 quant)\n",
       "            )\n",
       "          )\n",
       "          (output): QDQBertOutput(\n",
       "            (dense): QuantLinear(\n",
       "              in_features=3072, out_features=768, bias=True\n",
       "              (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=2.4792 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (_weight_quantizer): TensorQuantizer(8bit fake axis=(0,) amax=[0.1338, 1.0384](768) calibrator=MaxCalibrator scale=1.0 quant)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (add_local_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=5.1303 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (add_residual_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=23.7561 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (2): QDQBertLayer(\n",
       "          (attention): QDQBertAttention(\n",
       "            (self): QDQBertSelfAttention(\n",
       "              (query): QuantLinear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=22.2597 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=(0,) amax=[0.1519, 0.5226](768) calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (key): QuantLinear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=22.2597 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=(0,) amax=[0.1586, 0.6574](768) calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (value): QuantLinear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=22.2597 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=(0,) amax=[0.0927, 0.5691](768) calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (matmul_q_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=10.8590 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (matmul_k_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=8.8922 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (matmul_v_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=3.5050 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (matmul_a_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=0.7881 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            )\n",
       "            (output): QDQBertSelfOutput(\n",
       "              (dense): QuantLinear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=1.5292 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=(0,) amax=[0.0546, 0.5824](768) calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (add_local_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=1.5733 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (add_residual_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=22.2597 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): QDQBertIntermediate(\n",
       "            (dense): QuantLinear(\n",
       "              in_features=768, out_features=3072, bias=True\n",
       "              (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=25.3726 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (_weight_quantizer): TensorQuantizer(8bit fake axis=(0,) amax=[0.0962, 0.6515](3072) calibrator=MaxCalibrator scale=1.0 quant)\n",
       "            )\n",
       "          )\n",
       "          (output): QDQBertOutput(\n",
       "            (dense): QuantLinear(\n",
       "              in_features=3072, out_features=768, bias=True\n",
       "              (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=5.4743 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (_weight_quantizer): TensorQuantizer(8bit fake axis=(0,) amax=[0.1189, 0.9865](768) calibrator=MaxCalibrator scale=1.0 quant)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (add_local_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=8.3749 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (add_residual_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=25.3726 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (3): QDQBertLayer(\n",
       "          (attention): QDQBertAttention(\n",
       "            (self): QDQBertSelfAttention(\n",
       "              (query): QuantLinear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=19.5269 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=(0,) amax=[0.1655, 0.6085](768) calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (key): QuantLinear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=19.5269 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=(0,) amax=[0.1591, 0.6744](768) calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (value): QuantLinear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=19.5269 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=(0,) amax=[0.1096, 0.4942](768) calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (matmul_q_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=11.2382 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (matmul_k_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=10.1940 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (matmul_v_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=4.0930 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (matmul_a_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=0.6143 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            )\n",
       "            (output): QDQBertSelfOutput(\n",
       "              (dense): QuantLinear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=1.4349 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=(0,) amax=[0.0487, 0.6398](768) calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (add_local_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=1.4685 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (add_residual_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=19.5269 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): QDQBertIntermediate(\n",
       "            (dense): QuantLinear(\n",
       "              in_features=768, out_features=3072, bias=True\n",
       "              (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=23.5186 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (_weight_quantizer): TensorQuantizer(8bit fake axis=(0,) amax=[0.0921, 0.6942](3072) calibrator=MaxCalibrator scale=1.0 quant)\n",
       "            )\n",
       "          )\n",
       "          (output): QDQBertOutput(\n",
       "            (dense): QuantLinear(\n",
       "              in_features=3072, out_features=768, bias=True\n",
       "              (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=5.5658 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (_weight_quantizer): TensorQuantizer(8bit fake axis=(0,) amax=[0.1252, 1.0283](768) calibrator=MaxCalibrator scale=1.0 quant)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (add_local_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=3.2256 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (add_residual_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=23.5186 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (4): QDQBertLayer(\n",
       "          (attention): QDQBertAttention(\n",
       "            (self): QDQBertSelfAttention(\n",
       "              (query): QuantLinear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=19.0308 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=(0,) amax=[0.1818, 0.6171](768) calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (key): QuantLinear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=19.0308 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=(0,) amax=[0.1737, 0.6774](768) calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (value): QuantLinear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=19.0308 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=(0,) amax=[0.0965, 0.3672](768) calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (matmul_q_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=10.3299 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (matmul_k_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=9.9871 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (matmul_v_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=2.9571 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (matmul_a_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=0.5410 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            )\n",
       "            (output): QDQBertSelfOutput(\n",
       "              (dense): QuantLinear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=2.0579 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=(0,) amax=[0.0243, 0.5534](768) calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (add_local_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=2.5376 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (add_residual_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=19.0308 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): QDQBertIntermediate(\n",
       "            (dense): QuantLinear(\n",
       "              in_features=768, out_features=3072, bias=True\n",
       "              (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=22.8352 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (_weight_quantizer): TensorQuantizer(8bit fake axis=(0,) amax=[0.0947, 0.6763](3072) calibrator=MaxCalibrator scale=1.0 quant)\n",
       "            )\n",
       "          )\n",
       "          (output): QDQBertOutput(\n",
       "            (dense): QuantLinear(\n",
       "              in_features=3072, out_features=768, bias=True\n",
       "              (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=5.8965 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (_weight_quantizer): TensorQuantizer(8bit fake axis=(0,) amax=[0.1001, 1.0148](768) calibrator=MaxCalibrator scale=1.0 quant)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (add_local_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=4.1937 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (add_residual_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=22.8352 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (5): QDQBertLayer(\n",
       "          (attention): QDQBertAttention(\n",
       "            (self): QDQBertSelfAttention(\n",
       "              (query): QuantLinear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=21.2023 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=(0,) amax=[0.1441, 0.5500](768) calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (key): QuantLinear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=21.2023 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=(0,) amax=[0.1398, 0.6392](768) calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (value): QuantLinear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=21.2023 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=(0,) amax=[0.1045, 0.3702](768) calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (matmul_q_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=9.6675 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (matmul_k_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=10.5083 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (matmul_v_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=3.8853 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (matmul_a_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=0.5531 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            )\n",
       "            (output): QDQBertSelfOutput(\n",
       "              (dense): QuantLinear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=1.7910 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=(0,) amax=[0.0132, 0.5822](768) calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (add_local_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=2.0695 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (add_residual_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=21.2023 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): QDQBertIntermediate(\n",
       "            (dense): QuantLinear(\n",
       "              in_features=768, out_features=3072, bias=True\n",
       "              (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=23.2437 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (_weight_quantizer): TensorQuantizer(8bit fake axis=(0,) amax=[0.0828, 0.6019](3072) calibrator=MaxCalibrator scale=1.0 quant)\n",
       "            )\n",
       "          )\n",
       "          (output): QDQBertOutput(\n",
       "            (dense): QuantLinear(\n",
       "              in_features=3072, out_features=768, bias=True\n",
       "              (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=2.6517 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (_weight_quantizer): TensorQuantizer(8bit fake axis=(0,) amax=[0.1048, 1.0222](768) calibrator=MaxCalibrator scale=1.0 quant)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (add_local_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=2.9217 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (add_residual_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=23.2437 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (6): QDQBertLayer(\n",
       "          (attention): QDQBertAttention(\n",
       "            (self): QDQBertSelfAttention(\n",
       "              (query): QuantLinear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=21.3477 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=(0,) amax=[0.1642, 0.6043](768) calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (key): QuantLinear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=21.3477 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=(0,) amax=[0.1595, 0.6278](768) calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (value): QuantLinear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=21.3477 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=(0,) amax=[0.1190, 0.4426](768) calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (matmul_q_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=9.4666 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (matmul_k_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=9.9298 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (matmul_v_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=3.0881 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (matmul_a_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=0.5958 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            )\n",
       "            (output): QDQBertSelfOutput(\n",
       "              (dense): QuantLinear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=2.0587 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=(0,) amax=[0.0709, 0.5058](768) calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (add_local_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=3.3172 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (add_residual_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=21.3477 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): QDQBertIntermediate(\n",
       "            (dense): QuantLinear(\n",
       "              in_features=768, out_features=3072, bias=True\n",
       "              (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=22.1748 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (_weight_quantizer): TensorQuantizer(8bit fake axis=(0,) amax=[0.1002, 0.6699](3072) calibrator=MaxCalibrator scale=1.0 quant)\n",
       "            )\n",
       "          )\n",
       "          (output): QDQBertOutput(\n",
       "            (dense): QuantLinear(\n",
       "              in_features=3072, out_features=768, bias=True\n",
       "              (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=2.4878 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (_weight_quantizer): TensorQuantizer(8bit fake axis=(0,) amax=[0.1194, 1.0115](768) calibrator=MaxCalibrator scale=1.0 quant)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (add_local_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=6.5609 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (add_residual_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=22.1748 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (7): QDQBertLayer(\n",
       "          (attention): QDQBertAttention(\n",
       "            (self): QDQBertSelfAttention(\n",
       "              (query): QuantLinear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=22.3952 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=(0,) amax=[0.1621, 0.6402](768) calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (key): QuantLinear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=22.3952 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=(0,) amax=[0.1712, 0.6015](768) calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (value): QuantLinear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=22.3952 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=(0,) amax=[0.0624, 0.3250](768) calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (matmul_q_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=8.8818 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (matmul_k_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=9.0426 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (matmul_v_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=2.8084 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (matmul_a_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=0.7217 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            )\n",
       "            (output): QDQBertSelfOutput(\n",
       "              (dense): QuantLinear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=2.8457 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=(0,) amax=[0.0550, 0.6221](768) calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (add_local_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=5.8872 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (add_residual_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=22.3952 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): QDQBertIntermediate(\n",
       "            (dense): QuantLinear(\n",
       "              in_features=768, out_features=3072, bias=True\n",
       "              (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=22.3410 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (_weight_quantizer): TensorQuantizer(8bit fake axis=(0,) amax=[0.0798, 0.7414](3072) calibrator=MaxCalibrator scale=1.0 quant)\n",
       "            )\n",
       "          )\n",
       "          (output): QDQBertOutput(\n",
       "            (dense): QuantLinear(\n",
       "              in_features=3072, out_features=768, bias=True\n",
       "              (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=2.8300 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (_weight_quantizer): TensorQuantizer(8bit fake axis=(0,) amax=[0.1221, 1.2854](768) calibrator=MaxCalibrator scale=1.0 quant)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (add_local_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=11.7479 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (add_residual_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=22.3410 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (8): QDQBertLayer(\n",
       "          (attention): QDQBertAttention(\n",
       "            (self): QDQBertSelfAttention(\n",
       "              (query): QuantLinear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=22.8846 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=(0,) amax=[0.1674, 0.5365](768) calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (key): QuantLinear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=22.8846 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=(0,) amax=[0.1649, 0.6477](768) calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (value): QuantLinear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=22.8846 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=(0,) amax=[0.0949, 0.3530](768) calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (matmul_q_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=9.9038 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (matmul_k_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=9.0857 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (matmul_v_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=3.3595 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (matmul_a_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=0.5520 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            )\n",
       "            (output): QDQBertSelfOutput(\n",
       "              (dense): QuantLinear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=1.8644 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=(0,) amax=[0.0494, 0.5720](768) calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (add_local_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=6.3703 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (add_residual_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=22.8846 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): QDQBertIntermediate(\n",
       "            (dense): QuantLinear(\n",
       "              in_features=768, out_features=3072, bias=True\n",
       "              (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=22.0888 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (_weight_quantizer): TensorQuantizer(8bit fake axis=(0,) amax=[0.0869, 0.5807](3072) calibrator=MaxCalibrator scale=1.0 quant)\n",
       "            )\n",
       "          )\n",
       "          (output): QDQBertOutput(\n",
       "            (dense): QuantLinear(\n",
       "              in_features=3072, out_features=768, bias=True\n",
       "              (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=3.3958 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (_weight_quantizer): TensorQuantizer(8bit fake axis=(0,) amax=[0.1237, 1.3025](768) calibrator=MaxCalibrator scale=1.0 quant)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (add_local_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=8.2477 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (add_residual_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=22.0888 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (9): QDQBertLayer(\n",
       "          (attention): QDQBertAttention(\n",
       "            (self): QDQBertSelfAttention(\n",
       "              (query): QuantLinear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=22.7030 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=(0,) amax=[0.1545, 0.5240](768) calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (key): QuantLinear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=22.7030 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=(0,) amax=[0.1542, 0.5843](768) calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (value): QuantLinear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=22.7030 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=(0,) amax=[0.0838, 0.3533](768) calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (matmul_q_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=9.8699 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (matmul_k_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=9.0611 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (matmul_v_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=3.3043 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (matmul_a_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=0.5683 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            )\n",
       "            (output): QDQBertSelfOutput(\n",
       "              (dense): QuantLinear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=2.1081 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=(0,) amax=[0.0701, 0.5085](768) calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (add_local_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=6.3062 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (add_residual_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=22.7030 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): QDQBertIntermediate(\n",
       "            (dense): QuantLinear(\n",
       "              in_features=768, out_features=3072, bias=True\n",
       "              (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=21.3909 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (_weight_quantizer): TensorQuantizer(8bit fake axis=(0,) amax=[0.0689, 0.5368](3072) calibrator=MaxCalibrator scale=1.0 quant)\n",
       "            )\n",
       "          )\n",
       "          (output): QDQBertOutput(\n",
       "            (dense): QuantLinear(\n",
       "              in_features=3072, out_features=768, bias=True\n",
       "              (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=3.6746 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (_weight_quantizer): TensorQuantizer(8bit fake axis=(0,) amax=[0.1116, 1.0891](768) calibrator=MaxCalibrator scale=1.0 quant)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (add_local_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=5.0953 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (add_residual_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=21.3909 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (10): QDQBertLayer(\n",
       "          (attention): QDQBertAttention(\n",
       "            (self): QDQBertSelfAttention(\n",
       "              (query): QuantLinear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=21.7367 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=(0,) amax=[0.1565, 0.5091](768) calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (key): QuantLinear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=21.7367 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=(0,) amax=[0.1599, 0.5542](768) calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (value): QuantLinear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=21.7367 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=(0,) amax=[0.0913, 0.2951](768) calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (matmul_q_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=8.3141 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (matmul_k_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=8.3140 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (matmul_v_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=3.5668 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (matmul_a_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=0.6283 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            )\n",
       "            (output): QDQBertSelfOutput(\n",
       "              (dense): QuantLinear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=3.3139 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=(0,) amax=[0.0822, 0.5450](768) calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (add_local_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=5.0508 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (add_residual_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=21.7367 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): QDQBertIntermediate(\n",
       "            (dense): QuantLinear(\n",
       "              in_features=768, out_features=3072, bias=True\n",
       "              (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=18.8718 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (_weight_quantizer): TensorQuantizer(8bit fake axis=(0,) amax=[0.0845, 0.5929](3072) calibrator=MaxCalibrator scale=1.0 quant)\n",
       "            )\n",
       "          )\n",
       "          (output): QDQBertOutput(\n",
       "            (dense): QuantLinear(\n",
       "              in_features=3072, out_features=768, bias=True\n",
       "              (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=3.2979 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (_weight_quantizer): TensorQuantizer(8bit fake axis=(0,) amax=[0.1073, 1.0226](768) calibrator=MaxCalibrator scale=1.0 quant)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (add_local_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=4.1809 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (add_residual_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=18.8718 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (11): QDQBertLayer(\n",
       "          (attention): QDQBertAttention(\n",
       "            (self): QDQBertSelfAttention(\n",
       "              (query): QuantLinear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=18.6916 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=(0,) amax=[0.1717, 0.5519](768) calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (key): QuantLinear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=18.6916 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=(0,) amax=[0.1763, 0.5545](768) calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (value): QuantLinear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=18.6916 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=(0,) amax=[0.1061, 0.3834](768) calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (matmul_q_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=9.1137 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (matmul_k_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=7.2776 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (matmul_v_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=3.7551 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (matmul_a_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=0.5068 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            )\n",
       "            (output): QDQBertSelfOutput(\n",
       "              (dense): QuantLinear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=3.7846 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "                (_weight_quantizer): TensorQuantizer(8bit fake axis=(0,) amax=[0.0972, 0.5767](768) calibrator=MaxCalibrator scale=1.0 quant)\n",
       "              )\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (add_local_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=7.4840 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (add_residual_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=18.6916 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): QDQBertIntermediate(\n",
       "            (dense): QuantLinear(\n",
       "              in_features=768, out_features=3072, bias=True\n",
       "              (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=12.2354 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (_weight_quantizer): TensorQuantizer(8bit fake axis=(0,) amax=[0.0989, 0.3906](3072) calibrator=MaxCalibrator scale=1.0 quant)\n",
       "            )\n",
       "          )\n",
       "          (output): QDQBertOutput(\n",
       "            (dense): QuantLinear(\n",
       "              in_features=3072, out_features=768, bias=True\n",
       "              (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=3.4522 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "              (_weight_quantizer): TensorQuantizer(8bit fake axis=(0,) amax=[0.0954, 0.9991](768) calibrator=MaxCalibrator scale=1.0 quant)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (add_local_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=12.8952 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (add_residual_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=12.2354 calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): QDQBertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_q = QDQBertForSequenceClassification.from_pretrained(\"roberta-in-bert-trained\", num_labels=num_labels)\n",
    "\n",
    "calibrate(model=model_q, encoded_dataset=encoded_dataset)\n",
    "\n",
    "# count = 0\n",
    "# for name, mod in model_q.named_modules():\n",
    "#     if isinstance(mod, pytorch_quantization.nn.TensorQuantizer):\n",
    "#         print(f\"{name:80} {mod}\")\n",
    "#         count += 1\n",
    "# print(f\"{count} TensorQuantizers found in model\")\n",
    "# model_q.save_pretrained(\"roberta-in-bert-trained-quantized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantization Aware Training (QAT)\n",
    "\n",
    "The query aware training is not a mandatory step, but **highly** recommended to get the best accuracy. Basically we will redo the training with the quantization enabled and a low learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "imY1oC3SIrJf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:437] 2021-12-06 18:34:07,721 >> Using amp half precision backend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4492516815662384, 'eval_accuracy': 0.8271013754457464, 'eval_runtime': 46.2281, 'eval_samples_per_second': 212.317, 'eval_steps_per_second': 3.331}\n",
      "{'eval_loss': 0.4492516815662384, 'eval_accuracy': 0.8271013754457464, 'eval_runtime': 46.2281, 'eval_samples_per_second': 212.317, 'eval_steps_per_second': 3.331}\n",
      "{'loss': 0.4752, 'learning_rate': 9.188396349413299e-07, 'epoch': 0.08}\n",
      "{'eval_loss': 0.4362102150917053, 'eval_accuracy': 0.8346408558329088, 'eval_runtime': 46.4717, 'eval_samples_per_second': 211.204, 'eval_steps_per_second': 3.314, 'epoch': 0.08}\n",
      "{'loss': 0.4643, 'learning_rate': 8.373533246414604e-07, 'epoch': 0.16}\n",
      "{'eval_loss': 0.42539361119270325, 'eval_accuracy': 0.8370860927152318, 'eval_runtime': 46.5627, 'eval_samples_per_second': 210.791, 'eval_steps_per_second': 3.307, 'epoch': 0.16}\n",
      "{'loss': 0.4509, 'learning_rate': 7.558670143415907e-07, 'epoch': 0.24}\n",
      "{'eval_loss': 0.42584264278411865, 'eval_accuracy': 0.8367804381049414, 'eval_runtime': 46.5106, 'eval_samples_per_second': 211.027, 'eval_steps_per_second': 3.311, 'epoch': 0.24}\n",
      "{'loss': 0.4454, 'learning_rate': 6.743807040417211e-07, 'epoch': 0.33}\n",
      "{'eval_loss': 0.427680641412735, 'eval_accuracy': 0.8410596026490066, 'eval_runtime': 46.5186, 'eval_samples_per_second': 210.991, 'eval_steps_per_second': 3.311, 'epoch': 0.33}\n",
      "{'loss': 0.4486, 'learning_rate': 5.928943937418514e-07, 'epoch': 0.41}\n",
      "{'eval_loss': 0.419879287481308, 'eval_accuracy': 0.8401426388181356, 'eval_runtime': 46.4807, 'eval_samples_per_second': 211.163, 'eval_steps_per_second': 3.313, 'epoch': 0.41}\n",
      "{'loss': 0.444, 'learning_rate': 5.114895697522818e-07, 'epoch': 0.49}\n",
      "{'eval_loss': 0.42938971519470215, 'eval_accuracy': 0.8374936321956189, 'eval_runtime': 46.467, 'eval_samples_per_second': 211.225, 'eval_steps_per_second': 3.314, 'epoch': 0.49}\n",
      "{'loss': 0.442, 'learning_rate': 4.30003259452412e-07, 'epoch': 0.57}\n",
      "{'eval_loss': 0.4225366413593292, 'eval_accuracy': 0.8381049414161997, 'eval_runtime': 46.5078, 'eval_samples_per_second': 211.04, 'eval_steps_per_second': 3.311, 'epoch': 0.57}\n",
      "{'loss': 0.4463, 'learning_rate': 3.485169491525424e-07, 'epoch': 0.65}\n",
      "{'eval_loss': 0.423688679933548, 'eval_accuracy': 0.8393275598573612, 'eval_runtime': 46.4966, 'eval_samples_per_second': 211.09, 'eval_steps_per_second': 3.312, 'epoch': 0.65}\n",
      "{'loss': 0.4488, 'learning_rate': 2.671121251629727e-07, 'epoch': 0.73}\n",
      "{'eval_loss': 0.4213014543056488, 'eval_accuracy': 0.8401426388181356, 'eval_runtime': 46.5212, 'eval_samples_per_second': 210.979, 'eval_steps_per_second': 3.31, 'epoch': 0.73}\n",
      "{'loss': 0.4354, 'learning_rate': 1.8562581486310303e-07, 'epoch': 0.81}\n",
      "{'eval_loss': 0.4192813038825989, 'eval_accuracy': 0.8407539480387163, 'eval_runtime': 48.5842, 'eval_samples_per_second': 202.02, 'eval_steps_per_second': 3.17, 'epoch': 0.81}\n",
      "{'loss': 0.4344, 'learning_rate': 1.0422099087353327e-07, 'epoch': 0.9}\n",
      "{'eval_loss': 0.41954925656318665, 'eval_accuracy': 0.8381049414161997, 'eval_runtime': 48.5554, 'eval_samples_per_second': 202.14, 'eval_steps_per_second': 3.172, 'epoch': 0.9}\n",
      "{'loss': 0.436, 'learning_rate': 2.2734680573663627e-08, 'epoch': 0.98}\n",
      "{'eval_loss': 0.41829705238342285, 'eval_accuracy': 0.8401426388181356, 'eval_runtime': 46.6717, 'eval_samples_per_second': 210.299, 'eval_steps_per_second': 3.3, 'epoch': 0.98}\n",
      "{'train_runtime': 4966.1274, 'train_samples_per_second': 79.076, 'train_steps_per_second': 2.471, 'train_loss': 0.4474433752206656, 'epoch': 1.0}\n",
      "{'eval_loss': 0.427680641412735, 'eval_accuracy': 0.8410596026490066, 'eval_runtime': 46.5232, 'eval_samples_per_second': 210.97, 'eval_steps_per_second': 3.31, 'epoch': 1.0}\n",
      "{'eval_loss': 0.427680641412735, 'eval_accuracy': 0.8410596026490066, 'eval_runtime': 46.5232, 'eval_samples_per_second': 210.97, 'eval_steps_per_second': 3.31, 'epoch': 1.0}\n"
     ]
    }
   ],
   "source": [
    "model_q = QDQBertForSequenceClassification.from_pretrained(\"roberta-in-bert-trained-quantized\", num_labels=num_labels)\n",
    "model_q = model_q.cuda()\n",
    "\n",
    "args.learning_rate /= 10\n",
    "trainer = Trainer(\n",
    "    model_q,\n",
    "    args,\n",
    "    train_dataset=encoded_dataset[\"train\"],\n",
    "    eval_dataset=encoded_dataset[validation_key],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "transformers.logging.set_verbosity_error()\n",
    "print(trainer.evaluate())\n",
    "trainer.train()\n",
    "print(trainer.evaluate())\n",
    "model_q.save_pretrained(\"roberta-in-bert-trained-quantized-bis\")\n",
    "del model_q\n",
    "del trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export a `QDQ Pytorch` model on `ONNX`, we need to enable fake quantization mode from Pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/geantvert/.local/share/virtualenvs/fast_transformer/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:285: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/geantvert/.local/share/virtualenvs/fast_transformer/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:291: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n"
     ]
    }
   ],
   "source": [
    "data = encoded_dataset[\"train\"][0: 3]\n",
    "input_torch = {k: torch.tensor(v, dtype=torch.long, device=\"cuda\") for k, v in data.items() if k in [\"input_ids\", \"attention_mask\", \"token_type_ids\"]}\n",
    "\n",
    "from pytorch_quantization.nn import TensorQuantizer\n",
    "model_q = QDQBertForSequenceClassification.from_pretrained(\"roberta-in-bert-trained-quantized-bis\", num_labels=num_labels)\n",
    "model_q = model_q.cuda()\n",
    "TensorQuantizer.use_fb_fake_quant = True\n",
    "convert_to_onnx(model_q, output_path=\"model_q.onnx\", inputs_pytorch=input_torch)\n",
    "TensorQuantizer.use_fb_fake_quant = False\n",
    "del model_q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Convert `ONNX` graph to `TensorRT` engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "engine = build_engine(\n",
    "    runtime=runtime,\n",
    "    onnx_file_path=\"model_q.onnx\",\n",
    "    logger=trt_logger,\n",
    "    min_shape=(batch_size, max_seq_len),\n",
    "    optimal_shape=(batch_size, max_seq_len),\n",
    "    max_shape=(batch_size, max_seq_len),\n",
    "    workspace_size=10000 * 1024 * 1024,\n",
    "    fp16=False,\n",
    "    int8=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Prepare input and output buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "profile_index = 0\n",
    "np_input = {\"input_ids\": np.random.randint(1, 10000, size=(batch_size, max_seq_len), dtype=np.int64),\n",
    " \"attention_mask\": np.ones(shape=(batch_size, max_seq_len), dtype=np.int64),\n",
    "            }\n",
    "\n",
    "stream: Stream = pycuda.driver.Stream()\n",
    "\n",
    "context: IExecutionContext = engine.create_execution_context()\n",
    "context.set_optimization_profile_async(profile_index=profile_index, stream_handle=stream.handle)\n",
    "input_binding_idxs, output_binding_idxs = get_binding_idxs(engine, profile_index)  # type: List[int], List[int]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Inference on `TensorRT`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 0.1358001 , -1.4377486 ,  1.3672757 ],\n",
      "       [-0.16206698, -1.149481  ,  1.4266016 ],\n",
      "       [ 0.0163878 , -1.0470941 ,  1.2498031 ],\n",
      "       [-0.21079333, -0.91275144,  1.2614312 ],\n",
      "       [ 0.13416213, -1.2132894 ,  1.0915226 ],\n",
      "       [-0.23387383, -0.6663823 ,  1.0708152 ],\n",
      "       [-0.4426742 , -0.64095986,  0.6767337 ],\n",
      "       [-0.39520252, -0.6310587 ,  1.162437  ],\n",
      "       [-0.11956491, -0.9094458 ,  1.2330313 ],\n",
      "       [-0.34652767, -0.56745625,  1.1321819 ],\n",
      "       [-0.3788384 , -0.9477967 ,  1.3850961 ],\n",
      "       [-1.079162  ,  0.04613969,  0.9176692 ],\n",
      "       [-0.12555303, -0.8791798 ,  1.2635291 ],\n",
      "       [-0.12463601, -0.63906515,  0.95351076],\n",
      "       [ 0.31858096, -0.410717  ,  0.69519377],\n",
      "       [ 0.07587517, -0.58817637,  0.82071406],\n",
      "       [ 0.1137608 , -0.8322618 ,  0.6675602 ],\n",
      "       [-0.50839895, -0.8443974 ,  1.462322  ],\n",
      "       [-0.14658742, -1.1222454 ,  1.3913041 ],\n",
      "       [ 0.05990895, -1.4671483 ,  1.5297441 ],\n",
      "       [ 0.17553274, -0.26642302,  0.67778957],\n",
      "       [ 0.14809372, -1.3270702 ,  1.1495501 ],\n",
      "       [-0.1042301 , -0.8665275 ,  0.90043837],\n",
      "       [-0.78590935, -0.6129427 ,  0.9732029 ],\n",
      "       [-0.19332369, -0.8912125 ,  1.1381842 ],\n",
      "       [ 0.50638545, -0.9965472 ,  0.69867384],\n",
      "       [-0.0973227 , -0.8511242 ,  1.2328701 ],\n",
      "       [ 0.16307044, -1.1843398 ,  1.437165  ],\n",
      "       [-0.6260487 , -0.5227167 ,  1.247594  ],\n",
      "       [-0.30106562, -0.6723875 ,  1.1667051 ],\n",
      "       [ 0.01060311, -1.1707903 ,  1.3197892 ],\n",
      "       [-0.22743034, -0.99327207,  0.9541633 ]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "tensorrt_output = infer_tensorrt(\n",
    "    context=context,\n",
    "    host_inputs=np_input,\n",
    "    input_binding_idxs=input_binding_idxs,\n",
    "    output_binding_idxs=output_binding_idxs,\n",
    "    stream=stream,\n",
    ")\n",
    "print(tensorrt_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Conversion with `trtexec` (command line approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/src/tensorrt/bin/trtexec --onnx=model_q.onnx --shapes=input_ids:32x256,attention_mask:32x256 --int8 --workspace=6000  --saveEngine=\"test.plan\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Method 2: use a dedicated QDQ model\n",
    "\n",
    "In method 2, the idea is to take the source code of a specific model and add manually in the source code `QDQ` nodes. That way, quantization will work out of the box. Even if `Bert` has many variations, it seems that very few of them are really used. Hugging Face transformers library include `Bert` model.\n",
    "Our library offer a dedicated implementation of `Roberta`.\n",
    "\n",
    "To adapt another architecture, you need to:\n",
    "\n",
    "* replaced linear layers with their quantized version\n",
    "* replace operations not supported out of the box by TensorRT by a similar code supporting the operation.\n",
    "\n",
    "> it's not a complex process, but it requires some knowledge of `ONNX` supported operations and `TensorRT` framework\n",
    "\n",
    "The process below is a bit simpler than the method 1:\n",
    "\n",
    "* finetune the QDQ model on the task (Quantization Aware Training)\n",
    "* calibrate\n",
    "* Quantization Aware training (QAT)\n",
    "\n",
    "> you may skip step 1/ if you want\n",
    "\n",
    "### Fine tuning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:437] 2021-12-06 20:38:02,464 >> Using amp half precision backend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6886, 'learning_rate': 9.188396349413299e-06, 'epoch': 0.08}\n",
      "{'eval_loss': 0.4678966999053955, 'eval_accuracy': 0.8171166581762608, 'eval_runtime': 18.7354, 'eval_samples_per_second': 523.874, 'eval_steps_per_second': 8.22, 'epoch': 0.08}\n",
      "{'loss': 0.5021, 'learning_rate': 8.373533246414604e-06, 'epoch': 0.16}\n",
      "{'eval_loss': 0.4271945059299469, 'eval_accuracy': 0.8333163525216505, 'eval_runtime': 18.5466, 'eval_samples_per_second': 529.209, 'eval_steps_per_second': 8.303, 'epoch': 0.16}\n",
      "{'loss': 0.4682, 'learning_rate': 7.558670143415907e-06, 'epoch': 0.24}\n",
      "{'eval_loss': 0.4240091145038605, 'eval_accuracy': 0.8358634742740703, 'eval_runtime': 18.6916, 'eval_samples_per_second': 525.101, 'eval_steps_per_second': 8.239, 'epoch': 0.24}\n",
      "{'loss': 0.4491, 'learning_rate': 6.743807040417211e-06, 'epoch': 0.33}\n",
      "{'eval_loss': 0.38295766711235046, 'eval_accuracy': 0.8523688232297504, 'eval_runtime': 18.6766, 'eval_samples_per_second': 525.524, 'eval_steps_per_second': 8.246, 'epoch': 0.33}\n",
      "{'loss': 0.4292, 'learning_rate': 5.9289439374185145e-06, 'epoch': 0.41}\n",
      "{'eval_loss': 0.3819591999053955, 'eval_accuracy': 0.8519612837493632, 'eval_runtime': 19.1793, 'eval_samples_per_second': 511.75, 'eval_steps_per_second': 8.029, 'epoch': 0.41}\n",
      "{'loss': 0.4188, 'learning_rate': 5.114080834419818e-06, 'epoch': 0.49}\n",
      "{'eval_loss': 0.3905084729194641, 'eval_accuracy': 0.8507386653082017, 'eval_runtime': 18.5694, 'eval_samples_per_second': 528.559, 'eval_steps_per_second': 8.293, 'epoch': 0.49}\n",
      "{'loss': 0.4171, 'learning_rate': 4.30003259452412e-06, 'epoch': 0.57}\n",
      "{'eval_loss': 0.36459046602249146, 'eval_accuracy': 0.8601120733571065, 'eval_runtime': 18.5686, 'eval_samples_per_second': 528.579, 'eval_steps_per_second': 8.294, 'epoch': 0.57}\n",
      "{'loss': 0.4118, 'learning_rate': 3.4851694915254244e-06, 'epoch': 0.65}\n",
      "{'eval_loss': 0.35626235604286194, 'eval_accuracy': 0.8616403464085584, 'eval_runtime': 18.5178, 'eval_samples_per_second': 530.029, 'eval_steps_per_second': 8.316, 'epoch': 0.65}\n",
      "{'loss': 0.4006, 'learning_rate': 2.670306388526728e-06, 'epoch': 0.73}\n",
      "{'eval_loss': 0.3605223596096039, 'eval_accuracy': 0.8653082017320428, 'eval_runtime': 18.6003, 'eval_samples_per_second': 527.68, 'eval_steps_per_second': 8.279, 'epoch': 0.73}\n",
      "{'loss': 0.3936, 'learning_rate': 1.8570730117340288e-06, 'epoch': 0.81}\n",
      "{'eval_loss': 0.3559686243534088, 'eval_accuracy': 0.8653082017320428, 'eval_runtime': 18.5309, 'eval_samples_per_second': 529.656, 'eval_steps_per_second': 8.31, 'epoch': 0.81}\n",
      "{'loss': 0.3945, 'learning_rate': 1.0422099087353325e-06, 'epoch': 0.9}\n",
      "{'eval_loss': 0.3518819212913513, 'eval_accuracy': 0.8659195109526235, 'eval_runtime': 18.5189, 'eval_samples_per_second': 529.998, 'eval_steps_per_second': 8.316, 'epoch': 0.9}\n",
      "{'loss': 0.3977, 'learning_rate': 2.2734680573663624e-07, 'epoch': 0.98}\n",
      "{'eval_loss': 0.34959253668785095, 'eval_accuracy': 0.8677534386143657, 'eval_runtime': 18.5328, 'eval_samples_per_second': 529.602, 'eval_steps_per_second': 8.31, 'epoch': 0.98}\n",
      "{'train_runtime': 2665.1824, 'train_samples_per_second': 147.345, 'train_steps_per_second': 4.605, 'train_loss': 0.44651927413343606, 'epoch': 1.0}\n",
      "{'eval_loss': 0.34959253668785095, 'eval_accuracy': 0.8677534386143657, 'eval_runtime': 18.4913, 'eval_samples_per_second': 530.789, 'eval_steps_per_second': 8.328, 'epoch': 1.0}\n",
      "{'eval_loss': 0.34959253668785095, 'eval_accuracy': 0.8677534386143657, 'eval_runtime': 18.4913, 'eval_samples_per_second': 530.789, 'eval_steps_per_second': 8.328, 'epoch': 1.0}\n"
     ]
    }
   ],
   "source": [
    "model_roberta: PreTrainedModel = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels)\n",
    "model_roberta = model_roberta.cuda()\n",
    "\n",
    "args.learning_rate = 1e-5\n",
    "trainer = Trainer(\n",
    "    model_roberta,\n",
    "    args,\n",
    "    train_dataset=encoded_dataset[\"train\"],\n",
    "    eval_dataset=encoded_dataset[validation_key],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "transformers.logging.set_verbosity_error()\n",
    "trainer.train()\n",
    "print(trainer.evaluate())\n",
    "# {'eval_loss': 0.3559744358062744, 'eval_accuracy': 0.8655119714722364, 'eval_runtime': 19.6678, 'eval_samples_per_second': 499.04, 'eval_steps_per_second': 7.83, 'epoch': 0.98}\n",
    "trainer.save_model(\"roberta-model\")\n",
    "del model_roberta\n",
    "del trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e696905fbfdf4a149cb2437482b20cf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1369f4ac82f4f90b2194d209dc1c8cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "input_desc = QuantDescriptor(num_bits=8, calib_method=\"histogram\")\n",
    "# below we do per-channel quantization for weights, set axis to None to get a per tensor calibration\n",
    "weight_desc = QuantDescriptor(num_bits=8, axis=(0,))\n",
    "quant_nn.QuantLinear.set_default_quant_desc_input(input_desc)\n",
    "quant_nn.QuantLinear.set_default_quant_desc_weight(weight_desc)\n",
    "\n",
    "# keep it on CPU\n",
    "model_roberta_q: PreTrainedModel = QDQRobertaForSequenceClassification.from_pretrained(\"roberta-model\")\n",
    "calibrate(model=model_roberta_q, encoded_dataset=encoded_dataset)\n",
    "\n",
    "\n",
    "model_roberta_q.save_pretrained(\"roberta-trained-quantized\")\n",
    "del model_roberta_q\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "### Quantization Aware Training (QAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:437] 2021-12-06 21:28:16,421 >> Using amp half precision backend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 1.0000000000000002e-06\n",
      "{'eval_loss': 0.38657698035240173, 'eval_accuracy': 0.8526744778400408, 'eval_runtime': 47.6064, 'eval_samples_per_second': 206.17, 'eval_steps_per_second': 3.235}\n",
      "{'eval_loss': 0.38657698035240173, 'eval_accuracy': 0.8526744778400408, 'eval_runtime': 47.6064, 'eval_samples_per_second': 206.17, 'eval_steps_per_second': 3.235}\n",
      "{'loss': 0.4018, 'learning_rate': 9.187581486310301e-07, 'epoch': 0.08}\n",
      "{'eval_loss': 0.38418063521385193, 'eval_accuracy': 0.8558329088130413, 'eval_runtime': 46.6509, 'eval_samples_per_second': 210.393, 'eval_steps_per_second': 3.301, 'epoch': 0.08}\n",
      "{'loss': 0.3954, 'learning_rate': 8.373533246414604e-07, 'epoch': 0.16}\n",
      "{'eval_loss': 0.3795166015625, 'eval_accuracy': 0.8589913397860418, 'eval_runtime': 46.5562, 'eval_samples_per_second': 210.821, 'eval_steps_per_second': 3.308, 'epoch': 0.16}\n",
      "{'loss': 0.3916, 'learning_rate': 7.558670143415907e-07, 'epoch': 0.24}\n",
      "{'eval_loss': 0.3784726560115814, 'eval_accuracy': 0.8558329088130413, 'eval_runtime': 46.5355, 'eval_samples_per_second': 210.914, 'eval_steps_per_second': 3.309, 'epoch': 0.24}\n",
      "{'loss': 0.3909, 'learning_rate': 6.743807040417211e-07, 'epoch': 0.33}\n",
      "{'eval_loss': 0.38643816113471985, 'eval_accuracy': 0.8565461029037188, 'eval_runtime': 46.544, 'eval_samples_per_second': 210.876, 'eval_steps_per_second': 3.309, 'epoch': 0.33}\n",
      "{'loss': 0.3932, 'learning_rate': 5.928943937418514e-07, 'epoch': 0.41}\n",
      "{'eval_loss': 0.3807451128959656, 'eval_accuracy': 0.8582781456953642, 'eval_runtime': 46.5617, 'eval_samples_per_second': 210.796, 'eval_steps_per_second': 3.307, 'epoch': 0.41}\n",
      "{'loss': 0.3894, 'learning_rate': 5.114895697522818e-07, 'epoch': 0.49}\n",
      "{'eval_loss': 0.3824027180671692, 'eval_accuracy': 0.8613346917982679, 'eval_runtime': 46.5541, 'eval_samples_per_second': 210.83, 'eval_steps_per_second': 3.308, 'epoch': 0.49}\n",
      "{'loss': 0.3895, 'learning_rate': 4.3008474576271193e-07, 'epoch': 0.57}\n",
      "{'eval_loss': 0.3791654407978058, 'eval_accuracy': 0.8613346917982679, 'eval_runtime': 46.5392, 'eval_samples_per_second': 210.897, 'eval_steps_per_second': 3.309, 'epoch': 0.57}\n",
      "{'loss': 0.388, 'learning_rate': 3.4859843546284233e-07, 'epoch': 0.65}\n",
      "{'eval_loss': 0.3764157295227051, 'eval_accuracy': 0.8595007641365258, 'eval_runtime': 47.0386, 'eval_samples_per_second': 208.659, 'eval_steps_per_second': 3.274, 'epoch': 0.65}\n",
      "{'loss': 0.3928, 'learning_rate': 2.671121251629727e-07, 'epoch': 0.73}\n",
      "{'eval_loss': 0.37711256742477417, 'eval_accuracy': 0.8613346917982679, 'eval_runtime': 48.7144, 'eval_samples_per_second': 201.48, 'eval_steps_per_second': 3.161, 'epoch': 0.73}\n",
      "{'loss': 0.381, 'learning_rate': 1.857073011734029e-07, 'epoch': 0.81}\n",
      "{'eval_loss': 0.38059118390083313, 'eval_accuracy': 0.8595007641365258, 'eval_runtime': 47.0072, 'eval_samples_per_second': 208.798, 'eval_steps_per_second': 3.276, 'epoch': 0.81}\n",
      "{'loss': 0.3798, 'learning_rate': 1.0422099087353327e-07, 'epoch': 0.9}\n",
      "{'eval_loss': 0.3735353648662567, 'eval_accuracy': 0.8599083036169128, 'eval_runtime': 48.5826, 'eval_samples_per_second': 202.027, 'eval_steps_per_second': 3.17, 'epoch': 0.9}\n",
      "{'loss': 0.3823, 'learning_rate': 2.2734680573663627e-08, 'epoch': 0.98}\n",
      "{'eval_loss': 0.3766668438911438, 'eval_accuracy': 0.8596026490066225, 'eval_runtime': 48.2033, 'eval_samples_per_second': 203.617, 'eval_steps_per_second': 3.195, 'epoch': 0.98}\n",
      "{'train_runtime': 5010.7316, 'train_samples_per_second': 78.372, 'train_steps_per_second': 2.449, 'train_loss': 0.3895211076798619, 'epoch': 1.0}\n",
      "{'eval_loss': 0.3824027180671692, 'eval_accuracy': 0.8613346917982679, 'eval_runtime': 47.2938, 'eval_samples_per_second': 207.532, 'eval_steps_per_second': 3.256, 'epoch': 1.0}\n",
      "{'eval_loss': 0.3824027180671692, 'eval_accuracy': 0.8613346917982679, 'eval_runtime': 47.2938, 'eval_samples_per_second': 207.532, 'eval_steps_per_second': 3.256, 'epoch': 1.0}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_roberta_q: PreTrainedModel = QDQRobertaForSequenceClassification.from_pretrained(\"roberta-trained-quantized\", num_labels=num_labels)\n",
    "model_roberta_q = model_roberta_q.cuda()\n",
    "\n",
    "args.learning_rate /= 10\n",
    "print(f\"LR: {args.learning_rate}\")\n",
    "trainer = Trainer(\n",
    "    model_roberta_q,\n",
    "    args,\n",
    "    train_dataset=encoded_dataset[\"train\"],\n",
    "    eval_dataset=encoded_dataset[validation_key],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "transformers.logging.set_verbosity_error()\n",
    "print(trainer.evaluate())\n",
    "# 4 batches\n",
    "# {'eval_loss': 0.38076257705688477, 'eval_accuracy': 0.8552215995924605, 'eval_runtime': 46.9577, 'eval_samples_per_second': 209.018, 'eval_steps_per_second': 3.28}\n",
    "# 100 batches\n",
    "# {'eval_loss': 0.386756956577301, 'eval_accuracy': 0.8516556291390729, 'eval_runtime': 48.9996, 'eval_samples_per_second': 200.308, 'eval_steps_per_second': 3.143}\n",
    "trainer.train()\n",
    "print(trainer.evaluate())\n",
    "# {'eval_loss': 0.40235549211502075, 'eval_accuracy': 0.8589913397860418, 'eval_runtime': 46.1754, 'eval_samples_per_second': 212.559, 'eval_steps_per_second': 3.335, 'epoch': 1.0}\n",
    "model_roberta_q.save_pretrained(\"roberta-in-bert-trained-quantized-retrained\")\n",
    "del model_roberta_q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "### Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/geantvert/.local/share/virtualenvs/fast_transformer/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:285: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/geantvert/.local/share/virtualenvs/fast_transformer/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:291: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n"
     ]
    }
   ],
   "source": [
    "model_roberta_q: PreTrainedModel = QDQRobertaForSequenceClassification.from_pretrained(\"roberta-in-bert-trained-quantized-retrained\", num_labels=num_labels)\n",
    "model_roberta_q = model_roberta_q.cuda()\n",
    "\n",
    "data = encoded_dataset[\"train\"][1: 3]\n",
    "input_torch = {k: torch.tensor(list(v), dtype=torch.long, device=\"cuda\") for k, v in data.items() if k in [\"input_ids\", \"attention_mask\", \"token_type_ids\"]}\n",
    "\n",
    "from pytorch_quantization.nn import TensorQuantizer\n",
    "TensorQuantizer.use_fb_fake_quant = True\n",
    "convert_to_onnx(model_pytorch=model_roberta_q, output_path=\"roberta_q.onnx\", inputs_pytorch=input_torch)\n",
    "TensorQuantizer.use_fb_fake_quant = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latency measures\n",
    "\n",
    "Let's see if what we have done is useful...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorRT baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we export a randomly initialized Roberta model, the purpose is to only check the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = encoded_dataset[\"train\"][1:10]\n",
    "input_torch = {k: torch.tensor(list(v), dtype=torch.long, device=\"cuda\")\n",
    "               for k, v in data.items() if k in [\"input_ids\", \"attention_mask\", \"token_type_ids\"]}\n",
    "\n",
    "baseline_model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels)\n",
    "baseline_model = baseline_model.cuda()\n",
    "convert_to_onnx(baseline_model, output_path=\"baseline.onnx\", inputs_pytorch=input_torch)\n",
    "del baseline_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!/usr/src/tensorrt/bin/trtexec --onnx=baseline.onnx --shapes=input_ids:1x384,attention_mask:1x384 --best --workspace=6000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "whPRbBNbIrIl",
    "n9qywopnIrJH",
    "7k8ge1L1IrJk"
   ],
   "name": "Copie de Text Classification on GLUE",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0022faf286b44e858e638ccd5ded38b0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "023900ca566446eab5905b25b16a3de7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "08286a6371584b4186014ecb5d5f164d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2d3a08166846438db79b0f89314fe76a",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_d1ecc3d380fc4758b03190b23686a2f1",
      "value": " 481/481 [00:00&lt;00:00, 10.9kB/s]"
     }
    },
    "092db03992f24951b494fbb81da5b9d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_994cf2338c7c4899952e25723445693c",
       "IPY_MODEL_6aa2f5d46f1f454198d8e69517549ff1",
       "IPY_MODEL_72b8f11065254e5ca488cd346b5add54"
      ],
      "layout": "IPY_MODEL_023900ca566446eab5905b25b16a3de7"
     }
    },
    "0dab554959dc44b3b313ee8ae91ca88d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e1f08cf954ae4aea818c90d893486c77",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_f01fdef82047471e8c1b780cae5379cc",
      "value": " 420M/420M [00:13&lt;00:00, 33.6MB/s]"
     }
    },
    "10678736bd534c63aebda414da01b4db": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "14648b8262944f5faac134a7c0184e47": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "154200a8bc0b44fe8d0419fd56c6539d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "15aae23369674f82888ed9fbd99739f2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "163146c2f23440bcbf782116a35b5684": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cf9597523c024514b9b3e66bc77e3fa8",
      "max": 440473133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cced5f1cccc2400a8fbfd7a6eaedc666",
      "value": 440473133
     }
    },
    "167874df55014291be95cd390b1e60d3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "17b83e0d0fb947d7bf20319ff930e8fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_854cfd13416543fba8221093b903658b",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_cbbb20b5d01a4450bfb8dfbf8048d64f",
      "value": "Downloading: 100%"
     }
    },
    "17bd5357081d41c6b0161d63bd00820a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "196ffc99ad5a40109d9b1cfe12032b62": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1bea379404df429b9852b62a938661ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a4c444f06c0847c09a44917084d3908d",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_300f01e3547648f3983a83d3d3118c54",
      "value": 1
     }
    },
    "1da1d80871f545bbb21bf5a84d2120a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8585eab4b3fe4992bd7e7c4596e2483b",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7ec6da801d0d45c4bb80eeab5518e124",
      "value": 570
     }
    },
    "21ef195fa88f49c4a2c057f8028177a2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "26bc2038bed74279813ab5af09a2724c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0022faf286b44e858e638ccd5ded38b0",
      "max": 456318,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7ff32d18c9f0473893a6a6b2941c54b0",
      "value": 456318
     }
    },
    "28b7346a9b8c4b198dd9dbea1be013b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2d3a08166846438db79b0f89314fe76a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2eac6b4817e14d7fae396e6458b940fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_927ad6ade85a402594074fa90ab558c2",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_cae29b9c6d45412fab70977fcd0f3234",
      "value": "Downloading: 100%"
     }
    },
    "300f01e3547648f3983a83d3d3118c54": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "30646fa2c0dc494e9dbcbd4dc598410e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "360d6eb0e41543dba6d457912e32a77d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "37cda4cae81a4d94aa831fb40b5c3b26": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_56fd7584b0844590936519ec3851922e",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_5b1ad9f5d02c4b298a02ce6041692057",
      "value": " 4/4 [00:00&lt;00:00,  5.97ba/s]"
     }
    },
    "3bfff454943b4b04a12ec29bbe28e0aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cedca6e55b84443e82f3d01471d61048",
       "IPY_MODEL_a7d355f456eb4d3995dd91c5917a72c1",
       "IPY_MODEL_b264b220d9c444bd9da46a7e6c8fd5ed"
      ],
      "layout": "IPY_MODEL_154200a8bc0b44fe8d0419fd56c6539d"
     }
    },
    "3e7fbd1c0e534cb8abca18d1edfc9277": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4320b12de9d14c459cc88319e2d7622a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4552ee8ca6bd4a0b956651cc23f4ff3c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4b13c3b3435f4689b29d48e0a35bebd6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4e91efae49b64f038fd3fbfcfd2be510": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4fae966b76844c869cdea1e53891e26f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "54c0ad5ab737433190c4a824be128a48": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "561b1ede331a40c1a2bff9422e8eea0e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "56fd7584b0844590936519ec3851922e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "59418bbeb20547e5b5e1a5728262c757": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5b1ad9f5d02c4b298a02ce6041692057": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5e2185bd6e4f4a10b89ac606868a43bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2eac6b4817e14d7fae396e6458b940fa",
       "IPY_MODEL_af16284f77594397a69ad0e322b5e736",
       "IPY_MODEL_a20579a9e7364fb485d79bdc4feb54dc"
      ],
      "layout": "IPY_MODEL_f44d2beebfe44186b0ac8016e89e4b49"
     }
    },
    "5f032f56105f463a8680aa2482d0b162": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "65017db07d7f4e798ede741cc92488f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_86cc326e574a4fada7224e6f0c209e9a",
       "IPY_MODEL_af5b646f89024c139c695a1f058fb772",
       "IPY_MODEL_37cda4cae81a4d94aa831fb40b5c3b26"
      ],
      "layout": "IPY_MODEL_6fa74604c68543a38392fa0e1587f707"
     }
    },
    "68c4c867096d41a78740fdee30edcadb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6aa2f5d46f1f454198d8e69517549ff1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7b483d17d1d14fdd922600f0c906fc2f",
      "max": 1355863,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4320b12de9d14c459cc88319e2d7622a",
      "value": 1355863
     }
    },
    "6d48e5ce9a854a3bb0506d774665f428": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fbdb7c7250d846b2880005a9012c484b",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_17bd5357081d41c6b0161d63bd00820a",
      "value": " 478M/478M [00:15&lt;00:00, 34.7MB/s]"
     }
    },
    "6e54ce781ca54ad283911fa4774e3361": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6e604307427a466cab51d50d363ee86d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6fa74604c68543a38392fa0e1587f707": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "728a9dcc79824e1eb2bfa49d915a8f08": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d314c0bb87e04893b96de0e18766d3ab",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_fa35b3acd9ce4cb098fcd69bb405db00",
      "value": "Downloading: 100%"
     }
    },
    "72b8f11065254e5ca488cd346b5add54": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_10678736bd534c63aebda414da01b4db",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_14648b8262944f5faac134a7c0184e47",
      "value": " 1.29M/1.29M [00:00&lt;00:00, 2.22MB/s]"
     }
    },
    "7701ec898fd443f1b35b187aea3651e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "78601982b0e04b80adaa502db2ef685a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d6426fea2eda41dd9a31cb3f35b0877e",
       "IPY_MODEL_163146c2f23440bcbf782116a35b5684",
       "IPY_MODEL_0dab554959dc44b3b313ee8ae91ca88d"
      ],
      "layout": "IPY_MODEL_167874df55014291be95cd390b1e60d3"
     }
    },
    "788badadfd834f61926a39a43ef1d517": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7a75099f99054645bf3fc1b778dac7e6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7b483d17d1d14fdd922600f0c906fc2f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7bb3b69a2f814e60b0cec253c759a16b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d731cfb34124448bbd8baab3d27b75db",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_cbb3e9bf5d07406d9768a98a6f0b5b64",
      "value": "100%"
     }
    },
    "7c875ecd9cb54405a6c45969bcb4b4c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7d520bdde27742abb42803843721d101": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7ec6da801d0d45c4bb80eeab5518e124": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7ff32d18c9f0473893a6a6b2941c54b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8399339998564d21ba5db6f0514c02c6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "854cfd13416543fba8221093b903658b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8585eab4b3fe4992bd7e7c4596e2483b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "86cc326e574a4fada7224e6f0c209e9a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_561b1ede331a40c1a2bff9422e8eea0e",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_28b7346a9b8c4b198dd9dbea1be013b6",
      "value": "100%"
     }
    },
    "87d85ac2d3104f68b99db880b1089638": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_728a9dcc79824e1eb2bfa49d915a8f08",
       "IPY_MODEL_c815bfd265f4480298c39c76b9eaf770",
       "IPY_MODEL_6d48e5ce9a854a3bb0506d774665f428"
      ],
      "layout": "IPY_MODEL_6e604307427a466cab51d50d363ee86d"
     }
    },
    "8a11c8fed672470b8335dc575a4a220e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_93dbcc6d23a743bab0da8af6ee5e2825",
      "max": 481,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f8a0053903c64e75ac25eab5b24d5871",
      "value": 481
     }
    },
    "8defdddee0e64a20b101e6c50bd7c60b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7bb3b69a2f814e60b0cec253c759a16b",
       "IPY_MODEL_d25cca081db3469b80163d6707f5a37d",
       "IPY_MODEL_f8abc3e44ae3428885aafbea2b37384c"
      ],
      "layout": "IPY_MODEL_f485d2b19ffa4585a1da20986f28af29"
     }
    },
    "927ad6ade85a402594074fa90ab558c2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "93dbcc6d23a743bab0da8af6ee5e2825": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "969b6fdac1d6418d89a683db1e6ec6b2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "990482eebca2424bb5ecbd114007e02c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "994cf2338c7c4899952e25723445693c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d9a0852554284d36b6b121f579b06b41",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_c7bd52ef524c4d279dfcaa3aebe4a2c5",
      "value": "Downloading: 100%"
     }
    },
    "99e94791043b4499b06601f7524f9b14": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d5c8ff9e3bd849059fa7b30eab5fc940",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_196ffc99ad5a40109d9b1cfe12032b62",
      "value": "Downloading: 100%"
     }
    },
    "9bc6e14b912249e3b7d02f31bcc74667": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_969b6fdac1d6418d89a683db1e6ec6b2",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_6e54ce781ca54ad283911fa4774e3361",
      "value": " 446k/446k [00:00&lt;00:00, 650kB/s]"
     }
    },
    "a02624219ee84f50b1a3032eaa030a39": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a0a2918e9772475cac51124b3b83fcaf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a20579a9e7364fb485d79bdc4feb54dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4b13c3b3435f4689b29d48e0a35bebd6",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_d5d015711ae04d2f801577fc50af6c15",
      "value": " 878k/878k [00:00&lt;00:00, 1.33MB/s]"
     }
    },
    "a3e2c73d393d4e58a371f3da3dd80e6d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a4c444f06c0847c09a44917084d3908d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a51b461c062f4636bfa4b48823d0709b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a61d366d91c34697a55f62b754e1f3a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a9b98fd93fcd4fc4a2b2aa88c82835d0",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_b8722dc10d4447fe9630cbf169260cc8",
      "value": "100%"
     }
    },
    "a7d355f456eb4d3995dd91c5917a72c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5f032f56105f463a8680aa2482d0b162",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a02624219ee84f50b1a3032eaa030a39",
      "value": 2
     }
    },
    "a9b98fd93fcd4fc4a2b2aa88c82835d0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ac14ba24dcf3404db9fd303dbb24d7a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_17b83e0d0fb947d7bf20319ff930e8fc",
       "IPY_MODEL_1da1d80871f545bbb21bf5a84d2120a0",
       "IPY_MODEL_c593f2e45e244637821cc5721788bf2c"
      ],
      "layout": "IPY_MODEL_4e91efae49b64f038fd3fbfcfd2be510"
     }
    },
    "aecf7f063234416abf3f24766481cb89": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "af16284f77594397a69ad0e322b5e736": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7a75099f99054645bf3fc1b778dac7e6",
      "max": 898823,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_30646fa2c0dc494e9dbcbd4dc598410e",
      "value": 898823
     }
    },
    "af5b646f89024c139c695a1f058fb772": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_21ef195fa88f49c4a2c057f8028177a2",
      "max": 4,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_aecf7f063234416abf3f24766481cb89",
      "value": 4
     }
    },
    "b264b220d9c444bd9da46a7e6c8fd5ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8399339998564d21ba5db6f0514c02c6",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_7701ec898fd443f1b35b187aea3651e9",
      "value": " 2/2 [00:00&lt;00:00,  6.46ba/s]"
     }
    },
    "b4d3f284fc4c4061b58d43a738f9bc78": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7d520bdde27742abb42803843721d101",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_68c4c867096d41a78740fdee30edcadb",
      "value": "Downloading: 100%"
     }
    },
    "b6be028de2ae4ff691538eedb33793af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b4d3f284fc4c4061b58d43a738f9bc78",
       "IPY_MODEL_8a11c8fed672470b8335dc575a4a220e",
       "IPY_MODEL_08286a6371584b4186014ecb5d5f164d"
      ],
      "layout": "IPY_MODEL_a3e2c73d393d4e58a371f3da3dd80e6d"
     }
    },
    "b8722dc10d4447fe9630cbf169260cc8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bbe3a471efb04ea8b5aabc4be819d585": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a61d366d91c34697a55f62b754e1f3a5",
       "IPY_MODEL_1bea379404df429b9852b62a938661ae",
       "IPY_MODEL_c801e1727de44b67aa7cb1c3d970e1fe"
      ],
      "layout": "IPY_MODEL_59418bbeb20547e5b5e1a5728262c757"
     }
    },
    "be4affe852b348de8fe1362582b08da9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_99e94791043b4499b06601f7524f9b14",
       "IPY_MODEL_26bc2038bed74279813ab5af09a2724c",
       "IPY_MODEL_9bc6e14b912249e3b7d02f31bcc74667"
      ],
      "layout": "IPY_MODEL_c6c100b71f26405fb960598feb5eee03"
     }
    },
    "c593f2e45e244637821cc5721788bf2c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c92a19dfa84142af91522bc22f21fca6",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_990482eebca2424bb5ecbd114007e02c",
      "value": " 570/570 [00:00&lt;00:00, 13.1kB/s]"
     }
    },
    "c6c100b71f26405fb960598feb5eee03": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c7bd52ef524c4d279dfcaa3aebe4a2c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c801e1727de44b67aa7cb1c3d970e1fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4552ee8ca6bd4a0b956651cc23f4ff3c",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_7c875ecd9cb54405a6c45969bcb4b4c6",
      "value": " 1/1 [00:00&lt;00:00,  7.22ba/s]"
     }
    },
    "c815bfd265f4480298c39c76b9eaf770": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_15aae23369674f82888ed9fbd99739f2",
      "max": 501200538,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3e7fbd1c0e534cb8abca18d1edfc9277",
      "value": 501200538
     }
    },
    "c92a19dfa84142af91522bc22f21fca6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cae29b9c6d45412fab70977fcd0f3234": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cbb3e9bf5d07406d9768a98a6f0b5b64": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cbbb20b5d01a4450bfb8dfbf8048d64f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cced5f1cccc2400a8fbfd7a6eaedc666": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cedca6e55b84443e82f3d01471d61048": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a0a2918e9772475cac51124b3b83fcaf",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_4fae966b76844c869cdea1e53891e26f",
      "value": "100%"
     }
    },
    "cf9597523c024514b9b3e66bc77e3fa8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d1ecc3d380fc4758b03190b23686a2f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d25cca081db3469b80163d6707f5a37d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_360d6eb0e41543dba6d457912e32a77d",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_788badadfd834f61926a39a43ef1d517",
      "value": 3
     }
    },
    "d314c0bb87e04893b96de0e18766d3ab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d5c8ff9e3bd849059fa7b30eab5fc940": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d5d015711ae04d2f801577fc50af6c15": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d6426fea2eda41dd9a31cb3f35b0877e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a51b461c062f4636bfa4b48823d0709b",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_f651eecbb6d44c24820cf6fe5ab92e7b",
      "value": "Downloading: 100%"
     }
    },
    "d731cfb34124448bbd8baab3d27b75db": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d9a0852554284d36b6b121f579b06b41": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e1f08cf954ae4aea818c90d893486c77": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f01fdef82047471e8c1b780cae5379cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f237ed04039945e9aa224d1b9d04e1b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f44d2beebfe44186b0ac8016e89e4b49": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f485d2b19ffa4585a1da20986f28af29": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f651eecbb6d44c24820cf6fe5ab92e7b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f8a0053903c64e75ac25eab5b24d5871": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f8abc3e44ae3428885aafbea2b37384c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_54c0ad5ab737433190c4a824be128a48",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_f237ed04039945e9aa224d1b9d04e1b5",
      "value": " 3/3 [00:00&lt;00:00, 52.79it/s]"
     }
    },
    "fa35b3acd9ce4cb098fcd69bb405db00": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fbdb7c7250d846b2880005a9012c484b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}