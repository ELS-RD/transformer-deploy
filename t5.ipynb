{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from time import time\n",
    "from typing import Callable, Dict, Set\n",
    "\n",
    "import numpy as np\n",
    "import onnx\n",
    "import tensorrt as trt\n",
    "import torch\n",
    "from onnx import ModelProto\n",
    "from tensorrt import ICudaEngine\n",
    "from tensorrt.tensorrt import Logger, Runtime\n",
    "from torch.nn import Linear\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, PretrainedConfig, T5ForConditionalGeneration, TensorType\n",
    "from transformers.generation_utils import GenerationMixin\n",
    "from transformers.modeling_outputs import BaseModelOutputWithPastAndCrossAttentions, Seq2SeqLMOutput\n",
    "from transformers.models.t5.modeling_t5 import T5Stack\n",
    "\n",
    "from transformer_deploy.backends.ort_utils import create_model_for_provider, inference_onnx_binding, optimize_onnx\n",
    "from transformer_deploy.backends.pytorch_utils import convert_to_onnx\n",
    "from transformer_deploy.backends.trt_utils import (\n",
    "    TensorRTShape,\n",
    "    add_output_nodes,\n",
    "    build_engine,\n",
    "    get_adjency_dict,\n",
    "    get_fix_fp16_network_func,\n",
    "    get_list_fp32_nodes,\n",
    "    load_engine,\n",
    "    save_engine,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "model_name = \"t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "input_ids: torch.Tensor = tokenizer(\"Studies show that\", return_tensors=TensorType.PYTORCH).input_ids\n",
    "input_ids = input_ids.to(\"cuda\")\n",
    "model: T5ForConditionalGeneration = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "model = model.eval()\n",
    "model = model.to(\"cuda\")\n",
    "out_enc: BaseModelOutputWithPastAndCrossAttentions = model.encoder(input_ids=input_ids)\n",
    "out_full: Seq2SeqLMOutput = model(input_ids=input_ids, decoder_input_ids=input_ids)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/geantvert/.local/share/virtualenvs/fast_transformer/lib/python3.9/site-packages/transformers/modeling_utils.py:529: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if causal_mask.shape[1] < attention_mask.shape[1]:\n"
     ]
    }
   ],
   "source": [
    "class ExportT5(torch.nn.Module):\n",
    "    def __init__(self, decoder: T5Stack, lm_head: Linear):\n",
    "        super(ExportT5, self).__init__()\n",
    "        self.decoder = decoder\n",
    "        self.lm_head = lm_head\n",
    "\n",
    "    def forward(self, input_ids: torch.Tensor, encoder_hidden_states: torch.Tensor):\n",
    "        out_dec = self.decoder.forward(input_ids=input_ids, encoder_hidden_states=encoder_hidden_states)\n",
    "        # Rescale output before projecting on vocab\n",
    "        out_dec = out_dec[\"last_hidden_state\"] * (model.model_dim**-0.5)\n",
    "        out_lm = self.lm_head(out_dec)\n",
    "        return out_lm\n",
    "\n",
    "model = model.to(\"cuda\")\n",
    "\n",
    "convert_to_onnx(\n",
    "    model_pytorch=model.encoder,\n",
    "    output_path=\"test-enc.onnx\",\n",
    "    inputs_pytorch={\"input_ids\": input_ids},\n",
    "    var_output_seq=True,\n",
    "    quantization=False,\n",
    ")\n",
    "optimize_onnx(\n",
    "    onnx_path=\"test-enc.onnx\", onnx_optim_model_path=\"test-enc-opt.onnx\", architecture=\"bert\", use_cuda=True, fp16=True\n",
    ")\n",
    "\n",
    "enc_onnx = create_model_for_provider(\"test-enc-opt.onnx\", \"CUDAExecutionProvider\")\n",
    "enc_onnx_out = inference_onnx_binding(\n",
    "    model_onnx=enc_onnx,\n",
    "    inputs={\"input_ids\": input_ids},\n",
    "    device=input_ids.device.type,\n",
    "    output_shape=tuple(input_ids.shape) + (int(model.encoder.config.d_model),),\n",
    ")[\"output\"]\n",
    "assert np.allclose(enc_onnx_out.detach().cpu().numpy(), out_enc.last_hidden_state.detach().cpu().numpy(), atol=1e-2)\n",
    "\n",
    "model_to_export = ExportT5(decoder=model.decoder, lm_head=model.lm_head).eval()\n",
    "out_model_export: torch.Tensor = model_to_export(input_ids=input_ids, encoder_hidden_states=out_enc.last_hidden_state)\n",
    "assert np.allclose(out_model_export.detach().cpu().numpy(), out_full.logits.detach().cpu().numpy(), atol=1e-5)\n",
    "\n",
    "inputs_onnx = {\"input_ids\": input_ids, \"encoder_hidden_states\": out_enc.last_hidden_state}\n",
    "\n",
    "convert_to_onnx(\n",
    "    model_pytorch=model_to_export,\n",
    "    output_path=\"test-dec.onnx\",\n",
    "    inputs_pytorch=inputs_onnx,\n",
    "    var_output_seq=False,\n",
    "    quantization=False,\n",
    "    fix_output_dim_size=False,  # specific to decoder part\n",
    ")\n",
    "optimize_onnx(\n",
    "    onnx_path=\"test-dec.onnx\",\n",
    "    onnx_optim_model_path=\"test-dec-opt.onnx\",\n",
    "    architecture=\"bert\",\n",
    "    use_cuda=True,\n",
    "    fp16=True,\n",
    "    num_attention_heads=model.config.num_heads,\n",
    "    hidden_size=model.config.d_model,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> Studien studies show that</s>\n",
      "<pad> Studien studies show that</s>\n",
      "11.085162878036499\n",
      "14.284526824951172\n"
     ]
    }
   ],
   "source": [
    "model = model.to(\"cuda\")\n",
    "enc_onnx = create_model_for_provider(\"test-enc-opt.onnx\", \"CUDAExecutionProvider\")\n",
    "dec_onnx = create_model_for_provider(\"test-dec-opt.onnx\", \"CUDAExecutionProvider\")\n",
    "\n",
    "\n",
    "def decoder_pytorch_inference(input_ids: torch.Tensor, last_hidden_state: torch.Tensor):\n",
    "    out_dec = model.decoder(input_ids=input_ids, encoder_hidden_states=last_hidden_state)[\"last_hidden_state\"]\n",
    "    # Rescale output before projecting on vocab\n",
    "    out_dec = out_dec * (model.model_dim**-0.5)\n",
    "    out_lm = model.lm_head(out_dec)\n",
    "    return out_lm\n",
    "\n",
    "\n",
    "def decoder_onnx_inference(input_ids: torch.Tensor, last_hidden_state: torch.Tensor):\n",
    "    result_dict = inference_onnx_binding(\n",
    "        model_onnx=dec_onnx,\n",
    "        inputs={\"input_ids\": input_ids, \"encoder_hidden_states\": last_hidden_state},\n",
    "        device=input_ids.device.type,\n",
    "        output_shape=tuple(input_ids.shape) + (int(model.config.vocab_size),),\n",
    "    )\n",
    "    return result_dict[\"output\"]\n",
    "\n",
    "\n",
    "def decoder_onnx_standard_inference(input_ids: torch.Tensor, last_hidden_state: torch.Tensor):\n",
    "    result_list = dec_onnx.run(\n",
    "        None, {\"input_ids\": input_ids.type(torch.int32).numpy(), \"encoder_hidden_states\": last_hidden_state.numpy()}\n",
    "    )\n",
    "    return torch.from_numpy(result_list[0])\n",
    "\n",
    "\n",
    "dec_onnx_out = decoder_onnx_inference(input_ids=input_ids, last_hidden_state=out_enc.last_hidden_state)\n",
    "assert np.allclose(dec_onnx_out.detach().cpu().numpy(), out_full.logits.detach().cpu().numpy(), atol=1e-1)\n",
    "\n",
    "\n",
    "def encoder_onnx_inference(input_ids: torch.Tensor, **_) -> BaseModelOutputWithPastAndCrossAttentions:\n",
    "    result = inference_onnx_binding(\n",
    "        model_onnx=enc_onnx,  # noqa: F821\n",
    "        inputs={\"input_ids\": input_ids},\n",
    "        output_shape=tuple(input_ids.shape) + (int(model.encoder.config.d_model),),\n",
    "        device=input_ids.device.type,\n",
    "    )\n",
    "    return BaseModelOutputWithPastAndCrossAttentions(last_hidden_state=result[\"output\"])\n",
    "\n",
    "\n",
    "def encoder_pytorch_inference(input_ids, **_) -> BaseModelOutputWithPastAndCrossAttentions:\n",
    "    return model.encoder(input_ids=input_ids)\n",
    "\n",
    "\n",
    "# https://github.com/NVIDIA/TensorRT/blob/main/demo/HuggingFace/T5/export.py\n",
    "class ExtT5(torch.nn.Module, GenerationMixin):\n",
    "    def __init__(self, config: PretrainedConfig, device: torch.device, encoder_func: Callable, decoder_func: Callable):\n",
    "        super(ExtT5, self).__init__()\n",
    "        self.main_input_name = \"input_ids\"  # https://github.com/huggingface/transformers/pull/14803\n",
    "        self.config: PretrainedConfig = config\n",
    "        self.device: torch.device = device\n",
    "\n",
    "        self.encoder_func = encoder_func\n",
    "        self.decoder_func = decoder_func\n",
    "\n",
    "    def get_encoder(self):\n",
    "        return self.encoder_func\n",
    "\n",
    "    def get_decoder(self):\n",
    "        return self.decoder_func\n",
    "\n",
    "    def prepare_inputs_for_generation(self, input_ids, **kwargs):\n",
    "        return {\n",
    "            self.main_input_name: input_ids,\n",
    "            \"encoder_hidden_states\": kwargs[\"encoder_outputs\"][\"last_hidden_state\"],\n",
    "        }\n",
    "\n",
    "    def forward(self, input_ids: torch.Tensor, encoder_hidden_states: torch.Tensor, **_):\n",
    "        dec_output = self.get_decoder()(input_ids=input_ids, last_hidden_state=encoder_hidden_states)\n",
    "        return Seq2SeqLMOutput(logits=dec_output)\n",
    "\n",
    "\n",
    "model_gen = (\n",
    "    ExtT5(\n",
    "        config=model.config,\n",
    "        device=model.device,\n",
    "        encoder_func=encoder_onnx_inference,  # encoder_pytorch_inference\n",
    "        decoder_func=decoder_onnx_inference,  # decoder_pytorch_inference\n",
    "    )\n",
    "    .cuda()\n",
    "    .eval()\n",
    ")\n",
    "\n",
    "# model = model.eval()\n",
    "with torch.inference_mode():\n",
    "    out_enc: BaseModelOutputWithPastAndCrossAttentions = model.encoder(input_ids=input_ids)\n",
    "    a = model_gen(input_ids=input_ids, encoder_hidden_states=out_enc.last_hidden_state).logits\n",
    "    b = model(input_ids=input_ids, decoder_input_ids=input_ids).logits\n",
    "    assert np.allclose(a.detach().cpu().numpy(), b.detach().cpu().numpy(), atol=1e-1)\n",
    "\n",
    "    print(\n",
    "        tokenizer.decode(\n",
    "            model_gen.generate(inputs=input_ids, max_length=20, num_beams=7, no_repeat_ngram_size=2)[0],\n",
    "            skip_special_tokens=False,\n",
    "        )\n",
    "    )\n",
    "    print(\n",
    "        tokenizer.decode(\n",
    "            model.generate(inputs=input_ids, max_length=20, num_beams=7, no_repeat_ngram_size=2)[0],\n",
    "            skip_special_tokens=False,\n",
    "        )\n",
    "    )\n",
    "\n",
    "start = time()\n",
    "for _ in range(3):\n",
    "    model_gen.generate(inputs=input_ids, max_length=500, num_beams=5, no_repeat_ngram_size=2, min_length=500)\n",
    "print(time() - start)\n",
    "\n",
    "model.config.use_cache = True\n",
    "with torch.inference_mode():\n",
    "    start = time()\n",
    "    for _ in range(3):\n",
    "        model.generate(inputs=input_ids, max_length=500, num_beams=5, no_repeat_ngram_size=2, min_length=500)\n",
    "    print(time() - start)\n",
    "\n",
    "model = model.cpu()\n",
    "del enc_onnx\n",
    "del dec_onnx\n",
    "\n",
    "trt_logger: Logger = trt.Logger(trt.Logger.ERROR)\n",
    "runtime: Runtime = trt.Runtime(trt_logger)\n",
    "trt_model_name = \"trt-t5-dec.plan\"\n",
    "\n",
    "# create only of does not exist because it's slow to run...\n",
    "\n",
    "# 768 for base model, 512 for small, make it dependent from the Pytorch model configuration\n",
    "input_id_shape = TensorRTShape(min_shape=[5, 1], optimal_shape=[5, 500], max_shape=[5, 500], input_name=\"input_ids\")\n",
    "encoder_hidden_states_shape = TensorRTShape(\n",
    "    min_shape=[5, 1, 512], optimal_shape=[5, 500 // 2, 512], max_shape=[5, 500, 512], input_name=\"encoder_hidden_states\"\n",
    ")\n",
    "\n",
    "\n",
    "model = model.cuda()\n",
    "model_onnx: ModelProto = onnx.load(\"test-dec.onnx\")\n",
    "model_onnx_all_nodes = add_output_nodes(model=model_onnx)\n",
    "onnx_graph: Dict[str, Set[str]] = get_adjency_dict(model=model_onnx)\n",
    "ort_model_all_nodes = create_model_for_provider(model_onnx_all_nodes.SerializeToString(), \"CUDAExecutionProvider\")\n",
    "\n",
    "\n",
    "# use info from tokenizer size and max shape provided through the command line\n",
    "def get_random_input():\n",
    "    input = torch.randint(high=tokenizer.vocab_size, size=(5, 500), dtype=torch.int32, device=\"cuda\")\n",
    "    hidden_state = model.encoder(input_ids=input).last_hidden_state.detach().cpu().numpy()\n",
    "    return {\"input_ids\": input.detach().cpu().numpy(), \"encoder_hidden_states\": hidden_state}\n",
    "\n",
    "\n",
    "keep_fp32 = get_list_fp32_nodes(\n",
    "    onnx_graph=onnx_graph, model=ort_model_all_nodes, get_input=get_random_input, nb_try=200\n",
    ")\n",
    "model = model.cpu()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-48.0803, -14.2901, -20.4682,  ..., -67.6375, -67.8819, -67.8281],\n",
      "        [-54.2086, -14.2957, -21.5224,  ..., -66.5668, -66.9079, -66.7077],\n",
      "        [-35.6367,  -5.6427, -15.6152,  ..., -49.5692, -49.8774, -49.7235],\n",
      "        [-31.3282,  -3.7932, -11.2617,  ..., -43.0694, -43.3203, -43.1963]],\n",
      "       device='cuda:0')\n",
      "1.4864044189453125\n",
      "0.6534547805786133\n",
      "1.1358990669250488\n"
     ]
    }
   ],
   "source": [
    "engine: ICudaEngine = build_engine(\n",
    "    runtime=runtime,\n",
    "    onnx_file_path=\"test-dec.onnx\",\n",
    "    logger=trt_logger,\n",
    "    workspace_size=20000 * 1024**2,\n",
    "    fp16=True,\n",
    "    int8=False,\n",
    "    input_shapes=[input_id_shape, encoder_hidden_states_shape],\n",
    "    fp16_fix=get_fix_fp16_network_func(keep_fp32=keep_fp32),\n",
    ")\n",
    "save_engine(engine, trt_model_name)\n",
    "\n",
    "tensorrt_model = load_engine(runtime=runtime, engine_file_path=trt_model_name)\n",
    "a = tensorrt_model(\n",
    "    {\n",
    "        \"input_ids\": input_ids.type(torch.int32).repeat((5, 1)),\n",
    "        \"encoder_hidden_states\": out_enc.last_hidden_state.repeat((5, 1, 1)),\n",
    "    }\n",
    ")\n",
    "print(a[0])\n",
    "\n",
    "benchmark_input = torch.ones((5, 500), dtype=torch.int32, device=\"cuda\")\n",
    "benchmark_enc_output = out_enc.last_hidden_state.repeat((5, 1, 1))\n",
    "for _ in range(10):\n",
    "    tensorrt_model(\n",
    "        {\n",
    "            \"input_ids\": benchmark_input,\n",
    "            \"encoder_hidden_states\": benchmark_enc_output,\n",
    "        }\n",
    "    )\n",
    "start = time()\n",
    "for _ in range(100):\n",
    "    tensorrt_model(\n",
    "        {\n",
    "            \"input_ids\": benchmark_input,\n",
    "            \"encoder_hidden_states\": benchmark_enc_output,\n",
    "        }\n",
    "    )\n",
    "print(time() - start)\n",
    "\n",
    "dec_onnx = create_model_for_provider(\"test-dec-opt.onnx\", \"CUDAExecutionProvider\")\n",
    "dec_onnx_out = decoder_onnx_inference(input_ids=input_ids, last_hidden_state=out_enc.last_hidden_state)\n",
    "\n",
    "\n",
    "for _ in range(10):\n",
    "    decoder_onnx_inference(input_ids=benchmark_input, last_hidden_state=benchmark_enc_output)\n",
    "start = time()\n",
    "for _ in range(100):\n",
    "    decoder_onnx_inference(input_ids=benchmark_input, last_hidden_state=benchmark_enc_output)\n",
    "print(time() - start)\n",
    "\n",
    "model.cuda()\n",
    "for _ in range(10):\n",
    "    model.decoder(input_ids=benchmark_input, encoder_hidden_states=benchmark_enc_output)\n",
    "start = time()\n",
    "for _ in range(100):\n",
    "    model.decoder(input_ids=benchmark_input, encoder_hidden_states=benchmark_enc_output)\n",
    "print(time() - start)\n",
    "\n",
    "# TensorRT, ONNX Runtime, Pytorch\n",
    "\n",
    "# sequence 500\n",
    "# 0.8640644550323486\n",
    "# 0.6695075035095215\n",
    "# 1.1308434009552002\n",
    "\n",
    "# sequence 250\n",
    "# 0.9177014827728271\n",
    "# 0.6861860752105713\n",
    "# 1.1923034191131592"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 2.7558e-02,  1.5035e-01, -1.0642e-01,  1.3436e-01, -2.7034e-03,\n          1.0121e-01, -3.7072e-02, -1.1961e-01,  4.2827e-01, -6.8828e-02,\n          4.7860e-03,  1.0388e-01, -1.9117e-01, -9.1395e-02,  8.0236e-01,\n         -2.9004e-02, -8.3236e-03, -4.1821e-02,  5.1209e-02, -8.1611e-02,\n          5.2725e-02,  7.5980e-02, -8.5656e-02,  2.2240e+00,  4.7778e-02,\n         -7.0944e-02, -3.6483e-02,  2.8398e-01, -3.3781e-02, -1.3103e-01,\n          4.6392e-02, -4.0270e-02, -5.6167e-02, -1.5688e-02,  4.1200e-01,\n         -3.9407e-02, -1.1113e-01, -7.7969e-02, -1.3417e-01,  1.9564e-01,\n         -4.9984e-02, -5.9329e-02,  2.2479e-01,  7.3668e-02, -5.7873e-02,\n          1.4900e-02, -6.9493e-01,  1.7280e-02,  1.0609e-01,  9.2358e-02,\n         -1.3377e-01, -5.1072e-02, -8.8388e-02,  1.4478e-01, -1.1261e-01,\n          4.1928e-03,  5.3930e-02, -7.4811e-02,  5.8460e-02,  2.1837e-02,\n          8.2831e-02,  9.2348e-02, -2.5649e-02, -8.6028e-02, -1.2986e-02,\n         -4.3584e-02, -4.8884e-02, -3.3386e-02,  5.5349e-01,  1.8710e-01,\n         -3.0446e-02,  5.1245e-02,  5.5034e-02, -5.5080e-02, -1.7116e-03,\n          9.5299e-02, -4.5908e-02, -1.2584e-02,  8.4189e-02,  2.0390e-01,\n         -2.0322e-01,  8.3806e-02,  5.3210e-02, -8.4752e-02, -4.7789e-02,\n         -1.1201e-01, -2.8879e-02, -3.3881e-02, -1.7329e-01,  6.1102e-01,\n         -1.2889e-02, -9.4040e-02,  8.2499e-02, -7.6344e-02, -8.5806e-02,\n          2.5688e-02, -1.5681e-02, -1.1451e-02,  6.4907e-03, -2.3519e-02,\n          3.4917e-02, -5.8727e-02,  1.3254e-02,  1.5825e-01,  4.7590e-02,\n          1.0409e-01,  6.9138e-02,  3.9837e-02, -3.2700e-02, -9.1413e-02,\n         -1.0145e-01,  1.4211e-03, -4.9003e-03,  7.6215e-02, -7.3899e-02,\n         -8.5377e-02,  2.2540e-02, -4.9561e-02,  3.2881e-02, -2.2287e-02,\n         -6.8049e-02, -2.0162e-02,  1.6643e-02,  2.7118e-04, -2.5598e-02,\n          4.4508e-01, -9.3383e-02,  3.1402e-02, -1.0722e-01, -7.8249e-02,\n          2.4561e-02,  1.1590e-02, -6.1977e-02, -8.2639e-03, -4.8054e-02,\n          2.7819e-02, -5.3643e-02,  6.1974e-01, -8.0894e-02,  1.1800e-02,\n         -3.8681e-02, -9.5972e-02,  8.1281e-02, -6.7938e-02,  5.6997e-02,\n          6.1085e-02,  9.6156e-02,  2.4264e-02,  1.5556e-02, -3.0101e+00,\n          1.2210e-01, -1.4733e-02,  8.8266e-02, -1.0615e-02,  9.5372e-02,\n          3.4785e-02, -4.5652e-02,  3.7928e-02,  7.2694e-02, -6.9918e+00,\n         -9.0426e-02,  5.7168e-02,  9.9028e-02,  4.6014e-02, -1.1359e-01,\n         -1.3036e-01,  1.4493e-01,  3.3658e-01, -5.2206e-02,  4.0246e-02,\n          2.0170e-02, -5.1977e-02,  4.4187e-02, -7.7361e-02,  1.9363e-02,\n          6.2262e-02, -6.1391e-02,  1.8870e-03, -3.3080e-02,  2.0343e-03,\n          3.4712e-02,  4.9128e-02,  2.6168e-03,  6.7538e-02, -3.0646e-01,\n         -1.0470e-01,  8.9288e-02,  1.2655e-01, -9.8930e-02, -2.5814e-02,\n         -1.1663e+00, -2.1569e-01,  3.9756e-03, -5.4395e-02,  4.2298e-03,\n         -1.4125e-02, -7.4977e-03, -6.1164e-02,  1.7089e-02, -6.3246e-02,\n         -3.2219e-02, -4.2473e-02, -3.9572e-02, -3.2147e-02, -7.0602e-02,\n          1.7271e-03,  3.1442e-02, -5.3144e-02, -4.6806e-02, -7.4991e-02,\n          1.7826e-02,  3.7886e-02, -5.9538e-02, -1.5893e-01, -6.2725e-02,\n         -2.4954e-02, -1.1495e-02, -5.6767e-02,  1.7637e-02, -5.2201e-02,\n         -3.3890e-02,  1.0832e-01, -3.6066e-02, -1.4835e-01,  7.2391e-03,\n          1.9350e-02, -2.5393e-01,  4.7064e-02, -1.2885e-01, -5.2605e-02,\n          3.4596e-02, -3.2223e-02,  2.3422e-02,  7.2860e-02, -2.5571e-01,\n         -6.5474e-02,  1.2896e-01,  8.3955e-02, -9.2654e-02,  7.1887e-02,\n          2.8062e-01,  4.2431e-02,  2.2218e-02,  4.0215e-02, -1.6136e-01,\n          9.2229e-01,  8.5288e-02,  4.6689e-04, -6.1003e-01,  4.4943e-02,\n          5.1845e-02,  1.8363e-02,  5.8040e-02, -6.6558e-02, -1.2740e-02,\n         -4.8374e-02, -7.0576e-03, -7.4274e-02, -2.5041e-01,  9.4789e-02,\n         -2.0065e-02,  5.5635e-03,  1.0549e-01,  6.3857e-01, -1.2988e-02,\n          6.1025e-02, -9.9692e-02,  8.6344e-02,  5.2507e-03, -8.4472e-02,\n          6.4332e-02, -3.9105e-02,  2.0621e-01,  5.0989e-01,  6.3143e-02,\n         -2.0267e-02, -4.0145e-02,  6.0277e-03, -5.9656e-02, -1.2237e-01,\n         -4.2363e-01,  3.2023e-02, -3.3462e-02, -5.3224e-03,  6.4035e-02,\n         -2.4841e-02,  7.4523e-02,  4.0785e-02,  5.0653e-02,  1.5206e-02,\n         -2.3787e-01,  4.2905e-04,  5.5600e-02,  1.7442e-01, -2.0597e+00,\n          2.2187e-01, -8.1337e-02, -3.3713e-02,  1.3336e-02,  3.6996e-02,\n          7.0871e-02,  1.7253e-02,  6.7578e-02,  1.5223e-02, -4.0918e-02,\n          4.6613e-02, -1.5509e-01, -3.2361e-01,  4.6950e-01, -9.7088e-02,\n         -2.0382e-02,  1.8947e-01, -7.4724e-01,  1.4031e-01, -9.4198e-02,\n         -5.9677e-02,  3.4392e-02,  4.5680e-02, -2.0871e-01, -6.9111e-02,\n         -1.0838e-01, -1.4020e-01, -9.6648e-02, -2.4828e-01, -2.9278e+00,\n          4.8934e-02,  7.4296e-02,  6.2194e-02,  1.5646e-02,  8.0211e-02,\n          8.4065e-02, -8.2835e-02, -1.4783e-01,  6.2116e-02,  6.1863e-03,\n         -8.3127e-02, -1.6525e-01, -4.2172e-02, -8.7703e-02, -1.0587e-01,\n          6.6061e-02, -1.2229e-01, -6.8209e-03,  1.3168e-01, -1.0773e-02,\n         -1.7031e-01,  2.6722e-02, -3.8696e-02,  7.6689e-02, -5.8725e-02,\n          1.9595e-01, -1.2188e-02,  5.9784e-02,  5.0740e-02,  2.5466e-02,\n         -2.7911e-01, -1.2255e-01,  2.8395e-02,  3.9120e-02,  1.3815e-01,\n         -9.5946e-02,  1.9945e-02,  6.0094e-02, -1.4042e-01, -5.9581e-02,\n         -1.0952e-01, -7.3304e-02, -3.3756e-01, -1.6652e-03,  8.1181e-04,\n          6.8361e-02,  1.6927e-01, -6.6210e-02,  1.1466e-02, -3.0490e-01,\n         -1.2575e-01,  8.7528e-03, -8.2843e-02,  3.2838e-03, -2.1481e-01,\n          4.4152e-02, -1.1502e+00, -2.0167e-01, -2.2349e-02,  1.5185e-01,\n          5.1614e-02,  1.1127e-01,  2.4280e-02, -2.7464e-01, -8.6794e-03,\n          1.2796e-02,  2.3091e-02, -1.4170e-01,  1.2471e-02, -6.3778e-02,\n         -1.0977e-01,  4.8351e-02,  7.4095e-02,  5.8914e-02,  7.7498e-02,\n          2.7251e-01,  1.8195e-01,  7.3700e-02, -1.1701e-01, -5.5508e-02,\n          2.0029e-02, -5.6784e-02, -3.5544e-02, -1.6008e-02,  4.2423e-02,\n          2.4862e-01, -1.2843e-01, -9.1526e-02, -9.2777e-02, -1.5552e-02,\n          2.1962e-02,  5.6796e-02,  3.9258e-01,  1.6204e-02,  2.8135e-02,\n          5.0101e-02, -1.0456e-01, -8.2916e-02,  2.7435e-02, -1.5171e-01,\n         -7.9315e-02,  3.0147e-02, -1.7285e-02, -1.2829e-01,  2.7650e-02,\n          5.3211e-02, -5.4338e-02,  1.0162e-01, -1.9675e-02, -9.0279e-02,\n         -4.6922e-02,  1.6096e-03,  1.9443e-02,  3.8715e-02, -4.2711e-02,\n         -7.7991e-02,  4.1426e-02,  8.2201e-03,  1.5081e-01,  3.3575e-03,\n         -2.2131e-02,  3.8794e-03, -1.0341e-01, -1.3226e-01,  9.7978e-04,\n          8.5674e-02, -6.0801e-02, -5.3318e-02, -1.8344e-01,  4.9798e-02,\n          2.9513e-02,  5.8625e-02, -1.1644e-02,  5.6686e-02, -2.3213e-02,\n          5.9430e-02,  3.0600e-02, -7.0081e-02, -9.4119e-02,  1.2767e-01,\n         -9.1701e-02,  5.3907e-02,  1.4844e-01,  5.5191e-02, -4.8491e-02,\n         -7.4864e-02, -4.8856e-03, -1.1108e-01,  2.9740e-02, -1.3206e-01,\n         -1.0341e-01, -5.5583e-02, -3.4414e-01, -9.1679e-03, -3.5313e-02,\n         -1.3231e-01,  4.7432e-02,  8.9266e-02, -1.2552e-01,  5.9633e-02,\n         -5.4128e-02, -9.0885e-03, -1.9906e-01, -4.2343e-03, -8.0676e-03,\n          1.4961e-03, -7.9238e-02,  6.1884e-02,  4.9478e-02, -7.5517e-02,\n          1.7999e-02,  8.1206e-02, -1.8421e-01, -6.5564e-02, -6.8393e-02,\n         -2.1154e-01, -7.4016e-01, -3.8952e-02,  1.1902e-01,  3.7813e-02,\n         -1.3577e-01, -1.5776e-01, -1.4139e-02,  4.6991e-02,  6.5095e-02,\n          3.4050e-04,  5.8639e-02]], device='cuda:0', grad_fn=<SliceBackward0>)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_enc: BaseModelOutputWithPastAndCrossAttentions = model.encoder(input_ids=input_ids)\n",
    "model.decoder(input_ids=input_ids, encoder_hidden_states=out_enc.last_hidden_state, past_key_values=None).last_hidden_state[:,-1,:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 2.7559e-02,  1.5035e-01, -1.0642e-01,  1.3436e-01, -2.7034e-03,\n          1.0121e-01, -3.7072e-02, -1.1961e-01,  4.2827e-01, -6.8828e-02,\n          4.7861e-03,  1.0388e-01, -1.9117e-01, -9.1395e-02,  8.0236e-01,\n         -2.9004e-02, -8.3238e-03, -4.1821e-02,  5.1210e-02, -8.1611e-02,\n          5.2724e-02,  7.5980e-02, -8.5656e-02,  2.2240e+00,  4.7778e-02,\n         -7.0944e-02, -3.6484e-02,  2.8398e-01, -3.3781e-02, -1.3103e-01,\n          4.6392e-02, -4.0270e-02, -5.6167e-02, -1.5688e-02,  4.1200e-01,\n         -3.9406e-02, -1.1113e-01, -7.7969e-02, -1.3417e-01,  1.9564e-01,\n         -4.9984e-02, -5.9328e-02,  2.2479e-01,  7.3668e-02, -5.7874e-02,\n          1.4900e-02, -6.9493e-01,  1.7280e-02,  1.0609e-01,  9.2357e-02,\n         -1.3377e-01, -5.1072e-02, -8.8387e-02,  1.4478e-01, -1.1260e-01,\n          4.1932e-03,  5.3930e-02, -7.4811e-02,  5.8460e-02,  2.1838e-02,\n          8.2830e-02,  9.2348e-02, -2.5650e-02, -8.6029e-02, -1.2986e-02,\n         -4.3583e-02, -4.8884e-02, -3.3387e-02,  5.5351e-01,  1.8710e-01,\n         -3.0447e-02,  5.1245e-02,  5.5034e-02, -5.5080e-02, -1.7118e-03,\n          9.5299e-02, -4.5908e-02, -1.2584e-02,  8.4189e-02,  2.0390e-01,\n         -2.0322e-01,  8.3806e-02,  5.3210e-02, -8.4752e-02, -4.7789e-02,\n         -1.1201e-01, -2.8879e-02, -3.3881e-02, -1.7330e-01,  6.1102e-01,\n         -1.2889e-02, -9.4040e-02,  8.2499e-02, -7.6344e-02, -8.5807e-02,\n          2.5688e-02, -1.5682e-02, -1.1451e-02,  6.4908e-03, -2.3518e-02,\n          3.4917e-02, -5.8727e-02,  1.3254e-02,  1.5825e-01,  4.7590e-02,\n          1.0409e-01,  6.9139e-02,  3.9837e-02, -3.2700e-02, -9.1413e-02,\n         -1.0145e-01,  1.4212e-03, -4.8999e-03,  7.6215e-02, -7.3899e-02,\n         -8.5377e-02,  2.2540e-02, -4.9561e-02,  3.2881e-02, -2.2287e-02,\n         -6.8049e-02, -2.0161e-02,  1.6643e-02,  2.7154e-04, -2.5598e-02,\n          4.4508e-01, -9.3383e-02,  3.1402e-02, -1.0722e-01, -7.8250e-02,\n          2.4561e-02,  1.1590e-02, -6.1978e-02, -8.2641e-03, -4.8054e-02,\n          2.7818e-02, -5.3643e-02,  6.1974e-01, -8.0894e-02,  1.1800e-02,\n         -3.8681e-02, -9.5972e-02,  8.1281e-02, -6.7938e-02,  5.6997e-02,\n          6.1085e-02,  9.6156e-02,  2.4264e-02,  1.5555e-02, -3.0102e+00,\n          1.2210e-01, -1.4733e-02,  8.8266e-02, -1.0616e-02,  9.5372e-02,\n          3.4785e-02, -4.5652e-02,  3.7928e-02,  7.2694e-02, -6.9918e+00,\n         -9.0425e-02,  5.7168e-02,  9.9027e-02,  4.6014e-02, -1.1359e-01,\n         -1.3036e-01,  1.4493e-01,  3.3658e-01, -5.2206e-02,  4.0246e-02,\n          2.0170e-02, -5.1978e-02,  4.4187e-02, -7.7361e-02,  1.9363e-02,\n          6.2263e-02, -6.1392e-02,  1.8873e-03, -3.3080e-02,  2.0337e-03,\n          3.4712e-02,  4.9128e-02,  2.6168e-03,  6.7538e-02, -3.0646e-01,\n         -1.0470e-01,  8.9288e-02,  1.2655e-01, -9.8930e-02, -2.5814e-02,\n         -1.1664e+00, -2.1569e-01,  3.9758e-03, -5.4394e-02,  4.2295e-03,\n         -1.4125e-02, -7.4978e-03, -6.1164e-02,  1.7089e-02, -6.3246e-02,\n         -3.2219e-02, -4.2474e-02, -3.9572e-02, -3.2148e-02, -7.0602e-02,\n          1.7266e-03,  3.1441e-02, -5.3143e-02, -4.6806e-02, -7.4992e-02,\n          1.7826e-02,  3.7886e-02, -5.9538e-02, -1.5893e-01, -6.2725e-02,\n         -2.4954e-02, -1.1496e-02, -5.6767e-02,  1.7637e-02, -5.2200e-02,\n         -3.3890e-02,  1.0832e-01, -3.6066e-02, -1.4835e-01,  7.2392e-03,\n          1.9350e-02, -2.5393e-01,  4.7064e-02, -1.2885e-01, -5.2606e-02,\n          3.4595e-02, -3.2223e-02,  2.3422e-02,  7.2860e-02, -2.5571e-01,\n         -6.5474e-02,  1.2896e-01,  8.3955e-02, -9.2654e-02,  7.1888e-02,\n          2.8062e-01,  4.2430e-02,  2.2217e-02,  4.0215e-02, -1.6136e-01,\n          9.2231e-01,  8.5289e-02,  4.6700e-04, -6.0995e-01,  4.4942e-02,\n          5.1844e-02,  1.8363e-02,  5.8039e-02, -6.6558e-02, -1.2741e-02,\n         -4.8374e-02, -7.0576e-03, -7.4275e-02, -2.5042e-01,  9.4788e-02,\n         -2.0065e-02,  5.5633e-03,  1.0549e-01,  6.3857e-01, -1.2988e-02,\n          6.1024e-02, -9.9692e-02,  8.6343e-02,  5.2502e-03, -8.4473e-02,\n          6.4332e-02, -3.9104e-02,  2.0621e-01,  5.0988e-01,  6.3144e-02,\n         -2.0267e-02, -4.0145e-02,  6.0277e-03, -5.9656e-02, -1.2237e-01,\n         -4.2363e-01,  3.2023e-02, -3.3462e-02, -5.3217e-03,  6.4035e-02,\n         -2.4842e-02,  7.4523e-02,  4.0784e-02,  5.0653e-02,  1.5206e-02,\n         -2.3787e-01,  4.2893e-04,  5.5599e-02,  1.7442e-01, -2.0597e+00,\n          2.2187e-01, -8.1338e-02, -3.3712e-02,  1.3336e-02,  3.6996e-02,\n          7.0870e-02,  1.7253e-02,  6.7578e-02,  1.5224e-02, -4.0918e-02,\n          4.6613e-02, -1.5509e-01, -3.2361e-01,  4.6951e-01, -9.7088e-02,\n         -2.0382e-02,  1.8947e-01, -7.4723e-01,  1.4031e-01, -9.4199e-02,\n         -5.9677e-02,  3.4392e-02,  4.5680e-02, -2.0871e-01, -6.9111e-02,\n         -1.0838e-01, -1.4020e-01, -9.6648e-02, -2.4828e-01, -2.9278e+00,\n          4.8934e-02,  7.4296e-02,  6.2194e-02,  1.5646e-02,  8.0212e-02,\n          8.4066e-02, -8.2836e-02, -1.4783e-01,  6.2116e-02,  6.1861e-03,\n         -8.3127e-02, -1.6525e-01, -4.2172e-02, -8.7703e-02, -1.0587e-01,\n          6.6060e-02, -1.2229e-01, -6.8211e-03,  1.3168e-01, -1.0773e-02,\n         -1.7031e-01,  2.6723e-02, -3.8696e-02,  7.6689e-02, -5.8725e-02,\n          1.9595e-01, -1.2188e-02,  5.9785e-02,  5.0739e-02,  2.5466e-02,\n         -2.7911e-01, -1.2255e-01,  2.8395e-02,  3.9120e-02,  1.3815e-01,\n         -9.5946e-02,  1.9945e-02,  6.0094e-02, -1.4042e-01, -5.9581e-02,\n         -1.0952e-01, -7.3303e-02, -3.3756e-01, -1.6650e-03,  8.1169e-04,\n          6.8362e-02,  1.6927e-01, -6.6210e-02,  1.1466e-02, -3.0490e-01,\n         -1.2575e-01,  8.7527e-03, -8.2844e-02,  3.2840e-03, -2.1481e-01,\n          4.4152e-02, -1.1502e+00, -2.0167e-01, -2.2349e-02,  1.5185e-01,\n          5.1614e-02,  1.1127e-01,  2.4280e-02, -2.7464e-01, -8.6785e-03,\n          1.2796e-02,  2.3091e-02, -1.4170e-01,  1.2471e-02, -6.3778e-02,\n         -1.0977e-01,  4.8350e-02,  7.4094e-02,  5.8915e-02,  7.7498e-02,\n          2.7250e-01,  1.8195e-01,  7.3699e-02, -1.1701e-01, -5.5508e-02,\n          2.0029e-02, -5.6784e-02, -3.5544e-02, -1.6007e-02,  4.2423e-02,\n          2.4862e-01, -1.2843e-01, -9.1527e-02, -9.2774e-02, -1.5552e-02,\n          2.1962e-02,  5.6796e-02,  3.9258e-01,  1.6204e-02,  2.8135e-02,\n          5.0101e-02, -1.0456e-01, -8.2916e-02,  2.7435e-02, -1.5170e-01,\n         -7.9315e-02,  3.0147e-02, -1.7284e-02, -1.2829e-01,  2.7650e-02,\n          5.3210e-02, -5.4339e-02,  1.0162e-01, -1.9675e-02, -9.0280e-02,\n         -4.6922e-02,  1.6096e-03,  1.9443e-02,  3.8715e-02, -4.2711e-02,\n         -7.7992e-02,  4.1426e-02,  8.2198e-03,  1.5082e-01,  3.3577e-03,\n         -2.2130e-02,  3.8794e-03, -1.0341e-01, -1.3226e-01,  9.8023e-04,\n          8.5674e-02, -6.0801e-02, -5.3319e-02, -1.8344e-01,  4.9798e-02,\n          2.9513e-02,  5.8624e-02, -1.1644e-02,  5.6686e-02, -2.3213e-02,\n          5.9430e-02,  3.0600e-02, -7.0081e-02, -9.4119e-02,  1.2767e-01,\n         -9.1701e-02,  5.3907e-02,  1.4844e-01,  5.5190e-02, -4.8491e-02,\n         -7.4864e-02, -4.8855e-03, -1.1108e-01,  2.9740e-02, -1.3206e-01,\n         -1.0341e-01, -5.5583e-02, -3.4414e-01, -9.1684e-03, -3.5313e-02,\n         -1.3231e-01,  4.7432e-02,  8.9266e-02, -1.2552e-01,  5.9633e-02,\n         -5.4128e-02, -9.0889e-03, -1.9906e-01, -4.2343e-03, -8.0673e-03,\n          1.4961e-03, -7.9238e-02,  6.1884e-02,  4.9478e-02, -7.5516e-02,\n          1.7998e-02,  8.1206e-02, -1.8421e-01, -6.5565e-02, -6.8392e-02,\n         -2.1154e-01, -7.4017e-01, -3.8952e-02,  1.1902e-01,  3.7814e-02,\n         -1.3577e-01, -1.5776e-01, -1.4138e-02,  4.6991e-02,  6.5095e-02,\n          3.4050e-04,  5.8638e-02]], device='cuda:0', grad_fn=<SliceBackward0>)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_dec_pytorch = model.decoder(input_ids=input_ids[:, :-1], encoder_hidden_states=out_enc.last_hidden_state)\n",
    "model.decoder(input_ids=input_ids[:, -1:], encoder_hidden_states=out_enc.last_hidden_state, past_key_values=out_dec_pytorch.past_key_values).last_hidden_state[:,-1,:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/geantvert/.local/share/virtualenvs/fast_transformer/lib/python3.9/site-packages/torch/onnx/utils.py:90: UserWarning: 'enable_onnx_checker' is deprecated and ignored. It will be removed in the next PyTorch release. To proceed despite ONNX checker failures, catch torch.onnx.ONNXCheckerError.\n",
      "  warnings.warn(\"'enable_onnx_checker' is deprecated and ignored. It will be removed in \"\n",
      "/home/geantvert/.local/share/virtualenvs/fast_transformer/lib/python3.9/site-packages/torch/onnx/utils.py:103: UserWarning: `use_external_data_format' is deprecated and ignored. Will be removed in next PyTorch release. The code will work as it is False if models are not larger than 2GB, Otherwise set to False because of size limits imposed by Protocol Buffers.\n",
      "  warnings.warn(\"`use_external_data_format' is deprecated and ignored. Will be removed in next \"\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "from transformers.onnx.features import FeaturesManager\n",
    "\n",
    "feature = \"seq2seq-lm-with-past\"\n",
    "model = FeaturesManager.get_model_from_feature(feature, model_name)\n",
    "model_kind, model_onnx_config = FeaturesManager.check_supported_model_or_raise(model, feature=feature)\n",
    "onnx_config = model_onnx_config(model.config)\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.config.return_dict = True\n",
    "    model.eval()\n",
    "\n",
    "    # Check if we need to override certain configuration item\n",
    "    if onnx_config.values_override is not None:\n",
    "        for override_config_key, override_config_value in onnx_config.values_override.items():\n",
    "            setattr(model.config, override_config_key, override_config_value)\n",
    "\n",
    "    # Ensure inputs match\n",
    "    model_inputs = onnx_config.generate_dummy_inputs(tokenizer, framework=TensorType.PYTORCH)\n",
    "    for k, v in model_inputs.items():\n",
    "        if isinstance(v, torch.Tensor):\n",
    "            model_inputs[k] = model_inputs[k].type(torch.int32)\n",
    "    onnx_outputs = list(onnx_config.outputs.keys())\n",
    "\n",
    "    onnx_config.patch_ops()\n",
    "\n",
    "    # export can works with named args but the dict containing named args as to be last element of the args tuple\n",
    "    torch.onnx.export(\n",
    "        model,\n",
    "        (model_inputs,),\n",
    "        f=\"test-dec-cache.onnx\",\n",
    "        input_names=list(onnx_config.inputs.keys()),\n",
    "        output_names=onnx_outputs,\n",
    "        dynamic_axes={name: axes for name, axes in chain(onnx_config.inputs.items(), onnx_config.outputs.items())},\n",
    "        do_constant_folding=True,\n",
    "        use_external_data_format=onnx_config.use_external_data_format(model.num_parameters()),\n",
    "        enable_onnx_checker=True,\n",
    "        opset_version=13,\n",
    "    )\n",
    "\n",
    "    onnx_config.restore_ops()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "model.cuda()\n",
    "out_dec_pytorch = model.decoder(input_ids=input_ids[:, :-1], encoder_hidden_states=out_enc.last_hidden_state)\n",
    "\n",
    "model.cuda()\n",
    "\n",
    "model_inputs = {\n",
    "    'input_ids' : input_ids[:, -1:].type(torch.int32),\n",
    "    'encoder_hidden_states': out_enc.last_hidden_state,\n",
    "    'past_key_values': out_dec_pytorch.past_key_values,\n",
    "}\n",
    "\n",
    "input_names = ['input_ids',\n",
    " 'encoder_hidden_states',\n",
    " 'past_key_values.0.decoder.key',\n",
    " 'past_key_values.0.decoder.value',\n",
    " 'past_key_values.0.encoder.key',\n",
    " 'past_key_values.0.encoder.value',\n",
    " 'past_key_values.1.decoder.key',\n",
    " 'past_key_values.1.decoder.value',\n",
    " 'past_key_values.1.encoder.key',\n",
    " 'past_key_values.1.encoder.value',\n",
    " 'past_key_values.2.decoder.key',\n",
    " 'past_key_values.2.decoder.value',\n",
    " 'past_key_values.2.encoder.key',\n",
    " 'past_key_values.2.encoder.value',\n",
    " 'past_key_values.3.decoder.key',\n",
    " 'past_key_values.3.decoder.value',\n",
    " 'past_key_values.3.encoder.key',\n",
    " 'past_key_values.3.encoder.value',\n",
    " 'past_key_values.4.decoder.key',\n",
    " 'past_key_values.4.decoder.value',\n",
    " 'past_key_values.4.encoder.key',\n",
    " 'past_key_values.4.encoder.value',\n",
    " 'past_key_values.5.decoder.key',\n",
    " 'past_key_values.5.decoder.value',\n",
    " 'past_key_values.5.encoder.key',\n",
    " 'past_key_values.5.encoder.value']\n",
    "\n",
    "output_names = ['logits',\n",
    " 'present.0.decoder.key',\n",
    " 'present.0.decoder.value',\n",
    " 'present.0.encoder.key',\n",
    " 'present.0.encoder.value',\n",
    " 'present.1.decoder.key',\n",
    " 'present.1.decoder.value',\n",
    " 'present.1.encoder.key',\n",
    " 'present.1.encoder.value',\n",
    " 'present.2.decoder.key',\n",
    " 'present.2.decoder.value',\n",
    " 'present.2.encoder.key',\n",
    " 'present.2.encoder.value',\n",
    " 'present.3.decoder.key',\n",
    " 'present.3.decoder.value',\n",
    " 'present.3.encoder.key',\n",
    " 'present.3.encoder.value',\n",
    " 'present.4.decoder.key',\n",
    " 'present.4.decoder.value',\n",
    " 'present.4.encoder.key',\n",
    " 'present.4.encoder.value',\n",
    " 'present.5.decoder.key',\n",
    " 'present.5.decoder.value',\n",
    " 'present.5.encoder.key',\n",
    " 'present.5.encoder.value']\n",
    "\n",
    "dynamic_axis = {'input_ids': {0: 'batch', 1: 'encoder_sequence'}, 'past_key_values.0.decoder.key': {0: 'batch', 2: 'past_decoder_sequence'}, 'past_key_values.0.decoder.value': {0: 'batch', 2: 'past_decoder_sequence'}, 'past_key_values.0.encoder.key': {0: 'batch', 2: 'past_encoder_sequence'}, 'past_key_values.0.encoder.value': {0: 'batch', 2: 'past_encoder_sequence'}, 'past_key_values.1.decoder.key': {0: 'batch', 2: 'past_decoder_sequence'}, 'past_key_values.1.decoder.value': {0: 'batch', 2: 'past_decoder_sequence'}, 'past_key_values.1.encoder.key': {0: 'batch', 2: 'past_encoder_sequence'}, 'past_key_values.1.encoder.value': {0: 'batch', 2: 'past_encoder_sequence'}, 'past_key_values.2.decoder.key': {0: 'batch', 2: 'past_decoder_sequence'}, 'past_key_values.2.decoder.value': {0: 'batch', 2: 'past_decoder_sequence'}, 'past_key_values.2.encoder.key': {0: 'batch', 2: 'past_encoder_sequence'}, 'past_key_values.2.encoder.value': {0: 'batch', 2: 'past_encoder_sequence'}, 'past_key_values.3.decoder.key': {0: 'batch', 2: 'past_decoder_sequence'}, 'past_key_values.3.decoder.value': {0: 'batch', 2: 'past_decoder_sequence'}, 'past_key_values.3.encoder.key': {0: 'batch', 2: 'past_encoder_sequence'}, 'past_key_values.3.encoder.value': {0: 'batch', 2: 'past_encoder_sequence'}, 'past_key_values.4.decoder.key': {0: 'batch', 2: 'past_decoder_sequence'}, 'past_key_values.4.decoder.value': {0: 'batch', 2: 'past_decoder_sequence'}, 'past_key_values.4.encoder.key': {0: 'batch', 2: 'past_encoder_sequence'}, 'past_key_values.4.encoder.value': {0: 'batch', 2: 'past_encoder_sequence'}, 'past_key_values.5.decoder.key': {0: 'batch', 2: 'past_decoder_sequence'}, 'past_key_values.5.decoder.value': {0: 'batch', 2: 'past_decoder_sequence'}, 'past_key_values.5.encoder.key': {0: 'batch', 2: 'past_encoder_sequence'}, 'past_key_values.5.encoder.value': {0: 'batch', 2: 'past_encoder_sequence'}, 'logits': {0: 'batch', 1: 'decoder_sequence'}, 'present.0.decoder.key': {0: 'batch', 2: 'past_decoder_sequence + sequence'}, 'present.0.decoder.value': {0: 'batch', 2: 'past_decoder_sequence + sequence'}, 'present.0.encoder.key': {0: 'batch', 2: 'past_encoder_sequence'}, 'present.0.encoder.value': {0: 'batch', 2: 'past_encoder_sequence'}, 'present.1.decoder.key': {0: 'batch', 2: 'past_decoder_sequence + sequence'}, 'present.1.decoder.value': {0: 'batch', 2: 'past_decoder_sequence + sequence'}, 'present.1.encoder.key': {0: 'batch', 2: 'past_encoder_sequence'}, 'present.1.encoder.value': {0: 'batch', 2: 'past_encoder_sequence'}, 'present.2.decoder.key': {0: 'batch', 2: 'past_decoder_sequence + sequence'}, 'present.2.decoder.value': {0: 'batch', 2: 'past_decoder_sequence + sequence'}, 'present.2.encoder.key': {0: 'batch', 2: 'past_encoder_sequence'}, 'present.2.encoder.value': {0: 'batch', 2: 'past_encoder_sequence'}, 'present.3.decoder.key': {0: 'batch', 2: 'past_decoder_sequence + sequence'}, 'present.3.decoder.value': {0: 'batch', 2: 'past_decoder_sequence + sequence'}, 'present.3.encoder.key': {0: 'batch', 2: 'past_encoder_sequence'}, 'present.3.encoder.value': {0: 'batch', 2: 'past_encoder_sequence'}, 'present.4.decoder.key': {0: 'batch', 2: 'past_decoder_sequence + sequence'}, 'present.4.decoder.value': {0: 'batch', 2: 'past_decoder_sequence + sequence'}, 'present.4.encoder.key': {0: 'batch', 2: 'past_encoder_sequence'}, 'present.4.encoder.value': {0: 'batch', 2: 'past_encoder_sequence'}, 'present.5.decoder.key': {0: 'batch', 2: 'past_decoder_sequence + sequence'}, 'present.5.decoder.value': {0: 'batch', 2: 'past_decoder_sequence + sequence'}, 'present.5.encoder.key': {0: 'batch', 2: 'past_encoder_sequence'}, 'present.5.encoder.value': {0: 'batch', 2: 'past_encoder_sequence'}}\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.config.return_dict = True\n",
    "    model.eval()\n",
    "\n",
    "    # export can works with named args but the dict containing named args as to be last element of the args tuple\n",
    "    torch.onnx.export(\n",
    "        model.decoder,\n",
    "        (model_inputs,),\n",
    "        f=\"test-dec-cache.onnx\",\n",
    "        input_names=input_names,\n",
    "        output_names=output_names,\n",
    "        dynamic_axes=dynamic_axis,\n",
    "        do_constant_folding=True,\n",
    "        use_external_data_format=False,\n",
    "        enable_onnx_checker=True,\n",
    "        opset_version=13,\n",
    "    )\n",
    "\n",
    "    onnx_config.restore_ops()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "ort_cache = create_model_for_provider(\"test-dec-cache.onnx\", \"CPUExecutionProvider\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "(1, 1, 512)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_cache = dict()\n",
    "input_cache[\"input_ids\"] = input_ids[:, -1:].type(torch.int32).detach().cpu().numpy()\n",
    "\n",
    "for index, (k_dec, v_dec, k_enc, v_enc) in enumerate(out_dec_pytorch.past_key_values):  # type: int, (torch.Tensor, torch.Tensor)\n",
    "    input_cache[f\"past_key_values.{index}.decoder.key\"] = k_dec.detach().cpu().numpy()\n",
    "    input_cache[f\"past_key_values.{index}.decoder.value\"] = v_dec.detach().cpu().numpy()\n",
    "    input_cache[f\"past_key_values.{index}.encoder.key\"] = k_enc.detach().cpu().numpy()\n",
    "    input_cache[f\"past_key_values.{index}.encoder.value\"] = v_enc.detach().cpu().numpy()\n",
    "\n",
    "ort_cache.run([\"logits\"], input_cache)[0].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[ 2.7551e-02,  1.5033e-01, -1.0638e-01,  1.3437e-01, -2.7034e-03,\n           1.0119e-01, -3.7066e-02, -1.1958e-01,  4.2827e-01, -6.8837e-02,\n           4.7930e-03,  1.0388e-01, -1.9117e-01, -9.1408e-02,  8.0224e-01,\n          -2.9010e-02, -8.3016e-03, -4.1842e-02,  5.1235e-02, -8.1596e-02,\n           5.2729e-02,  7.5967e-02, -8.5656e-02,  2.2240e+00,  4.7762e-02,\n          -7.0900e-02, -3.6481e-02,  2.8401e-01, -3.3791e-02, -1.3101e-01,\n           4.6434e-02, -4.0252e-02, -5.6140e-02, -1.5710e-02,  4.1203e-01,\n          -3.9375e-02, -1.1114e-01, -7.7971e-02, -1.3421e-01,  1.9566e-01,\n          -4.9996e-02, -5.9346e-02,  2.2478e-01,  7.3680e-02, -5.7880e-02,\n           1.4898e-02, -6.9503e-01,  1.7287e-02,  1.0606e-01,  9.2383e-02,\n          -1.3378e-01, -5.1050e-02, -8.8404e-02,  1.4487e-01, -1.1263e-01,\n           4.1829e-03,  5.3950e-02, -7.4830e-02,  5.8463e-02,  2.1883e-02,\n           8.2851e-02,  9.2368e-02, -2.5662e-02, -8.6041e-02, -1.2973e-02,\n          -4.3556e-02, -4.8887e-02, -3.3391e-02,  5.5338e-01,  1.8713e-01,\n          -3.0421e-02,  5.1240e-02,  5.5065e-02, -5.5090e-02, -1.7137e-03,\n           9.5300e-02, -4.5899e-02, -1.2564e-02,  8.4190e-02,  2.0384e-01,\n          -2.0325e-01,  8.3824e-02,  5.3239e-02, -8.4725e-02, -4.7796e-02,\n          -1.1199e-01, -2.8854e-02, -3.3867e-02, -1.7333e-01,  6.1112e-01,\n          -1.2895e-02, -9.4087e-02,  8.2499e-02, -7.6347e-02, -8.5843e-02,\n           2.5715e-02, -1.5698e-02, -1.1458e-02,  6.4937e-03, -2.3514e-02,\n           3.4896e-02, -5.8752e-02,  1.3294e-02,  1.5820e-01,  4.7593e-02,\n           1.0408e-01,  6.9141e-02,  3.9843e-02, -3.2727e-02, -9.1422e-02,\n          -1.0145e-01,  1.4145e-03, -4.8944e-03,  7.6223e-02, -7.3935e-02,\n          -8.5385e-02,  2.2558e-02, -4.9582e-02,  3.2881e-02, -2.2290e-02,\n          -6.8029e-02, -2.0162e-02,  1.6654e-02,  2.8510e-04, -2.5601e-02,\n           4.4504e-01, -9.3392e-02,  3.1404e-02, -1.0724e-01, -7.8232e-02,\n           2.4581e-02,  1.1608e-02, -6.1949e-02, -8.2761e-03, -4.8032e-02,\n           2.7831e-02, -5.3661e-02,  6.1974e-01, -8.0898e-02,  1.1810e-02,\n          -3.8686e-02, -9.5962e-02,  8.1288e-02, -6.7911e-02,  5.6973e-02,\n           6.1092e-02,  9.6192e-02,  2.4291e-02,  1.5550e-02, -3.0105e+00,\n           1.2208e-01, -1.4719e-02,  8.8211e-02, -1.0647e-02,  9.5379e-02,\n           3.4756e-02, -4.5655e-02,  3.7942e-02,  7.2664e-02, -6.9923e+00,\n          -9.0435e-02,  5.7174e-02,  9.9040e-02,  4.6014e-02, -1.1360e-01,\n          -1.3036e-01,  1.4496e-01,  3.3655e-01, -5.2237e-02,  4.0264e-02,\n           2.0130e-02, -5.1967e-02,  4.4201e-02, -7.7366e-02,  1.9354e-02,\n           6.2240e-02, -6.1387e-02,  1.8715e-03, -3.3078e-02,  2.0348e-03,\n           3.4720e-02,  4.9113e-02,  2.6169e-03,  6.7537e-02, -3.0647e-01,\n          -1.0469e-01,  8.9290e-02,  1.2653e-01, -9.8944e-02, -2.5801e-02,\n          -1.1667e+00, -2.1569e-01,  3.9563e-03, -5.4400e-02,  4.2372e-03,\n          -1.4115e-02, -7.5038e-03, -6.1131e-02,  1.7113e-02, -6.3259e-02,\n          -3.2215e-02, -4.2465e-02, -3.9568e-02, -3.2183e-02, -7.0627e-02,\n           1.7471e-03,  3.1438e-02, -5.3158e-02, -4.6784e-02, -7.4984e-02,\n           1.7811e-02,  3.7859e-02, -5.9493e-02, -1.5895e-01, -6.2740e-02,\n          -2.4936e-02, -1.1529e-02, -5.6753e-02,  1.7598e-02, -5.2179e-02,\n          -3.3915e-02,  1.0834e-01, -3.6067e-02, -1.4835e-01,  7.2303e-03,\n           1.9320e-02, -2.5388e-01,  4.7052e-02, -1.2883e-01, -5.2605e-02,\n           3.4574e-02, -3.2190e-02,  2.3419e-02,  7.2872e-02, -2.5572e-01,\n          -6.5452e-02,  1.2896e-01,  8.3965e-02, -9.2649e-02,  7.1910e-02,\n           2.8065e-01,  4.2406e-02,  2.2191e-02,  4.0196e-02, -1.6140e-01,\n           9.2225e-01,  8.5310e-02,  4.6526e-04, -6.1000e-01,  4.4905e-02,\n           5.1839e-02,  1.8341e-02,  5.7995e-02, -6.6549e-02, -1.2780e-02,\n          -4.8370e-02, -7.0448e-03, -7.4271e-02, -2.5039e-01,  9.4823e-02,\n          -2.0055e-02,  5.5607e-03,  1.0546e-01,  6.3880e-01, -1.2996e-02,\n           6.1018e-02, -9.9674e-02,  8.6357e-02,  5.2492e-03, -8.4457e-02,\n           6.4348e-02, -3.9117e-02,  2.0620e-01,  5.0973e-01,  6.3134e-02,\n          -2.0285e-02, -4.0122e-02,  6.0226e-03, -5.9689e-02, -1.2235e-01,\n          -4.2362e-01,  3.1992e-02, -3.3480e-02, -5.3716e-03,  6.4029e-02,\n          -2.4840e-02,  7.4514e-02,  4.0804e-02,  5.0643e-02,  1.5236e-02,\n          -2.3790e-01,  4.1713e-04,  5.5600e-02,  1.7441e-01, -2.0599e+00,\n           2.2186e-01, -8.1344e-02, -3.3740e-02,  1.3341e-02,  3.7041e-02,\n           7.0887e-02,  1.7246e-02,  6.7576e-02,  1.5241e-02, -4.0968e-02,\n           4.6625e-02, -1.5510e-01, -3.2364e-01,  4.6944e-01, -9.7034e-02,\n          -2.0398e-02,  1.8948e-01, -7.4735e-01,  1.4030e-01, -9.4202e-02,\n          -5.9679e-02,  3.4381e-02,  4.5673e-02, -2.0870e-01, -6.9101e-02,\n          -1.0838e-01, -1.4019e-01, -9.6636e-02, -2.4835e-01, -2.9281e+00,\n           4.8929e-02,  7.4333e-02,  6.2202e-02,  1.5640e-02,  8.0266e-02,\n           8.4059e-02, -8.2833e-02, -1.4781e-01,  6.2118e-02,  6.1550e-03,\n          -8.3150e-02, -1.6525e-01, -4.2202e-02, -8.7727e-02, -1.0590e-01,\n           6.6095e-02, -1.2230e-01, -6.8224e-03,  1.3167e-01, -1.0765e-02,\n          -1.7025e-01,  2.6740e-02, -3.8706e-02,  7.6705e-02, -5.8739e-02,\n           1.9593e-01, -1.2193e-02,  5.9800e-02,  5.0716e-02,  2.5481e-02,\n          -2.7909e-01, -1.2253e-01,  2.8378e-02,  3.9127e-02,  1.3818e-01,\n          -9.5935e-02,  1.9945e-02,  6.0107e-02, -1.4044e-01, -5.9602e-02,\n          -1.0951e-01, -7.3292e-02, -3.3756e-01, -1.6821e-03,  8.2241e-04,\n           6.8365e-02,  1.6928e-01, -6.6220e-02,  1.1439e-02, -3.0488e-01,\n          -1.2575e-01,  8.7401e-03, -8.2858e-02,  3.2944e-03, -2.1482e-01,\n           4.4138e-02, -1.1503e+00, -2.0164e-01, -2.2355e-02,  1.5188e-01,\n           5.1598e-02,  1.1129e-01,  2.4283e-02, -2.7467e-01, -8.6828e-03,\n           1.2782e-02,  2.3108e-02, -1.4170e-01,  1.2463e-02, -6.3765e-02,\n          -1.0976e-01,  4.8327e-02,  7.4112e-02,  5.8970e-02,  7.7531e-02,\n           2.7253e-01,  1.8199e-01,  7.3722e-02, -1.1700e-01, -5.5506e-02,\n           2.0045e-02, -5.6784e-02, -3.5561e-02, -1.6044e-02,  4.2410e-02,\n           2.4865e-01, -1.2844e-01, -9.1536e-02, -9.2791e-02, -1.5587e-02,\n           2.1956e-02,  5.6824e-02,  3.9263e-01,  1.6213e-02,  2.8137e-02,\n           5.0112e-02, -1.0457e-01, -8.2898e-02,  2.7453e-02, -1.5170e-01,\n          -7.9310e-02,  3.0157e-02, -1.7293e-02, -1.2830e-01,  2.7603e-02,\n           5.3190e-02, -5.4312e-02,  1.0162e-01, -1.9718e-02, -9.0279e-02,\n          -4.6909e-02,  1.6258e-03,  1.9456e-02,  3.8735e-02, -4.2712e-02,\n          -7.7962e-02,  4.1424e-02,  8.2199e-03,  1.5082e-01,  3.3740e-03,\n          -2.2145e-02,  3.8848e-03, -1.0344e-01, -1.3227e-01,  9.7634e-04,\n           8.5690e-02, -6.0813e-02, -5.3308e-02, -1.8346e-01,  4.9784e-02,\n           2.9507e-02,  5.8635e-02, -1.1666e-02,  5.6662e-02, -2.3232e-02,\n           5.9432e-02,  3.0621e-02, -7.0069e-02, -9.4084e-02,  1.2766e-01,\n          -9.1732e-02,  5.3892e-02,  1.4847e-01,  5.5173e-02, -4.8516e-02,\n          -7.4854e-02, -4.8515e-03, -1.1112e-01,  2.9712e-02, -1.3206e-01,\n          -1.0344e-01, -5.5593e-02, -3.4411e-01, -9.1696e-03, -3.5345e-02,\n          -1.3233e-01,  4.7458e-02,  8.9262e-02, -1.2551e-01,  5.9608e-02,\n          -5.4122e-02, -9.0791e-03, -1.9907e-01, -4.2288e-03, -8.0875e-03,\n           1.4961e-03, -7.9234e-02,  6.1876e-02,  4.9482e-02, -7.5497e-02,\n           1.7991e-02,  8.1196e-02, -1.8420e-01, -6.5551e-02, -6.8390e-02,\n          -2.1157e-01, -7.4017e-01, -3.8935e-02,  1.1902e-01,  3.7806e-02,\n          -1.3578e-01, -1.5776e-01, -1.4133e-02,  4.6998e-02,  6.5100e-02,\n           3.4044e-04,  5.8627e-02]]], device='cuda:0')"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ort_cache = create_model_for_provider(\"test-dec-cache.onnx\", \"CUDAExecutionProvider\")\n",
    "input_cache = dict()\n",
    "input_cache[\"input_ids\"] = input_ids[:, -1:]\n",
    "\n",
    "for index, (k_dec, v_dec, k_enc, v_enc) in enumerate(out_dec_pytorch.past_key_values):  # type: int, (torch.Tensor, torch.Tensor, torch.Tensor)\n",
    "    input_cache[f\"past_key_values.{index}.decoder.key\"] = k_dec.cuda()\n",
    "    input_cache[f\"past_key_values.{index}.decoder.value\"] = v_dec.cuda()\n",
    "    input_cache[f\"past_key_values.{index}.encoder.key\"] = k_enc.cuda()\n",
    "    input_cache[f\"past_key_values.{index}.encoder.value\"] = v_enc.cuda()\n",
    "\n",
    "\n",
    "inference_onnx_binding(model_onnx=ort_cache, inputs=input_cache, device=\"cuda\", output_shape={\"logits\": (1, 1, 512)})[\"logits\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}