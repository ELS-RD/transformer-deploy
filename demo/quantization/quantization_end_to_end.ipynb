{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nvidia GPU INT-8 quantization on any transformers model (encoder based)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantization is one of the most effective and generic approach to make model inference faster.\n",
    "Basically, it replaces high precision float numbers in model tensors encoded in 32 or 16 bits by lower precision ones encoded in 8 bits or less:\n",
    "\n",
    "* it takes less memory\n",
    "* computation is easier / faster\n",
    "\n",
    "It can be applied to any model in theory, and, if done well, it should not decrease its accuracy.\n",
    "\n",
    "The purpose of this notebook is to show 2 processes to perform quantization on any `transformer` architectures.\n",
    "\n",
    "**TL;DR, we benchmarked Pytorch and Nvidia TensorRT, on both CPU and GPU, with/without quantization, our methods provide the fastest inference by large margin**.\n",
    "\n",
    "| Framework                 | Precision | Latency (ms) | Accuracy | Speedup    | Hardware |\n",
    "|:--------------------------|-----------|--------------|----------|:-----------|:--------:|\n",
    "| Pytorch                   | FP32      | 4000         | 86.8 %   | X 0.02     |   CPU    |\n",
    "| Pytorch                   | FP16      | 4005         | 86.8 %   | X 0.02     |   CPU    |\n",
    "| Pytorch                   | **INT-8** | 3670         | 86.8 %   | X 0.02     | **CPU**  |\n",
    "| Pytorch                   | FP32      | 80           | 86.8 %   | X 1        |   GPU    |\n",
    "| Pytorch                   | FP16      | 58           | 86.8 %   | X 1.38     |   GPU    |\n",
    "| ONNX Runtime              | FP32      | 74           | 86.8 %   | X 1.08     |   GPU    |\n",
    "| ONNX Runtime              | FP16      | 34           | 86.8 %   | X 2.35     |   GPU    |\n",
    "| ONNX Runtime              | FP32      | 3767         | 86.8 %   | X 0.02     |   CPU    |\n",
    "| ONNX Runtime              | FP16      | 4607         | 86.8 %   | X 0.02     |   CPU    |\n",
    "| ONNX Runtime              | **INT-8** | 3712         | 86.8 %   | X 0.02     | **CPU**  |\n",
    "| TensorRT                  | FP16      | 30           | 86.8 %   | X 2.67     |   GPU    |\n",
    "| TensorRT (**our method**) | **INT-8** | 15           | 84.4 %   | **X 5.33** | **GPU**  |\n",
    "\n",
    "> measures done on a Nvidia RTX 3090 GPU + 12 cores i7 Intel CPU (support AVX-2 instructions)\n",
    ">\n",
    "> `base` architecture flavor with batch of size 32 / seq len 256, similar results obtained for other sizes/seq len not included in the table.\n",
    ">\n",
    "> accuracy obtained after a single epoch, no LR search or any hyper parameter optimization\n",
    "\n",
    "\n",
    "## A (very) short intro to INT-8 quantization\n",
    "\n",
    "Basic idea behind model quantization is to replace tensors made of float numbers (usually encoded on 32 bits) by lower precision representation (integers encoded on 8 bits for Nvidia GPUs).\n",
    "Therefore computation is faster and model memory footprint is lower. Making tensor storage smaller makes memory transfer faster... and is also a source of computation acceleration.\n",
    "This technic is very interesting for its trade-off: you reduce inference time significantly, and when dataset is large enough, it costs close to nothing in accuracy.\n",
    "\n",
    "Replacing float numbers by integers is done through a mapping.\n",
    "This step is called `calibration`, and its purpose is to compute for each tensor or each channel of a tensor (one of its dimensions) a range of all possible values and then define a scale and a distribution center to map float numbers to 8 bits integers.\n",
    "\n",
    "There are several ways to perform quantization, depending of how and when the `calibration` is performed:\n",
    "\n",
    "* dynamically: the mapping is done during the inference, there are some overhead but it's easy to put in place and usually the accuracy is preserved,\n",
    "* statically, after training (`post training quantization` or `PTQ`): this way is efficient, but it may have a significant accuracy cost,\n",
    "* statically, before training (`quantization aware training` or `QAT`): this way is efficient and has a low accuracy cost as the weights will take care of the result\n",
    "\n",
    "Nvidia GPUs don't support dynamic quantization, CPU supports all type of quantization.  \n",
    "Compared to `PTQ`, `QAT` better presevers accuracy and should be prefered.\n",
    "\n",
    "\n",
    "During the quantization aware *training*:\n",
    "\n",
    "* in the inside, Pytorch will train with high precision float numbers,\n",
    "* on the outside, Pytorch will simulate that a quantization has already been applied and output results accordingly (for loss computation for instance)\n",
    "\n",
    "The simulation process is done through the add of quantization / dequantization nodes, most often called `QDQ`, it's an abbreviation you will see often in quantization world.\n",
    "\n",
    "\n",
    "\n",
    "> Want to learn more about quantization?\n",
    "> \n",
    "> * You can check this [high quality blog post](https://leimao.github.io/article/Neural-Networks-Quantization/) for more information.\n",
    "> * The process is well described in this [Nvidia presentation](https://on-demand.gputechconf.com/gtc/2017/presentation/s7310-8-bit-inference-with-tensorrt.pdf)\n",
    "\n",
    "## Why this notebook?\n",
    "\n",
    "CPU quantization is supported out of the box by `Pytorch` and `ONNX Runtime`.\n",
    "**GPU quantization on the other side requires specific tools and process to be applied**.\n",
    "\n",
    "In the specific case of `transformer` models, until recently (december 2021), the only way shown by Nvidia is to build manually the graph of our models in `TensorRT`. This is a low level approach, based on GPU capacity knowledge (which operators are supported, etc.). It's certainly out of reach of most NLP practitioners and is very time consuming to update/adapt to new architectures.\n",
    "\n",
    "Hopefully, Nvidia added to Hugging Face `transformer` library a new model called `QDQBert` few weeks ago.\n",
    "Basically, it's a vanilla `Bert` architecture which supports INT-8 quantization.\n",
    "It doesn't support moedern architectures out of the box, like `Albert`, `Roberta`, `deberta` or `Electra`.\n",
    "Nvidia also provide a demo dedicated to the SQuaD task.\n",
    "\n",
    "This open the door to extension of the approach to other architectures.\n",
    "\n",
    "To be both simple and cover most use cases, in this notebook we will see:\n",
    "\n",
    "* how to perform GPU quantization on **any** transformer model (not just Bert)\n",
    "* how to apply quantization to a common task like classification (which is easier to understand than question answering)\n",
    "* measure performance gain (latency)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project setup\n",
    "\n",
    "### Dependencies installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We install `master` branch of `transfomers` library to use a new model: **QDQBert** and `transformer-deploy` to leverage `TensorRT` models (TensorRT API is not something simple to master, it's highly advised to use a wrapper). Your machine should have Nvidia CUDA 11.X, TensorRT 8.2.1 and cuBLAS installed. It's said to be tricky to install, in my experience, just follow Nvidia instructions **and nothing else**, it should work out of the box. Docker image with TensorRT 8.2.1 has not yet been released, this notebook will be updated when it's ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "MOsHUjgdIrIW"
   },
   "outputs": [],
   "source": [
    "#! pip3 install transformers datasets sklearn\n",
    "#! pip3 install git+ssh://git@github.com/ELS-RD/transformer-deploy\n",
    "#! pip3 install git+ssh://git@github.com/NVIDIA/TensorRT#egg=pytorch-quantization\\&subdirectory=tools/pytorch-quantization/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the GPU is enabled and usable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2OzrD4f-3ydk",
    "outputId": "54cc2ea6-6969-4e01-f9f9-78c5fc91ff85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec 28 13:48:07 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 495.44       Driver Version: 495.44       CUDA Version: 11.5     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:03:00.0  On |                  N/A |\r\n",
      "| 35%   41C    P8    28W / 350W |    254MiB / 24267MiB |      7%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A      1604      G   /usr/lib/xorg/Xorg                161MiB |\r\n",
      "|    0   N/A  N/A      8473      G   /usr/bin/gnome-shell               39MiB |\r\n",
      "|    0   N/A  N/A    106329      G   ..._18576.log --shared-files       10MiB |\r\n",
      "|    0   N/A  N/A    110356      G   ...AAAAAAAAA= --shared-files       39MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "ac14ba24dcf3404db9fd303dbb24d7a5",
      "4e91efae49b64f038fd3fbfcfd2be510",
      "17b83e0d0fb947d7bf20319ff930e8fc",
      "1da1d80871f545bbb21bf5a84d2120a0",
      "c593f2e45e244637821cc5721788bf2c",
      "cbbb20b5d01a4450bfb8dfbf8048d64f",
      "854cfd13416543fba8221093b903658b",
      "7ec6da801d0d45c4bb80eeab5518e124",
      "8585eab4b3fe4992bd7e7c4596e2483b",
      "990482eebca2424bb5ecbd114007e02c",
      "c92a19dfa84142af91522bc22f21fca6",
      "78601982b0e04b80adaa502db2ef685a",
      "167874df55014291be95cd390b1e60d3",
      "d6426fea2eda41dd9a31cb3f35b0877e",
      "163146c2f23440bcbf782116a35b5684",
      "0dab554959dc44b3b313ee8ae91ca88d",
      "f651eecbb6d44c24820cf6fe5ab92e7b",
      "a51b461c062f4636bfa4b48823d0709b",
      "cced5f1cccc2400a8fbfd7a6eaedc666",
      "cf9597523c024514b9b3e66bc77e3fa8",
      "f01fdef82047471e8c1b780cae5379cc",
      "e1f08cf954ae4aea818c90d893486c77"
     ]
    },
    "id": "KPMoLPBn_1vN",
    "outputId": "58dca4e7-fc5c-4fd1-a8d4-755aa1e956cb"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "from typing import Dict, List\n",
    "from typing import OrderedDict as OD\n",
    "from typing import Union\n",
    "\n",
    "import datasets\n",
    "import numpy as np\n",
    "import pycuda.autoinit\n",
    "import tensorrt as trt\n",
    "import torch\n",
    "import transformers\n",
    "from datasets import load_dataset, load_metric\n",
    "from pycuda._driver import Stream\n",
    "from tensorrt.tensorrt import IExecutionContext, Logger, Runtime\n",
    "from pytorch_quantization import nn as quant_nn\n",
    "\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    IntervalStrategy,\n",
    "    PreTrainedModel,\n",
    "    PreTrainedTokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "\n",
    "from transformer_deploy.backends.ort_utils import (\n",
    "    convert_to_onnx,\n",
    "    convert_to_quant_onnx,\n",
    "    cpu_quantization,\n",
    "    create_model_for_provider,\n",
    "    optimize_onnx,\n",
    ")\n",
    "from transformer_deploy.backends.trt_utils import build_engine, get_binding_idxs, infer_tensorrt\n",
    "from transformer_deploy.benchmarks.utils import print_timings, track_infer_time\n",
    "from transformer_deploy.QDQModels.calibration_utils import QATCalibrate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set logging to `error` level to ease readability of this `notebook` on Github."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_level = logging.ERROR\n",
    "logging.getLogger().setLevel(log_level)\n",
    "datasets.utils.logging.set_verbosity(log_level)\n",
    "transformers.utils.logging.set_verbosity(log_level)\n",
    "transformers.utils.logging.enable_default_handler()\n",
    "transformers.utils.logging.enable_explicit_format()\n",
    "trt_logger: Logger = trt.Logger(trt.Logger.ERROR)\n",
    "transformers.logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rEJBSTyZIrIb"
   },
   "source": [
    "### Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part is inspired from an [official Notebooks from Hugging Face](https://github.com/huggingface/notebooks/blob/master/examples/text_classification.ipynb).\n",
    "\n",
    "There is nothing special to do. Define the task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "zVvslsfMIrIh"
   },
   "outputs": [],
   "source": [
    "model_name = \"roberta-base\"\n",
    "task = \"mnli\"\n",
    "num_labels = 3\n",
    "batch_size = 32\n",
    "max_seq_len = 256\n",
    "validation_key = \"validation_matched\"\n",
    "timings: Dict[str, List[float]] = dict()\n",
    "runtime: Runtime = trt.Runtime(trt_logger)\n",
    "profile_index = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W7QYTpxXIrIl"
   },
   "source": [
    "Preprocess data (task specific):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "IreSlFmlIrIm"
   },
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"premise\"], examples[\"hypothesis\"], truncation=True, padding=\"max_length\", max_length=max_seq_len\n",
    "    )\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    if task != \"stsb\":\n",
    "        predictions = np.argmax(predictions, axis=1)\n",
    "    else:\n",
    "        predictions = predictions[:, 0]\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "\n",
    "def convert_tensor(data: OD[str, List[List[int]]], output: str) -> OD[str, Union[np.ndarray, torch.Tensor]]:\n",
    "    input: OD[str, Union[np.ndarray, torch.Tensor]] = OrderedDict()\n",
    "    for k in [\"input_ids\", \"attention_mask\", \"token_type_ids\"]:\n",
    "        if k in data:\n",
    "            v = data[k]\n",
    "            if output == \"torch\":\n",
    "                value = torch.tensor(v, dtype=torch.long, device=\"cuda\")\n",
    "            elif output == \"np\":\n",
    "                value = np.asarray(v, dtype=np.int32)\n",
    "            else:\n",
    "                raise Exception(f\"unknown output type: {output}\")\n",
    "            input[k] = value\n",
    "    return input\n",
    "\n",
    "\n",
    "def measure_accuracy(infer, int64: bool) -> float:\n",
    "    outputs = list()\n",
    "    for start_index in range(0, len(encoded_dataset[validation_key]), batch_size):\n",
    "        end_index = start_index + batch_size\n",
    "        data = encoded_dataset[validation_key][start_index:end_index]\n",
    "        inputs: OD[str, np.ndarray] = convert_tensor(data=data, output=\"np\")\n",
    "        if int64:\n",
    "            for k, v in inputs.items():\n",
    "                inputs[k] = v.astype(np.int64)\n",
    "        output = infer(inputs)\n",
    "        output = np.argmax(output[0], axis=1).astype(int).tolist()\n",
    "        outputs.extend(output)\n",
    "    return np.mean(np.array(outputs) == np.array(validation_labels))\n",
    "\n",
    "\n",
    "def get_trainer(model: PreTrainedModel) -> Trainer:\n",
    "    trainer = Trainer(\n",
    "        model,\n",
    "        args,\n",
    "        train_dataset=encoded_dataset[\"train\"],\n",
    "        eval_dataset=encoded_dataset[validation_key],\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    transformers.logging.set_verbosity_error()\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8e98128f3c2444080dc22b6b859de1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9204fe779b0a4154a24c62d13fb04c18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer: PreTrainedTokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "\n",
    "dataset = load_dataset(\"glue\", task)\n",
    "metric = load_metric(\"glue\", task)\n",
    "\n",
    "encoded_dataset = dataset.map(preprocess_function, batched=True)\n",
    "validation_labels = [item[\"label\"] for item in encoded_dataset[validation_key]]\n",
    "\n",
    "nb_step = 1000\n",
    "strategy = IntervalStrategy.STEPS\n",
    "args = TrainingArguments(\n",
    "    f\"{model_name}-{task}\",\n",
    "    evaluation_strategy=strategy,\n",
    "    eval_steps=nb_step,\n",
    "    logging_steps=nb_step,\n",
    "    save_steps=nb_step,\n",
    "    save_strategy=strategy,\n",
    "    learning_rate=1e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size * 2,\n",
    "    num_train_epochs=1,\n",
    "    fp16=True,\n",
    "    group_by_length=True,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=[],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Standard) fine-tuning model\n",
    "\n",
    "Now that our data are ready, we can download/fine tune the pretrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:439] 2021-12-27 09:19:51,063 >> Using amp half precision backend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6605, 'learning_rate': 9.1875814863103e-06, 'epoch': 0.08}\n",
      "{'eval_loss': 0.4653007388114929, 'eval_accuracy': 0.8183392766174223, 'eval_runtime': 18.2981, 'eval_samples_per_second': 536.393, 'eval_steps_per_second': 8.416, 'epoch': 0.08}\n",
      "{'loss': 0.4956, 'learning_rate': 8.372718383311604e-06, 'epoch': 0.16}\n",
      "{'eval_loss': 0.4208127558231354, 'eval_accuracy': 0.8346408558329088, 'eval_runtime': 18.3709, 'eval_samples_per_second': 534.268, 'eval_steps_per_second': 8.383, 'epoch': 0.16}\n",
      "{'loss': 0.4662, 'learning_rate': 7.557855280312908e-06, 'epoch': 0.24}\n",
      "{'eval_loss': 0.42171549797058105, 'eval_accuracy': 0.8358634742740703, 'eval_runtime': 18.3642, 'eval_samples_per_second': 534.464, 'eval_steps_per_second': 8.386, 'epoch': 0.24}\n",
      "{'loss': 0.4458, 'learning_rate': 6.7429921773142115e-06, 'epoch': 0.33}\n",
      "{'eval_loss': 0.3808833658695221, 'eval_accuracy': 0.8527763627101376, 'eval_runtime': 18.3578, 'eval_samples_per_second': 534.649, 'eval_steps_per_second': 8.389, 'epoch': 0.33}\n",
      "{'loss': 0.4295, 'learning_rate': 5.9289439374185145e-06, 'epoch': 0.41}\n",
      "{'eval_loss': 0.383415549993515, 'eval_accuracy': 0.851044319918492, 'eval_runtime': 18.3946, 'eval_samples_per_second': 533.58, 'eval_steps_per_second': 8.372, 'epoch': 0.41}\n",
      "{'loss': 0.4193, 'learning_rate': 5.1148956975228174e-06, 'epoch': 0.49}\n",
      "{'eval_loss': 0.3880891799926758, 'eval_accuracy': 0.8494141619969434, 'eval_runtime': 18.4347, 'eval_samples_per_second': 532.418, 'eval_steps_per_second': 8.354, 'epoch': 0.49}\n",
      "{'loss': 0.4166, 'learning_rate': 4.30003259452412e-06, 'epoch': 0.57}\n",
      "{'eval_loss': 0.3630894124507904, 'eval_accuracy': 0.8582781456953642, 'eval_runtime': 18.5126, 'eval_samples_per_second': 530.181, 'eval_steps_per_second': 8.319, 'epoch': 0.57}\n",
      "{'loss': 0.4111, 'learning_rate': 3.4851694915254244e-06, 'epoch': 0.65}\n",
      "{'eval_loss': 0.3584975004196167, 'eval_accuracy': 0.8596026490066225, 'eval_runtime': 18.4771, 'eval_samples_per_second': 531.198, 'eval_steps_per_second': 8.335, 'epoch': 0.65}\n",
      "{'loss': 0.4002, 'learning_rate': 2.6711212516297265e-06, 'epoch': 0.73}\n",
      "{'eval_loss': 0.36166584491729736, 'eval_accuracy': 0.8625573102394295, 'eval_runtime': 18.489, 'eval_samples_per_second': 530.857, 'eval_steps_per_second': 8.329, 'epoch': 0.73}\n",
      "{'loss': 0.3938, 'learning_rate': 1.8562581486310302e-06, 'epoch': 0.81}\n",
      "{'eval_loss': 0.354215145111084, 'eval_accuracy': 0.8649006622516556, 'eval_runtime': 18.4614, 'eval_samples_per_second': 531.651, 'eval_steps_per_second': 8.342, 'epoch': 0.81}\n",
      "{'loss': 0.3951, 'learning_rate': 1.0413950456323338e-06, 'epoch': 0.9}\n",
      "{'eval_loss': 0.3511120676994324, 'eval_accuracy': 0.8663270504330107, 'eval_runtime': 18.512, 'eval_samples_per_second': 530.197, 'eval_steps_per_second': 8.319, 'epoch': 0.9}\n",
      "{'loss': 0.3972, 'learning_rate': 2.265319426336376e-07, 'epoch': 0.98}\n",
      "{'eval_loss': 0.34958672523498535, 'eval_accuracy': 0.8661232806928171, 'eval_runtime': 18.4826, 'eval_samples_per_second': 531.04, 'eval_steps_per_second': 8.332, 'epoch': 0.98}\n",
      "{'train_runtime': 2606.7651, 'train_samples_per_second': 150.647, 'train_steps_per_second': 4.708, 'train_loss': 0.44322973124517767, 'epoch': 1.0}\n",
      "{'eval_loss': 0.3511120676994324, 'eval_accuracy': 0.8663270504330107, 'eval_runtime': 18.5143, 'eval_samples_per_second': 530.13, 'eval_steps_per_second': 8.318, 'epoch': 1.0}\n",
      "{'eval_loss': 0.3511120676994324, 'eval_accuracy': 0.8663270504330107, 'eval_runtime': 18.5143, 'eval_samples_per_second': 530.13, 'eval_steps_per_second': 8.318, 'epoch': 1.0}\n"
     ]
    }
   ],
   "source": [
    "model_fp16: PreTrainedModel = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n",
    "trainer = get_trainer(model_fp16)\n",
    "transformers.logging.set_verbosity_error()\n",
    "trainer.train()\n",
    "print(trainer.evaluate())\n",
    "\n",
    "model_fp16.save_pretrained(\"model_trained_fp16\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Add quantization support to any model\n",
    "\n",
    "The idea is to take the source code of a specific model and add automatically `QDQ` nodes. That way, quantization will work out of the box for this architecture.\n",
    "The process is based on Python AST modification, basically we parse the source code in RAM, we convert it to a tree, then we patch the tree to add the QDQ nodes and we replace, in RAM, the original module source code.\n",
    "\n",
    "In theory it works for any model. However, not related to quantization, some models are not fully compliant with `TensorRT` (unsupported operators, etc.).\n",
    "For those models, we rewrite some part of the source code, these patch are manually written but are applied to model at run time (like the AST manipulation).\n",
    "\n",
    "> concrete examples on `Roberta` architecture: in HF library, there is a `cumsum` in the position embedding generation. Something very simple. It takes as input an integer tensor and output an integer tensor. It happens that the `cumsum` operator from TensorRT supports float but not integer (https://github.com/onnx/onnx-tensorrt/blob/master/docs/operators.md). It leads to a crash during the model conversion with a strange error message. Converting the input to float tensor fix the issue. Not complex, but requires some knowledge.\n",
    "\n",
    "The process below is:\n",
    "\n",
    "* Calibrate\n",
    "* Quantization Aware training (QAT)\n",
    "\n",
    "> there are many ways to get a QDQ model, you can modify Pytorch source code (including doing it at runtime like here), patch ONNX graph (this approach is used at Microsoft for instance but only support PTQ, not QAT as ONNX file can't be trained on Pytorch for now) or leverage the new FX Pytorch interface (it's a bit experimental and it seems to miss some feature to support Nvida QAT library). Modifying the source code is the most straight forward so we choosed to do it that way.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Post Training Quantization (PTQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "A PTQ is basically a finetuned model where we add quantization nodes and that we calibrate.\n",
    "\n",
    "Calibration is a key step in the static quantization process. On its quality depends the final accuracy (the inference speed will stay the same).  \n",
    "Moreover, a good PTQ is a good basis for a good Quantization Aware Training (QAT).\n",
    "\n",
    "By calling `with QATCalibrate(...) as qat:`, the lib will patch transformer model AST (source code) in RAM, basically adding quantization support to each model.\n",
    "\n",
    "#### Calibration percentile grid search\n",
    "\n",
    "One of the thing we try to guess during the calibration is what range of tensor values capture most of the information stored in the model. Indeed, a FP32 tensor can store at the same time very large and very small values, we obviously can't do the same with a 8-bits integer tensors and a scale. 8-bits integer can only encode 255 values so we need to fix some limits and say, if a value is outside our limits, it just takes a maximum value instead of its real one. For instance, if we say our range is -1000 to +1000 and a tensor contain the value +4000, it will be replaced by the maximum value, +1000.\n",
    "\n",
    "As said before, we will use the histogram method to find the perfect range. We also need to choose a percentile. Usually, you will choose something very close to 100.\n",
    "\n",
    "If the percentile is too small, we put too many values outside the final range. Values outside the range will be replaced by a single maximum value and you loose some granularity in model weights.\n",
    "\n",
    "If the percetile is too big, your range will be very large and because 8-bits signed integers can only encode values between -127 to +127, you loose in granularity.\n",
    "\n",
    "Therefore, we launch a grid search on percentile hyper parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:439] 2021-12-27 17:25:51,070 >> Using amp half precision backend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentile: 99.9\n",
      "{'eval_loss': 0.47421666979789734, 'eval_accuracy': 0.8121242995415181, 'eval_runtime': 47.9158, 'eval_samples_per_second': 204.839, 'eval_steps_per_second': 3.214}\n",
      "{'eval_loss': 0.47421666979789734, 'eval_accuracy': 0.8121242995415181, 'eval_runtime': 47.9158, 'eval_samples_per_second': 204.839, 'eval_steps_per_second': 3.214}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:439] 2021-12-27 17:30:13,795 >> Using amp half precision backend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentile: 99.99\n",
      "{'eval_loss': 0.3841923773288727, 'eval_accuracy': 0.8487009679062659, 'eval_runtime': 46.6715, 'eval_samples_per_second': 210.3, 'eval_steps_per_second': 3.3}\n",
      "{'eval_loss': 0.3841923773288727, 'eval_accuracy': 0.8487009679062659, 'eval_runtime': 46.6715, 'eval_samples_per_second': 210.3, 'eval_steps_per_second': 3.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:439] 2021-12-27 17:34:34,280 >> Using amp half precision backend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentile: 99.999\n",
      "{'eval_loss': 0.3939284086227417, 'eval_accuracy': 0.850636780438105, 'eval_runtime': 49.1138, 'eval_samples_per_second': 199.842, 'eval_steps_per_second': 3.136}\n",
      "{'eval_loss': 0.3939284086227417, 'eval_accuracy': 0.850636780438105, 'eval_runtime': 49.1138, 'eval_samples_per_second': 199.842, 'eval_steps_per_second': 3.136}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:439] 2021-12-27 17:38:54,289 >> Using amp half precision backend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentile: 99.9999\n",
      "{'eval_loss': 1.0285985469818115, 'eval_accuracy': 0.4956698930208864, 'eval_runtime': 48.0849, 'eval_samples_per_second': 204.118, 'eval_steps_per_second': 3.203}\n",
      "{'eval_loss': 1.0285985469818115, 'eval_accuracy': 0.4956698930208864, 'eval_runtime': 48.0849, 'eval_samples_per_second': 204.118, 'eval_steps_per_second': 3.203}\n"
     ]
    }
   ],
   "source": [
    "for percentile in [99.9, 99.99, 99.999, 99.9999]:\n",
    "    with QATCalibrate(method=\"histogram\", percentile=percentile) as qat:\n",
    "        model_q: PreTrainedModel = AutoModelForSequenceClassification.from_pretrained(\n",
    "            \"model_trained_fp16\", num_labels=num_labels\n",
    "        )\n",
    "        model_q = model_q.cuda()\n",
    "        qat.setup_model_qat(model_q)  # prepare quantizer to any model\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for start_index in range(0, 128, batch_size):\n",
    "                end_index = start_index + batch_size\n",
    "                data = encoded_dataset[\"train\"][start_index:end_index]\n",
    "                input_torch = {\n",
    "                    k: torch.tensor(v, dtype=torch.long, device=\"cuda\")\n",
    "                    for k, v in data.items()\n",
    "                    if k in [\"input_ids\", \"attention_mask\", \"token_type_ids\"]\n",
    "                }\n",
    "                model_q(**input_torch)\n",
    "    trainer = get_trainer(model_q)\n",
    "    print(f\"percentile: {percentile}\")\n",
    "    print(trainer.evaluate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the chosen percentile value has a high impact on the final accuracy.\n",
    "\n",
    "For the rest of the notebook, we apply the `99.999` percentile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:439] 2021-12-28 13:52:09,215 >> Using amp half precision backend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3939284086227417, 'eval_accuracy': 0.850636780438105, 'eval_runtime': 46.5572, 'eval_samples_per_second': 210.816, 'eval_steps_per_second': 3.308}\n",
      "{'eval_loss': 0.3939284086227417, 'eval_accuracy': 0.850636780438105, 'eval_runtime': 46.5572, 'eval_samples_per_second': 210.816, 'eval_steps_per_second': 3.308}\n"
     ]
    }
   ],
   "source": [
    "with QATCalibrate(method=\"histogram\", percentile=99.999) as qat:\n",
    "    model_q: PreTrainedModel = AutoModelForSequenceClassification.from_pretrained(\n",
    "        \"model_trained_fp16\", num_labels=num_labels\n",
    "    )\n",
    "    model_q = model_q.cuda()\n",
    "    qat.setup_model_qat(model_q)  # prepare quantizer to any model\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for start_index in range(0, 128, batch_size):\n",
    "            end_index = start_index + batch_size\n",
    "            data = encoded_dataset[\"train\"][start_index:end_index]\n",
    "            input_torch = {\n",
    "                k: torch.tensor(v, dtype=torch.long, device=\"cuda\")\n",
    "                for k, v in data.items()\n",
    "                if k in [\"input_ids\", \"attention_mask\", \"token_type_ids\"]\n",
    "            }\n",
    "            model_q(**input_torch)\n",
    "trainer = get_trainer(model_q)\n",
    "print(trainer.evaluate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Per layer quantization analysis\n",
    "\n",
    "Below we will run a sensitivity analysis, by enabling quantization of one layer at a time and measuring the accuracy. That way we will be able to detect if the quantization of a specific layer has a larger cost on accuracy than other layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer.0\n",
      "{'eval_loss': 0.35163024067878723, 'eval_accuracy': 0.8663270504330107, 'eval_runtime': 20.695, 'eval_samples_per_second': 474.27, 'eval_steps_per_second': 7.441}\n",
      "----\n",
      "layer.1\n",
      "{'eval_loss': 0.3527306318283081, 'eval_accuracy': 0.8661232806928171, 'eval_runtime': 26.1334, 'eval_samples_per_second': 375.573, 'eval_steps_per_second': 5.893}\n",
      "----\n",
      "layer.2\n",
      "{'eval_loss': 0.3557673394680023, 'eval_accuracy': 0.8629648497198166, 'eval_runtime': 21.1364, 'eval_samples_per_second': 464.366, 'eval_steps_per_second': 7.286}\n",
      "----\n",
      "layer.3\n",
      "{'eval_loss': 0.3551430106163025, 'eval_accuracy': 0.8649006622516556, 'eval_runtime': 20.9252, 'eval_samples_per_second': 469.051, 'eval_steps_per_second': 7.36}\n",
      "----\n",
      "layer.4\n",
      "{'eval_loss': 0.35053929686546326, 'eval_accuracy': 0.8649006622516556, 'eval_runtime': 21.05, 'eval_samples_per_second': 466.271, 'eval_steps_per_second': 7.316}\n",
      "----\n",
      "layer.5\n",
      "{'eval_loss': 0.35701483488082886, 'eval_accuracy': 0.865206316861946, 'eval_runtime': 20.9236, 'eval_samples_per_second': 469.088, 'eval_steps_per_second': 7.36}\n",
      "----\n",
      "layer.6\n",
      "{'eval_loss': 0.35283517837524414, 'eval_accuracy': 0.8649006622516556, 'eval_runtime': 20.8179, 'eval_samples_per_second': 471.469, 'eval_steps_per_second': 7.397}\n",
      "----\n",
      "layer.7\n",
      "{'eval_loss': 0.35288652777671814, 'eval_accuracy': 0.866632705043301, 'eval_runtime': 20.7823, 'eval_samples_per_second': 472.277, 'eval_steps_per_second': 7.41}\n",
      "----\n",
      "layer.8\n",
      "{'eval_loss': 0.35080182552337646, 'eval_accuracy': 0.8672440142638819, 'eval_runtime': 20.737, 'eval_samples_per_second': 473.308, 'eval_steps_per_second': 7.426}\n",
      "----\n",
      "layer.9\n",
      "{'eval_loss': 0.3503498136997223, 'eval_accuracy': 0.8673458991339786, 'eval_runtime': 20.8899, 'eval_samples_per_second': 469.843, 'eval_steps_per_second': 7.372}\n",
      "----\n",
      "layer.10\n",
      "{'eval_loss': 0.3510246276855469, 'eval_accuracy': 0.8658176260825268, 'eval_runtime': 20.8428, 'eval_samples_per_second': 470.905, 'eval_steps_per_second': 7.389}\n",
      "----\n",
      "layer.11\n",
      "{'eval_loss': 0.3509054183959961, 'eval_accuracy': 0.8656138563423331, 'eval_runtime': 20.8451, 'eval_samples_per_second': 470.853, 'eval_steps_per_second': 7.388}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "from pytorch_quantization import nn as quant_nn\n",
    "\n",
    "for i in range(12):\n",
    "    layer_name = f\"layer.{i}\"\n",
    "    print(layer_name)\n",
    "    for name, module in model_q.named_modules():\n",
    "        if isinstance(module, quant_nn.TensorQuantizer):\n",
    "            if layer_name in name:\n",
    "                module.enable_quant()\n",
    "            else:\n",
    "                module.disable_quant()\n",
    "    trainer.evaluate()\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that quantization of layers 2 to 6 has the largest accuracy impact.\n",
    "\n",
    "\n",
    "#### Operator quantization analysis\n",
    "\n",
    "\n",
    "Below we will run a sensitivity analysis, by enabling quantization of one operator type at a time and measuring the accuracy. That way we will be able to detect if a specific operator has a larger cost on accuracy. On Roberta we only quantize `matmul` and `LayerNorm`, so we test both candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matmul\n",
      "{'eval_loss': 0.35049352049827576, 'eval_accuracy': 0.8658176260825268, 'eval_runtime': 26.1972, 'eval_samples_per_second': 374.659, 'eval_steps_per_second': 5.878}\n",
      "----\n",
      "layernorm\n",
      "{'eval_loss': 0.35847699642181396, 'eval_accuracy': 0.8597045338767193, 'eval_runtime': 24.3004, 'eval_samples_per_second': 403.903, 'eval_steps_per_second': 6.337}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for op in [\"matmul\", \"layernorm\"]:\n",
    "    for name, module in model_q.named_modules():\n",
    "        if isinstance(module, quant_nn.TensorQuantizer):\n",
    "            if op in name:\n",
    "                module.enable_quant()\n",
    "            else:\n",
    "                module.disable_quant()\n",
    "    print(op)\n",
    "    trainer.evaluate()\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that `LayerNorm` quantization has a significant accuracy cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disable roberta.encoder.layer.2.output.layernorm_quantizer_0\n",
      "disable roberta.encoder.layer.2.output.layernorm_quantizer_1\n",
      "disable roberta.encoder.layer.3.output.layernorm_quantizer_0\n",
      "disable roberta.encoder.layer.3.output.layernorm_quantizer_1\n",
      "disable roberta.encoder.layer.4.output.layernorm_quantizer_0\n",
      "disable roberta.encoder.layer.4.output.layernorm_quantizer_1\n",
      "disable roberta.encoder.layer.6.output.layernorm_quantizer_0\n",
      "disable roberta.encoder.layer.6.output.layernorm_quantizer_1\n",
      "{'eval_loss': 0.3660135269165039, 'eval_accuracy': 0.8618441161487519, 'eval_runtime': 45.9324, 'eval_samples_per_second': 213.684, 'eval_steps_per_second': 3.353}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.3660135269165039,\n",
       " 'eval_accuracy': 0.8618441161487519,\n",
       " 'eval_runtime': 45.9324,\n",
       " 'eval_samples_per_second': 213.684,\n",
       " 'eval_steps_per_second': 3.353}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disable_layer_names = [\"layer.2\", \"layer.3\", \"layer.4\", \"layer.6\"]\n",
    "\n",
    "for name, module in model_q.named_modules():\n",
    "    if isinstance(module, quant_nn.TensorQuantizer):\n",
    "        if any([f\"{l}.output.layernorm\" in name for l in disable_layer_names]):\n",
    "            print(f\"disable {name}\")\n",
    "            module.disable_quant()\n",
    "        else:\n",
    "            module.enable_quant()\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By just disabling quantization for a single operator on a few layers, we keep most of the performance boost (quantization) but retrieve more than 1 point of accuracy. It's also possible to perform an analysis per quantizer to get a smaller granularity but it's a bit slow to run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Quantization Aware Training (QAT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We retrain the model with 1/10 or 1/100 of the original learning rate. Our goal is to retrieve most of the original accuracy. Usually you can use a part of the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:439] 2021-12-28 13:54:41,146 >> Using amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "args.learning_rate = 1e-7\n",
    "trainer = get_trainer(model_q)\n",
    "trainer.train()\n",
    "print(trainer.evaluate())\n",
    "model_q.save_pretrained(\"model-qat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export a `QDQ Pytorch` model on `ONNX`, we need to enable fake quantization mode from Pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = encoded_dataset[\"train\"][1:3]\n",
    "input_torch = convert_tensor(data, output=\"torch\")\n",
    "convert_to_quant_onnx(model_pytorch=model_q, output_path=\"model_qat.onnx\", inputs_pytorch=input_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "del model_q\n",
    "QATCalibrate.restore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert `ONNX` graph to `TensorRT` engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "engine = build_engine(\n",
    "    runtime=runtime,\n",
    "    onnx_file_path=\"model_qat.onnx\",\n",
    "    logger=trt_logger,\n",
    "    min_shape=(1, max_seq_len),\n",
    "    optimal_shape=(batch_size, max_seq_len),\n",
    "    max_shape=(batch_size, max_seq_len),\n",
    "    workspace_size=10000 * 1024 * 1024,\n",
    "    fp16=True,\n",
    "    int8=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# same conversion from the terminal\n",
    "# ,token_type_ids:32x256\n",
    "# !/usr/src/tensorrt/bin/trtexec --onnx=model_qat.onnx --shapes=input_ids:32x256,attention_mask:32x256 --best --workspace=10000 --saveEngine=\"test.plan\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare input and output buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "stream: Stream = pycuda.driver.Stream()\n",
    "context: IExecutionContext = engine.create_execution_context()\n",
    "context.set_optimization_profile_async(profile_index=profile_index, stream_handle=stream.handle)\n",
    "input_binding_idxs, output_binding_idxs = get_binding_idxs(engine, profile_index)  # type: List[int], List[int]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = encoded_dataset[\"train\"][0:batch_size]\n",
    "input_torch: OD[str, torch.Tensor] = convert_tensor(data=data, output=\"torch\")\n",
    "input_np: OD[str, np.ndarray] = convert_tensor(data=data, output=\"np\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference on `TensorRT`\n",
    "\n",
    "We first check that inference is working correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 0.3555643 ,  2.491011  , -2.3507996 ],\n",
      "       [ 2.8667073 , -1.095514  , -1.5070786 ],\n",
      "       [ 2.0140486 ,  0.3065021 , -1.9585495 ],\n",
      "       [ 2.2055676 ,  0.29951063, -2.2425632 ],\n",
      "       [ 2.7326503 , -0.18695493, -2.2924087 ],\n",
      "       [ 4.1053786 , -1.0233743 , -2.7114294 ],\n",
      "       [-3.583274  ,  2.672273  ,  1.2139126 ],\n",
      "       [ 4.0707603 , -1.1044825 , -2.4349666 ],\n",
      "       [ 0.322169  , -1.1554759 ,  0.89057773],\n",
      "       [-3.345267  , -0.3590604 ,  3.3627117 ],\n",
      "       [ 3.7562432 , -0.6960117 , -2.6524336 ],\n",
      "       [-2.3663151 , -1.3245198 ,  3.6388462 ],\n",
      "       [-2.4342794 ,  3.723619  , -0.8023841 ],\n",
      "       [-2.0167181 ,  1.9331539 ,  0.21542098],\n",
      "       [ 0.42074788, -0.8792107 ,  0.4193994 ],\n",
      "       [ 1.4081649 , -1.0378735 , -0.01496227],\n",
      "       [ 4.0923953 , -0.5934528 , -2.997319  ],\n",
      "       [-2.7030241 , -2.2501273 ,  4.499137  ],\n",
      "       [-3.3829408 , -0.6287503 ,  3.8455353 ],\n",
      "       [-2.1994479 ,  4.069879  , -1.3168232 ],\n",
      "       [ 4.007247  , -0.6379149 , -2.882104  ],\n",
      "       [ 3.2731495 ,  0.43009546, -3.303371  ],\n",
      "       [-3.1957986 , -1.1686544 ,  3.9192812 ],\n",
      "       [ 3.847499  , -0.21450461, -3.1094387 ],\n",
      "       [ 3.891227  , -1.5500838 , -1.9010733 ],\n",
      "       [-1.2735529 ,  1.2519035 ,  0.06569673],\n",
      "       [-3.333609  ,  0.18055555,  2.9410741 ],\n",
      "       [-2.6346335 ,  3.7274408 , -0.5079398 ],\n",
      "       [-3.7373166 , -0.27877253,  3.6565838 ],\n",
      "       [ 3.7639084 , -0.61928964, -2.756327  ],\n",
      "       [ 3.3646271 ,  0.01173172, -2.7986214 ],\n",
      "       [ 3.6130972 , -0.2016022 , -3.0241413 ]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "tensorrt_output = infer_tensorrt(\n",
    "    context=context,\n",
    "    host_inputs=input_np,\n",
    "    input_binding_idxs=input_binding_idxs,\n",
    "    output_binding_idxs=output_binding_idxs,\n",
    "    stream=stream,\n",
    ")\n",
    "print(tensorrt_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measure of the accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8585838003056546"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infer_trt = lambda inputs: infer_tensorrt(\n",
    "    context=context,\n",
    "    host_inputs=inputs,\n",
    "    input_binding_idxs=input_binding_idxs,\n",
    "    output_binding_idxs=output_binding_idxs,\n",
    "    stream=stream,\n",
    ")\n",
    "\n",
    "measure_accuracy(infer=infer_trt, int64=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Latency measures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TensorRT (INT-8)] mean=17.92ms, sd=0.53ms, min=17.21ms, max=20.23ms, median=17.73ms, 95p=19.27ms, 99p=19.82ms\n"
     ]
    }
   ],
   "source": [
    "time_buffer = list()\n",
    "for _ in range(100):\n",
    "    with track_infer_time(time_buffer):\n",
    "        _ = infer_tensorrt(\n",
    "            context=context,\n",
    "            host_inputs=input_np,\n",
    "            input_binding_idxs=input_binding_idxs,\n",
    "            output_binding_idxs=output_binding_idxs,\n",
    "            stream=stream,\n",
    "        )\n",
    "\n",
    "print_timings(name=\"TensorRT (INT-8)\", timings=time_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "del engine, context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will measure vanilla Pytorch inference on both FP32 and FP16 precision, it will be our baseline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pytorch (FP32)] mean=121.09ms, sd=1.05ms, min=120.22ms, max=125.82ms, median=120.84ms, 95p=123.41ms, 99p=124.63ms\n"
     ]
    }
   ],
   "source": [
    "baseline_model = AutoModelForSequenceClassification.from_pretrained(\"model_trained_fp16\", num_labels=num_labels)\n",
    "baseline_model = baseline_model.cuda()\n",
    "baseline_model = baseline_model.eval()\n",
    "\n",
    "data = encoded_dataset[\"train\"][0:batch_size]\n",
    "input_torch: OD[str, torch.Tensor] = convert_tensor(data=data, output=\"torch\")\n",
    "\n",
    "with torch.inference_mode():\n",
    "    for _ in range(30):\n",
    "        _ = baseline_model(**input_torch)\n",
    "        torch.cuda.synchronize()\n",
    "    time_buffer = list()\n",
    "    for _ in range(100):\n",
    "        with track_infer_time(time_buffer):\n",
    "            _ = baseline_model(**input_torch)\n",
    "            torch.cuda.synchronize()\n",
    "print_timings(name=\"Pytorch (FP32)\", timings=time_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    with torch.cuda.amp.autocast():\n",
    "        for _ in range(30):\n",
    "            _ = baseline_model(**input_torch)\n",
    "            torch.cuda.synchronize()\n",
    "        time_buffer = []\n",
    "        for _ in range(100):\n",
    "            with track_infer_time(time_buffer):\n",
    "                _ = baseline_model(**input_torch)\n",
    "                torch.cuda.synchronize()\n",
    "print_timings(name=\"Pytorch (FP16)\", timings=time_buffer)\n",
    "del baseline_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPU execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model = AutoModelForSequenceClassification.from_pretrained(\"model_trained_fp16\", num_labels=num_labels)\n",
    "baseline_model = baseline_model.eval()\n",
    "data = encoded_dataset[\"train\"][0:batch_size]\n",
    "input_torch: OD[str, torch.Tensor] = convert_tensor(data=data, output=\"torch\")\n",
    "input_torch_cpu = {k: v.to(\"cpu\") for k, v in input_torch.items()}\n",
    "\n",
    "torch.set_num_threads(os.cpu_count())\n",
    "\n",
    "with torch.inference_mode():\n",
    "    for _ in range(3):\n",
    "        _ = baseline_model(**input_torch_cpu)\n",
    "        torch.cuda.synchronize()\n",
    "    time_buffer = list()\n",
    "    for _ in range(10):\n",
    "        with track_infer_time(time_buffer):\n",
    "            _ = baseline_model(**input_torch_cpu)\n",
    "            torch.cuda.synchronize()\n",
    "print_timings(name=\"Pytorch (FP32) - CPU\", timings=time_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    with torch.cuda.amp.autocast():\n",
    "        for _ in range(3):\n",
    "            _ = baseline_model(**input_torch_cpu)\n",
    "            torch.cuda.synchronize()\n",
    "        time_buffer = []\n",
    "        for _ in range(10):\n",
    "            with track_infer_time(time_buffer):\n",
    "                _ = baseline_model(**input_torch_cpu)\n",
    "                torch.cuda.synchronize()\n",
    "print_timings(name=\"Pytorch (FP16) - CPU\", timings=time_buffer)\n",
    "del baseline_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we will perform dynamic quantization on CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_baseline_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"model_trained_fp16\", num_labels=num_labels\n",
    ")\n",
    "quantized_baseline_model = quantized_baseline_model.eval()\n",
    "quantized_baseline_model = torch.quantization.quantize_dynamic(\n",
    "    quantized_baseline_model, {torch.nn.Linear}, dtype=torch.qint8\n",
    ")\n",
    "\n",
    "with torch.inference_mode():\n",
    "    for _ in range(3):\n",
    "        _ = quantized_baseline_model(**input_torch_cpu)\n",
    "        torch.cuda.synchronize()\n",
    "    time_buffer = list()\n",
    "    for _ in range(10):\n",
    "        with track_infer_time(time_buffer):\n",
    "            _ = quantized_baseline_model(**input_torch_cpu)\n",
    "            torch.cuda.synchronize()\n",
    "print_timings(name=\"Pytorch (INT-8) - CPU\", timings=time_buffer)\n",
    "del quantized_baseline_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorRT baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we export our finetuned model, the purpose is to only check the performance on mixed precision (FP16, no quantization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "baseline_model = AutoModelForSequenceClassification.from_pretrained(\"model_trained_fp16\", num_labels=num_labels)\n",
    "baseline_model = baseline_model.cuda()\n",
    "convert_to_onnx(baseline_model, output_path=\"baseline.onnx\", inputs_pytorch=input_torch, opset=12)\n",
    "del baseline_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[libprotobuf WARNING google/protobuf/io/coded_stream.cc:604] Reading dangerously large protocol message.  If the message turns out to be larger than 2147483647 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.\n",
      "[libprotobuf WARNING google/protobuf/io/coded_stream.cc:81] The total number of bytes read was 556931338\n",
      "Unsupported ONNX data type: UINT8 (2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/26/2021-23:12:18] [TRT] [E] 4: [network.cpp::validate::2633] Error Code 4: Internal Error (Network must have at least one output)\n",
      "[12/26/2021-23:12:18] [TRT] [E] 2: [builder.cpp::buildSerializedNetwork::609] Error Code 2: Internal Error (Assertion enginePtr != nullptr failed. )\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "deserialize_cuda_engine(): incompatible function arguments. The following argument types are supported:\n    1. (self: tensorrt.tensorrt.Runtime, serialized_engine: buffer) -> tensorrt.tensorrt.ICudaEngine\n\nInvoked with: <tensorrt.tensorrt.Runtime object at 0x7f9867516c30>, None",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_1593728/3078764801.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m engine = build_engine(\n\u001B[0m\u001B[1;32m      2\u001B[0m     \u001B[0mruntime\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mruntime\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m     \u001B[0monnx_file_path\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"baseline.onnx\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m     \u001B[0mlogger\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtrt_logger\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m     \u001B[0mmin_shape\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmax_seq_len\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/workspace/fast_transformer/src/transformer_deploy/backends/trt_utils.py\u001B[0m in \u001B[0;36mbuild_engine\u001B[0;34m(runtime, onnx_file_path, logger, min_shape, optimal_shape, max_shape, workspace_size, fp16, int8)\u001B[0m\n\u001B[1;32m    138\u001B[0m                     \u001B[0mnetwork_definition\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfix_fp16_network\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnetwork_definition\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    139\u001B[0m                 \u001B[0mtrt_engine\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mbuilder\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbuild_serialized_network\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnetwork_definition\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mconfig\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 140\u001B[0;31m                 \u001B[0mengine\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mICudaEngine\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mruntime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdeserialize_cuda_engine\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrt_engine\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    141\u001B[0m                 \u001B[0;32massert\u001B[0m \u001B[0mengine\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"error during engine generation, check error messages above :-(\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    142\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0mengine\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: deserialize_cuda_engine(): incompatible function arguments. The following argument types are supported:\n    1. (self: tensorrt.tensorrt.Runtime, serialized_engine: buffer) -> tensorrt.tensorrt.ICudaEngine\n\nInvoked with: <tensorrt.tensorrt.Runtime object at 0x7f9867516c30>, None"
     ]
    }
   ],
   "source": [
    "engine = build_engine(\n",
    "    runtime=runtime,\n",
    "    onnx_file_path=\"baseline.onnx\",\n",
    "    logger=trt_logger,\n",
    "    min_shape=(batch_size, max_seq_len),\n",
    "    optimal_shape=(batch_size, max_seq_len),\n",
    "    max_shape=(batch_size, max_seq_len),\n",
    "    workspace_size=10000 * 1024 * 1024,\n",
    "    fp16=True,\n",
    "    int8=False,\n",
    ")\n",
    "stream: Stream = pycuda.driver.Stream()\n",
    "context: IExecutionContext = engine.create_execution_context()\n",
    "context.set_optimization_profile_async(profile_index=profile_index, stream_handle=stream.handle)\n",
    "input_binding_idxs, output_binding_idxs = get_binding_idxs(engine, profile_index)  # type: List[int], List[int]\n",
    "for _ in range(30):\n",
    "    _ = infer_tensorrt(\n",
    "        context=context,\n",
    "        host_inputs=input_np,\n",
    "        input_binding_idxs=input_binding_idxs,\n",
    "        output_binding_idxs=output_binding_idxs,\n",
    "        stream=stream,\n",
    "    )\n",
    "time_buffer = list()\n",
    "for _ in range(100):\n",
    "    with track_infer_time(time_buffer):\n",
    "        _ = infer_tensorrt(\n",
    "            context=context,\n",
    "            host_inputs=input_np,\n",
    "            input_binding_idxs=input_binding_idxs,\n",
    "            output_binding_idxs=output_binding_idxs,\n",
    "            stream=stream,\n",
    "        )\n",
    "\n",
    "print_timings(name=\"TensorRT (FP16)\", timings=time_buffer)\n",
    "del engine, context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ONNX Runtime baseline\n",
    "\n",
    "ONNX Runtime is the go to inference solution from Microsoft.\n",
    "\n",
    "The recent 1.10 version of ONNX Runtime (with TensorRT support) is still a bit buggy on transformer models, that is why we use the 1.9.0 version in the measures below.\n",
    "\n",
    "As before, CPU quantization is dynamic.\n",
    "Function `\n",
    "` will set ONNX Runtime to use all cores available and enable any possible optimizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot determine if 512 - sequence < 0\n",
      "Cannot determine if 512 - sequence < 0\n",
      "Cannot determine if 512 - sequence < 0\n",
      "Cannot determine if 512 - sequence < 0\n",
      "Cannot determine if 512 - sequence < 0\n",
      "Cannot determine if 512 - sequence < 0\n",
      "Cannot determine if 512 - sequence < 0\n",
      "Cannot determine if 512 - sequence < 0\n",
      "Cannot determine if 512 - sequence < 0\n",
      "Cannot determine if 512 - sequence < 0\n",
      "Cannot determine if 512 - sequence < 0\n",
      "Cannot determine if 512 - sequence < 0\n",
      "Cannot determine if 512 - sequence < 0\n",
      "Cannot determine if 512 - sequence < 0\n",
      "Cannot determine if 512 - sequence < 0\n",
      "Cannot determine if 512 - sequence < 0\n",
      "Cannot determine if 512 - sequence < 0\n",
      "Cannot determine if 512 - sequence < 0\n",
      "Cannot determine if 512 - sequence < 0\n",
      "Cannot determine if 512 - sequence < 0\n",
      "Cannot determine if 512 - sequence < 0\n",
      "Cannot determine if 512 - sequence < 0\n",
      "Cannot determine if 512 - sequence < 0\n",
      "Cannot determine if 512 - sequence < 0\n",
      "Cannot determine if 512 - sequence < 0\n",
      "Cannot determine if 512 - sequence < 0\n",
      "Cannot determine if 512 - sequence < 0\n",
      "Cannot determine if 512 - sequence < 0\n",
      "Cannot determine if 512 - sequence < 0\n",
      "Cannot determine if 512 - sequence < 0\n",
      "Cannot determine if 512 - sequence < 0\n",
      "Cannot determine if 512 - sequence < 0\n",
      "Cannot determine if 512 - sequence < 0\n",
      "Cannot determine if 512 - sequence < 0\n",
      "Cannot determine if 512 - sequence < 0\n",
      "Cannot determine if 512 - sequence < 0\n",
      "Cannot determine if 512 - sequence < 0\n",
      "Cannot determine if 512 - sequence < 0\n",
      "Cannot determine if 512 - sequence < 0\n",
      "Cannot determine if 512 - sequence < 0\n",
      "Cannot determine if 512 - sequence < 0\n",
      "Cannot determine if 512 - sequence < 0\n",
      "Cannot determine if 512 - sequence < 0\n",
      "Cannot determine if 512 - sequence < 0\n",
      "Cannot determine if 512 - sequence < 0\n",
      "Cannot determine if 512 - sequence < 0\n",
      "Cannot determine if 512 - sequence < 0\n",
      "Cannot determine if 512 - sequence < 0\n",
      "Cannot determine if 512 - sequence < 0\n",
      "Cannot determine if 512 - sequence < 0\n",
      "Cannot determine if 512 - sequence < 0\n",
      "Cannot determine if 512 - sequence < 0\n",
      "Cannot determine if 512 - sequence < 0\n",
      "Cannot determine if 512 - sequence < 0\n",
      "Cannot determine if 512 - sequence < 0\n",
      "Cannot determine if 512 - sequence < 0\n",
      "Cannot determine if 512 - sequence < 0\n",
      "Cannot determine if 512 - sequence < 0\n",
      "Cannot determine if 512 - sequence < 0\n",
      "Cannot determine if 512 - sequence < 0\n",
      "Cannot determine if 512 - sequence < 0\n",
      "Cannot determine if 512 - sequence < 0\n",
      "Cannot determine if 512 - sequence < 0\n",
      "Cannot determine if 512 - sequence < 0\n",
      "Cannot determine if 512 - sequence < 0\n",
      "Cannot determine if 512 - sequence < 0\n",
      "Cannot determine if 512 - sequence < 0\n",
      "Cannot determine if 512 - sequence < 0\n",
      "Cannot determine if 512 - sequence < 0\n",
      "Cannot determine if 512 - sequence < 0\n",
      "Cannot determine if 512 - sequence < 0\n",
      "Cannot determine if 512 - sequence < 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Unsupported operator SkipLayerNormalization. No schema registered for this operator.\n",
      "Warning: Unsupported operator BiasGelu. No schema registered for this operator.\n",
      "Warning: Unsupported operator SkipLayerNormalization. No schema registered for this operator.\n",
      "Warning: Unsupported operator SkipLayerNormalization. No schema registered for this operator.\n",
      "Warning: Unsupported operator BiasGelu. No schema registered for this operator.\n",
      "Warning: Unsupported operator SkipLayerNormalization. No schema registered for this operator.\n",
      "Warning: Unsupported operator SkipLayerNormalization. No schema registered for this operator.\n",
      "Warning: Unsupported operator BiasGelu. No schema registered for this operator.\n",
      "Warning: Unsupported operator SkipLayerNormalization. No schema registered for this operator.\n",
      "Warning: Unsupported operator SkipLayerNormalization. No schema registered for this operator.\n",
      "Warning: Unsupported operator BiasGelu. No schema registered for this operator.\n",
      "Warning: Unsupported operator SkipLayerNormalization. No schema registered for this operator.\n",
      "Warning: Unsupported operator SkipLayerNormalization. No schema registered for this operator.\n",
      "Warning: Unsupported operator BiasGelu. No schema registered for this operator.\n",
      "Warning: Unsupported operator SkipLayerNormalization. No schema registered for this operator.\n",
      "Warning: Unsupported operator SkipLayerNormalization. No schema registered for this operator.\n",
      "Warning: Unsupported operator BiasGelu. No schema registered for this operator.\n",
      "Warning: Unsupported operator SkipLayerNormalization. No schema registered for this operator.\n",
      "Warning: Unsupported operator SkipLayerNormalization. No schema registered for this operator.\n",
      "Warning: Unsupported operator BiasGelu. No schema registered for this operator.\n",
      "Warning: Unsupported operator SkipLayerNormalization. No schema registered for this operator.\n",
      "Warning: Unsupported operator SkipLayerNormalization. No schema registered for this operator.\n",
      "Warning: Unsupported operator BiasGelu. No schema registered for this operator.\n",
      "Warning: Unsupported operator SkipLayerNormalization. No schema registered for this operator.\n",
      "Warning: Unsupported operator SkipLayerNormalization. No schema registered for this operator.\n",
      "Warning: Unsupported operator BiasGelu. No schema registered for this operator.\n",
      "Warning: Unsupported operator SkipLayerNormalization. No schema registered for this operator.\n",
      "Warning: Unsupported operator SkipLayerNormalization. No schema registered for this operator.\n",
      "Warning: Unsupported operator BiasGelu. No schema registered for this operator.\n",
      "Warning: Unsupported operator SkipLayerNormalization. No schema registered for this operator.\n",
      "Warning: Unsupported operator SkipLayerNormalization. No schema registered for this operator.\n",
      "Warning: Unsupported operator BiasGelu. No schema registered for this operator.\n",
      "Warning: Unsupported operator SkipLayerNormalization. No schema registered for this operator.\n",
      "Warning: Unsupported operator SkipLayerNormalization. No schema registered for this operator.\n",
      "Warning: Unsupported operator BiasGelu. No schema registered for this operator.\n",
      "Warning: Unsupported operator SkipLayerNormalization. No schema registered for this operator.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignore MatMul due to non constant B: /[MatMul_59]\n",
      "Ignore MatMul due to non constant B: /[MatMul_123]\n",
      "Ignore MatMul due to non constant B: /[MatMul_188]\n",
      "Ignore MatMul due to non constant B: /[MatMul_112]\n",
      "Ignore MatMul due to non constant B: /[MatMul_137]\n",
      "Ignore MatMul due to non constant B: /[MatMul_93]\n",
      "Ignore MatMul due to non constant B: /[MatMul_236]\n",
      "Ignore MatMul due to non constant B: /[MatMul_248]\n",
      "Ignore MatMul due to non constant B: /[MatMul_265]\n",
      "Ignore MatMul due to non constant B: /[MatMul_275]\n",
      "Ignore MatMul due to non constant B: /[MatMul_292]\n",
      "Ignore MatMul due to non constant B: /[MatMul_356]\n",
      "Ignore MatMul due to non constant B: /[MatMul_421]\n",
      "Ignore MatMul due to non constant B: /[MatMul_345]\n",
      "Ignore MatMul due to non constant B: /[MatMul_370]\n",
      "Ignore MatMul due to non constant B: /[MatMul_326]\n",
      "Ignore MatMul due to non constant B: /[MatMul_469]\n",
      "Ignore MatMul due to non constant B: /[MatMul_481]\n",
      "Ignore MatMul due to non constant B: /[MatMul_498]\n",
      "Ignore MatMul due to non constant B: /[MatMul_508]\n",
      "Ignore MatMul due to non constant B: /[MatMul_525]\n",
      "Ignore MatMul due to non constant B: /[MatMul_589]\n",
      "Ignore MatMul due to non constant B: /[MatMul_654]\n",
      "Ignore MatMul due to non constant B: /[MatMul_578]\n",
      "Ignore MatMul due to non constant B: /[MatMul_603]\n",
      "Ignore MatMul due to non constant B: /[MatMul_559]\n",
      "Ignore MatMul due to non constant B: /[MatMul_702]\n",
      "Ignore MatMul due to non constant B: /[MatMul_714]\n",
      "Ignore MatMul due to non constant B: /[MatMul_731]\n",
      "Ignore MatMul due to non constant B: /[MatMul_741]\n",
      "Ignore MatMul due to non constant B: /[MatMul_758]\n",
      "Ignore MatMul due to non constant B: /[MatMul_822]\n",
      "Ignore MatMul due to non constant B: /[MatMul_887]\n",
      "Ignore MatMul due to non constant B: /[MatMul_811]\n",
      "Ignore MatMul due to non constant B: /[MatMul_836]\n",
      "Ignore MatMul due to non constant B: /[MatMul_792]\n",
      "Ignore MatMul due to non constant B: /[MatMul_935]\n",
      "Ignore MatMul due to non constant B: /[MatMul_947]\n",
      "Ignore MatMul due to non constant B: /[MatMul_964]\n",
      "Ignore MatMul due to non constant B: /[MatMul_974]\n",
      "Ignore MatMul due to non constant B: /[MatMul_991]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1055]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1120]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1044]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1069]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1025]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1168]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1180]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1197]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1207]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1224]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1288]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1353]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1277]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1302]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1258]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1401]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1413]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1430]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1440]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1457]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1521]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1586]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1510]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1535]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1491]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1634]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1646]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1663]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1673]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1690]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1754]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1819]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1743]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1768]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1724]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1867]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1879]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1896]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1906]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1923]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1987]\n",
      "Ignore MatMul due to non constant B: /[MatMul_2052]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1976]\n",
      "Ignore MatMul due to non constant B: /[MatMul_2001]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1957]\n",
      "Ignore MatMul due to non constant B: /[MatMul_2100]\n",
      "Ignore MatMul due to non constant B: /[MatMul_2112]\n",
      "Ignore MatMul due to non constant B: /[MatMul_2129]\n",
      "Ignore MatMul due to non constant B: /[MatMul_2139]\n",
      "Ignore MatMul due to non constant B: /[MatMul_2156]\n",
      "Ignore MatMul due to non constant B: /[MatMul_2220]\n",
      "Ignore MatMul due to non constant B: /[MatMul_2285]\n",
      "Ignore MatMul due to non constant B: /[MatMul_2209]\n",
      "Ignore MatMul due to non constant B: /[MatMul_2234]\n",
      "Ignore MatMul due to non constant B: /[MatMul_2190]\n",
      "Ignore MatMul due to non constant B: /[MatMul_2333]\n",
      "Ignore MatMul due to non constant B: /[MatMul_2345]\n",
      "Ignore MatMul due to non constant B: /[MatMul_2362]\n",
      "Ignore MatMul due to non constant B: /[MatMul_2372]\n",
      "Ignore MatMul due to non constant B: /[MatMul_2389]\n",
      "Ignore MatMul due to non constant B: /[MatMul_2453]\n",
      "Ignore MatMul due to non constant B: /[MatMul_2518]\n",
      "Ignore MatMul due to non constant B: /[MatMul_2442]\n",
      "Ignore MatMul due to non constant B: /[MatMul_2467]\n",
      "Ignore MatMul due to non constant B: /[MatMul_2423]\n",
      "Ignore MatMul due to non constant B: /[MatMul_2566]\n",
      "Ignore MatMul due to non constant B: /[MatMul_2578]\n",
      "Ignore MatMul due to non constant B: /[MatMul_2595]\n",
      "Ignore MatMul due to non constant B: /[MatMul_2605]\n",
      "Ignore MatMul due to non constant B: /[MatMul_2622]\n",
      "Ignore MatMul due to non constant B: /[MatMul_2686]\n",
      "Ignore MatMul due to non constant B: /[MatMul_2751]\n",
      "Ignore MatMul due to non constant B: /[MatMul_2675]\n",
      "Ignore MatMul due to non constant B: /[MatMul_2700]\n",
      "Ignore MatMul due to non constant B: /[MatMul_2656]\n",
      "Ignore MatMul due to non constant B: /[MatMul_2799]\n",
      "Ignore MatMul due to non constant B: /[MatMul_2811]\n",
      "Ignore MatMul due to non constant B: /[MatMul_2828]\n",
      "Ignore MatMul due to non constant B: /[MatMul_2838]\n",
      "Ignore MatMul due to non constant B: /[Gemm_2857_MatMul]\n",
      "Ignore MatMul due to non constant B: /[Gemm_2866_MatMul]\n"
     ]
    }
   ],
   "source": [
    "optimize_onnx(\n",
    "    onnx_path=\"baseline.onnx\",\n",
    "    onnx_optim_model_path=\"baseline-optimized.onnx\",\n",
    "    fp16=True,\n",
    "    use_cuda=True,\n",
    ")\n",
    "\n",
    "cpu_quantization(input_model_path=\"baseline-optimized.onnx\", output_model_path=\"baseline-quantized.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgument",
     "evalue": "[ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Invalid Feed Input Name:token_type_ids",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mInvalidArgument\u001B[0m                           Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_1609065/119157561.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcreate_model_for_provider\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"baseline-optimized.onnx\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mprovider_to_use\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"CUDAExecutionProvider\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 8\u001B[0;31m \u001B[0moutput\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrun\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minputs_onnx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/.local/share/virtualenvs/fast_transformer/lib/python3.9/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py\u001B[0m in \u001B[0;36mrun\u001B[0;34m(self, output_names, input_feed, run_options)\u001B[0m\n\u001B[1;32m    190\u001B[0m             \u001B[0moutput_names\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0moutput\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mname\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0moutput\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_outputs_meta\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    191\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 192\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_sess\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrun\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moutput_names\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput_feed\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrun_options\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    193\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mC\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mEPFail\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0merr\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    194\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_enable_fallback\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mInvalidArgument\u001B[0m: [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Invalid Feed Input Name:token_type_ids"
     ]
    }
   ],
   "source": [
    "labels = [item[\"label\"] for item in encoded_dataset[validation_key]]\n",
    "data = encoded_dataset[validation_key][0:batch_size]\n",
    "inputs_onnx: OD[str, np.ndarray] = convert_tensor(data=data, output=\"np\")\n",
    "for k, v in inputs_onnx.items():\n",
    "    inputs_onnx[k] = v.astype(np.int64)\n",
    "\n",
    "model = create_model_for_provider(path=\"baseline-optimized.onnx\", provider_to_use=\"CUDAExecutionProvider\")\n",
    "output = model.run(None, inputs_onnx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = encoded_dataset[\"train\"][0:batch_size]\n",
    "inputs_onnx: OD[str, np.ndarray] = convert_tensor(data=data, output=\"np\")\n",
    "for k, v in inputs_onnx.items():\n",
    "    inputs_onnx[k] = v.astype(np.int64)\n",
    "\n",
    "for provider, model_path, benchmark_name, warmup, nb_inference in [\n",
    "    (\"CUDAExecutionProvider\", \"baseline.onnx\", \"ONNX Runtime GPU (FP32)\", 10, 100),\n",
    "    (\"CUDAExecutionProvider\", \"baseline-optimized.onnx\", \"ONNX Runtime GPU (FP16)\", 10, 100),\n",
    "    (\"CPUExecutionProvider\", \"baseline.onnx\", \"ONNX Runtime CPU (FP32)\", 3, 10),\n",
    "    (\"CPUExecutionProvider\", \"baseline-optimized.onnx\", \"ONNX Runtime CPU (FP16)\", 3, 10),\n",
    "    (\"CPUExecutionProvider\", \"baseline-quantized.onnx\", \"ONNX Runtime CPU (INT-8)\", 3, 10),\n",
    "]:\n",
    "    model = create_model_for_provider(path=model_path, provider_to_use=provider)\n",
    "    for _ in range(warmup):\n",
    "        _ = model.run(None, inputs_onnx)\n",
    "    time_buffer = []\n",
    "    for _ in range(nb_inference):\n",
    "        with track_infer_time(time_buffer):\n",
    "            _ = model.run(None, inputs_onnx)\n",
    "    print_timings(name=benchmark_name, timings=time_buffer)\n",
    "    del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measure of the accuracy with ONNX Runtime engine and CUDA provider:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgument",
     "evalue": "[ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Invalid Feed Input Name:token_type_ids",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mInvalidArgument\u001B[0m                           Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_1609065/4016680404.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcreate_model_for_provider\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"baseline.onnx\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mprovider_to_use\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"CUDAExecutionProvider\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0minfer_ort\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mlambda\u001B[0m \u001B[0mtokens\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrun\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtokens\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0mmeasure_accuracy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minfer\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0minfer_ort\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mint64\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/tmp/ipykernel_1609065/3557841061.py\u001B[0m in \u001B[0;36mmeasure_accuracy\u001B[0;34m(infer, int64)\u001B[0m\n\u001B[1;32m     38\u001B[0m             \u001B[0;32mfor\u001B[0m \u001B[0mk\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mv\u001B[0m \u001B[0;32min\u001B[0m \u001B[0minputs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mitems\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     39\u001B[0m                 \u001B[0minputs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mk\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mv\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mint64\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 40\u001B[0;31m         \u001B[0moutput\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0minfer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     41\u001B[0m         \u001B[0moutput\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0margmax\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moutput\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mint\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtolist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     42\u001B[0m         \u001B[0moutputs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mextend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moutput\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_1609065/4016680404.py\u001B[0m in \u001B[0;36m<lambda>\u001B[0;34m(tokens)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcreate_model_for_provider\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"baseline.onnx\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mprovider_to_use\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"CUDAExecutionProvider\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0minfer_ort\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mlambda\u001B[0m \u001B[0mtokens\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrun\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtokens\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0mmeasure_accuracy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minfer\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0minfer_ort\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mint64\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/share/virtualenvs/fast_transformer/lib/python3.9/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py\u001B[0m in \u001B[0;36mrun\u001B[0;34m(self, output_names, input_feed, run_options)\u001B[0m\n\u001B[1;32m    190\u001B[0m             \u001B[0moutput_names\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0moutput\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mname\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0moutput\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_outputs_meta\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    191\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 192\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_sess\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrun\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moutput_names\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput_feed\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrun_options\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    193\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mC\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mEPFail\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0merr\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    194\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_enable_fallback\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mInvalidArgument\u001B[0m: [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Invalid Feed Input Name:token_type_ids"
     ]
    }
   ],
   "source": [
    "model = create_model_for_provider(path=\"baseline.onnx\", provider_to_use=\"CUDAExecutionProvider\")\n",
    "infer_ort = lambda tokens: model.run(None, tokens)\n",
    "measure_accuracy(infer=infer_ort, int64=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model_for_provider(path=\"baseline-optimized.onnx\", provider_to_use=\"CUDAExecutionProvider\")\n",
    "infer_ort = lambda tokens: model.run(None, tokens)\n",
    "measure_accuracy(infer=infer_ort, int64=True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "whPRbBNbIrIl",
    "n9qywopnIrJH",
    "7k8ge1L1IrJk"
   ],
   "name": "Copie de Text Classification on GLUE",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0022faf286b44e858e638ccd5ded38b0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "023900ca566446eab5905b25b16a3de7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "08286a6371584b4186014ecb5d5f164d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2d3a08166846438db79b0f89314fe76a",
      "placeholder": "​",
      "style": "IPY_MODEL_d1ecc3d380fc4758b03190b23686a2f1",
      "value": " 481/481 [00:00&lt;00:00, 10.9kB/s]"
     }
    },
    "092db03992f24951b494fbb81da5b9d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_994cf2338c7c4899952e25723445693c",
       "IPY_MODEL_6aa2f5d46f1f454198d8e69517549ff1",
       "IPY_MODEL_72b8f11065254e5ca488cd346b5add54"
      ],
      "layout": "IPY_MODEL_023900ca566446eab5905b25b16a3de7"
     }
    },
    "0dab554959dc44b3b313ee8ae91ca88d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e1f08cf954ae4aea818c90d893486c77",
      "placeholder": "​",
      "style": "IPY_MODEL_f01fdef82047471e8c1b780cae5379cc",
      "value": " 420M/420M [00:13&lt;00:00, 33.6MB/s]"
     }
    },
    "10678736bd534c63aebda414da01b4db": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "14648b8262944f5faac134a7c0184e47": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "154200a8bc0b44fe8d0419fd56c6539d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "15aae23369674f82888ed9fbd99739f2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "163146c2f23440bcbf782116a35b5684": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cf9597523c024514b9b3e66bc77e3fa8",
      "max": 440473133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cced5f1cccc2400a8fbfd7a6eaedc666",
      "value": 440473133
     }
    },
    "167874df55014291be95cd390b1e60d3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "17b83e0d0fb947d7bf20319ff930e8fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_854cfd13416543fba8221093b903658b",
      "placeholder": "​",
      "style": "IPY_MODEL_cbbb20b5d01a4450bfb8dfbf8048d64f",
      "value": "Downloading: 100%"
     }
    },
    "17bd5357081d41c6b0161d63bd00820a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "196ffc99ad5a40109d9b1cfe12032b62": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1bea379404df429b9852b62a938661ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a4c444f06c0847c09a44917084d3908d",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_300f01e3547648f3983a83d3d3118c54",
      "value": 1
     }
    },
    "1da1d80871f545bbb21bf5a84d2120a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8585eab4b3fe4992bd7e7c4596e2483b",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7ec6da801d0d45c4bb80eeab5518e124",
      "value": 570
     }
    },
    "21ef195fa88f49c4a2c057f8028177a2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "26bc2038bed74279813ab5af09a2724c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0022faf286b44e858e638ccd5ded38b0",
      "max": 456318,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7ff32d18c9f0473893a6a6b2941c54b0",
      "value": 456318
     }
    },
    "28b7346a9b8c4b198dd9dbea1be013b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2d3a08166846438db79b0f89314fe76a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2eac6b4817e14d7fae396e6458b940fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_927ad6ade85a402594074fa90ab558c2",
      "placeholder": "​",
      "style": "IPY_MODEL_cae29b9c6d45412fab70977fcd0f3234",
      "value": "Downloading: 100%"
     }
    },
    "300f01e3547648f3983a83d3d3118c54": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "30646fa2c0dc494e9dbcbd4dc598410e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "360d6eb0e41543dba6d457912e32a77d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "37cda4cae81a4d94aa831fb40b5c3b26": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_56fd7584b0844590936519ec3851922e",
      "placeholder": "​",
      "style": "IPY_MODEL_5b1ad9f5d02c4b298a02ce6041692057",
      "value": " 4/4 [00:00&lt;00:00,  5.97ba/s]"
     }
    },
    "3bfff454943b4b04a12ec29bbe28e0aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cedca6e55b84443e82f3d01471d61048",
       "IPY_MODEL_a7d355f456eb4d3995dd91c5917a72c1",
       "IPY_MODEL_b264b220d9c444bd9da46a7e6c8fd5ed"
      ],
      "layout": "IPY_MODEL_154200a8bc0b44fe8d0419fd56c6539d"
     }
    },
    "3e7fbd1c0e534cb8abca18d1edfc9277": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4320b12de9d14c459cc88319e2d7622a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4552ee8ca6bd4a0b956651cc23f4ff3c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4b13c3b3435f4689b29d48e0a35bebd6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4e91efae49b64f038fd3fbfcfd2be510": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4fae966b76844c869cdea1e53891e26f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "54c0ad5ab737433190c4a824be128a48": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "561b1ede331a40c1a2bff9422e8eea0e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "56fd7584b0844590936519ec3851922e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "59418bbeb20547e5b5e1a5728262c757": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5b1ad9f5d02c4b298a02ce6041692057": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5e2185bd6e4f4a10b89ac606868a43bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2eac6b4817e14d7fae396e6458b940fa",
       "IPY_MODEL_af16284f77594397a69ad0e322b5e736",
       "IPY_MODEL_a20579a9e7364fb485d79bdc4feb54dc"
      ],
      "layout": "IPY_MODEL_f44d2beebfe44186b0ac8016e89e4b49"
     }
    },
    "5f032f56105f463a8680aa2482d0b162": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "65017db07d7f4e798ede741cc92488f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_86cc326e574a4fada7224e6f0c209e9a",
       "IPY_MODEL_af5b646f89024c139c695a1f058fb772",
       "IPY_MODEL_37cda4cae81a4d94aa831fb40b5c3b26"
      ],
      "layout": "IPY_MODEL_6fa74604c68543a38392fa0e1587f707"
     }
    },
    "68c4c867096d41a78740fdee30edcadb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6aa2f5d46f1f454198d8e69517549ff1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7b483d17d1d14fdd922600f0c906fc2f",
      "max": 1355863,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4320b12de9d14c459cc88319e2d7622a",
      "value": 1355863
     }
    },
    "6d48e5ce9a854a3bb0506d774665f428": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fbdb7c7250d846b2880005a9012c484b",
      "placeholder": "​",
      "style": "IPY_MODEL_17bd5357081d41c6b0161d63bd00820a",
      "value": " 478M/478M [00:15&lt;00:00, 34.7MB/s]"
     }
    },
    "6e54ce781ca54ad283911fa4774e3361": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6e604307427a466cab51d50d363ee86d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6fa74604c68543a38392fa0e1587f707": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "728a9dcc79824e1eb2bfa49d915a8f08": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d314c0bb87e04893b96de0e18766d3ab",
      "placeholder": "​",
      "style": "IPY_MODEL_fa35b3acd9ce4cb098fcd69bb405db00",
      "value": "Downloading: 100%"
     }
    },
    "72b8f11065254e5ca488cd346b5add54": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_10678736bd534c63aebda414da01b4db",
      "placeholder": "​",
      "style": "IPY_MODEL_14648b8262944f5faac134a7c0184e47",
      "value": " 1.29M/1.29M [00:00&lt;00:00, 2.22MB/s]"
     }
    },
    "7701ec898fd443f1b35b187aea3651e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "78601982b0e04b80adaa502db2ef685a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d6426fea2eda41dd9a31cb3f35b0877e",
       "IPY_MODEL_163146c2f23440bcbf782116a35b5684",
       "IPY_MODEL_0dab554959dc44b3b313ee8ae91ca88d"
      ],
      "layout": "IPY_MODEL_167874df55014291be95cd390b1e60d3"
     }
    },
    "788badadfd834f61926a39a43ef1d517": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7a75099f99054645bf3fc1b778dac7e6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7b483d17d1d14fdd922600f0c906fc2f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7bb3b69a2f814e60b0cec253c759a16b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d731cfb34124448bbd8baab3d27b75db",
      "placeholder": "​",
      "style": "IPY_MODEL_cbb3e9bf5d07406d9768a98a6f0b5b64",
      "value": "100%"
     }
    },
    "7c875ecd9cb54405a6c45969bcb4b4c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7d520bdde27742abb42803843721d101": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7ec6da801d0d45c4bb80eeab5518e124": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7ff32d18c9f0473893a6a6b2941c54b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8399339998564d21ba5db6f0514c02c6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "854cfd13416543fba8221093b903658b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8585eab4b3fe4992bd7e7c4596e2483b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "86cc326e574a4fada7224e6f0c209e9a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_561b1ede331a40c1a2bff9422e8eea0e",
      "placeholder": "​",
      "style": "IPY_MODEL_28b7346a9b8c4b198dd9dbea1be013b6",
      "value": "100%"
     }
    },
    "87d85ac2d3104f68b99db880b1089638": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_728a9dcc79824e1eb2bfa49d915a8f08",
       "IPY_MODEL_c815bfd265f4480298c39c76b9eaf770",
       "IPY_MODEL_6d48e5ce9a854a3bb0506d774665f428"
      ],
      "layout": "IPY_MODEL_6e604307427a466cab51d50d363ee86d"
     }
    },
    "8a11c8fed672470b8335dc575a4a220e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_93dbcc6d23a743bab0da8af6ee5e2825",
      "max": 481,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f8a0053903c64e75ac25eab5b24d5871",
      "value": 481
     }
    },
    "8defdddee0e64a20b101e6c50bd7c60b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7bb3b69a2f814e60b0cec253c759a16b",
       "IPY_MODEL_d25cca081db3469b80163d6707f5a37d",
       "IPY_MODEL_f8abc3e44ae3428885aafbea2b37384c"
      ],
      "layout": "IPY_MODEL_f485d2b19ffa4585a1da20986f28af29"
     }
    },
    "927ad6ade85a402594074fa90ab558c2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "93dbcc6d23a743bab0da8af6ee5e2825": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "969b6fdac1d6418d89a683db1e6ec6b2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "990482eebca2424bb5ecbd114007e02c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "994cf2338c7c4899952e25723445693c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d9a0852554284d36b6b121f579b06b41",
      "placeholder": "​",
      "style": "IPY_MODEL_c7bd52ef524c4d279dfcaa3aebe4a2c5",
      "value": "Downloading: 100%"
     }
    },
    "99e94791043b4499b06601f7524f9b14": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d5c8ff9e3bd849059fa7b30eab5fc940",
      "placeholder": "​",
      "style": "IPY_MODEL_196ffc99ad5a40109d9b1cfe12032b62",
      "value": "Downloading: 100%"
     }
    },
    "9bc6e14b912249e3b7d02f31bcc74667": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_969b6fdac1d6418d89a683db1e6ec6b2",
      "placeholder": "​",
      "style": "IPY_MODEL_6e54ce781ca54ad283911fa4774e3361",
      "value": " 446k/446k [00:00&lt;00:00, 650kB/s]"
     }
    },
    "a02624219ee84f50b1a3032eaa030a39": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a0a2918e9772475cac51124b3b83fcaf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a20579a9e7364fb485d79bdc4feb54dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4b13c3b3435f4689b29d48e0a35bebd6",
      "placeholder": "​",
      "style": "IPY_MODEL_d5d015711ae04d2f801577fc50af6c15",
      "value": " 878k/878k [00:00&lt;00:00, 1.33MB/s]"
     }
    },
    "a3e2c73d393d4e58a371f3da3dd80e6d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a4c444f06c0847c09a44917084d3908d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a51b461c062f4636bfa4b48823d0709b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a61d366d91c34697a55f62b754e1f3a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a9b98fd93fcd4fc4a2b2aa88c82835d0",
      "placeholder": "​",
      "style": "IPY_MODEL_b8722dc10d4447fe9630cbf169260cc8",
      "value": "100%"
     }
    },
    "a7d355f456eb4d3995dd91c5917a72c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5f032f56105f463a8680aa2482d0b162",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a02624219ee84f50b1a3032eaa030a39",
      "value": 2
     }
    },
    "a9b98fd93fcd4fc4a2b2aa88c82835d0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ac14ba24dcf3404db9fd303dbb24d7a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_17b83e0d0fb947d7bf20319ff930e8fc",
       "IPY_MODEL_1da1d80871f545bbb21bf5a84d2120a0",
       "IPY_MODEL_c593f2e45e244637821cc5721788bf2c"
      ],
      "layout": "IPY_MODEL_4e91efae49b64f038fd3fbfcfd2be510"
     }
    },
    "aecf7f063234416abf3f24766481cb89": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "af16284f77594397a69ad0e322b5e736": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7a75099f99054645bf3fc1b778dac7e6",
      "max": 898823,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_30646fa2c0dc494e9dbcbd4dc598410e",
      "value": 898823
     }
    },
    "af5b646f89024c139c695a1f058fb772": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_21ef195fa88f49c4a2c057f8028177a2",
      "max": 4,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_aecf7f063234416abf3f24766481cb89",
      "value": 4
     }
    },
    "b264b220d9c444bd9da46a7e6c8fd5ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8399339998564d21ba5db6f0514c02c6",
      "placeholder": "​",
      "style": "IPY_MODEL_7701ec898fd443f1b35b187aea3651e9",
      "value": " 2/2 [00:00&lt;00:00,  6.46ba/s]"
     }
    },
    "b4d3f284fc4c4061b58d43a738f9bc78": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7d520bdde27742abb42803843721d101",
      "placeholder": "​",
      "style": "IPY_MODEL_68c4c867096d41a78740fdee30edcadb",
      "value": "Downloading: 100%"
     }
    },
    "b6be028de2ae4ff691538eedb33793af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b4d3f284fc4c4061b58d43a738f9bc78",
       "IPY_MODEL_8a11c8fed672470b8335dc575a4a220e",
       "IPY_MODEL_08286a6371584b4186014ecb5d5f164d"
      ],
      "layout": "IPY_MODEL_a3e2c73d393d4e58a371f3da3dd80e6d"
     }
    },
    "b8722dc10d4447fe9630cbf169260cc8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bbe3a471efb04ea8b5aabc4be819d585": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a61d366d91c34697a55f62b754e1f3a5",
       "IPY_MODEL_1bea379404df429b9852b62a938661ae",
       "IPY_MODEL_c801e1727de44b67aa7cb1c3d970e1fe"
      ],
      "layout": "IPY_MODEL_59418bbeb20547e5b5e1a5728262c757"
     }
    },
    "be4affe852b348de8fe1362582b08da9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_99e94791043b4499b06601f7524f9b14",
       "IPY_MODEL_26bc2038bed74279813ab5af09a2724c",
       "IPY_MODEL_9bc6e14b912249e3b7d02f31bcc74667"
      ],
      "layout": "IPY_MODEL_c6c100b71f26405fb960598feb5eee03"
     }
    },
    "c593f2e45e244637821cc5721788bf2c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c92a19dfa84142af91522bc22f21fca6",
      "placeholder": "​",
      "style": "IPY_MODEL_990482eebca2424bb5ecbd114007e02c",
      "value": " 570/570 [00:00&lt;00:00, 13.1kB/s]"
     }
    },
    "c6c100b71f26405fb960598feb5eee03": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c7bd52ef524c4d279dfcaa3aebe4a2c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c801e1727de44b67aa7cb1c3d970e1fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4552ee8ca6bd4a0b956651cc23f4ff3c",
      "placeholder": "​",
      "style": "IPY_MODEL_7c875ecd9cb54405a6c45969bcb4b4c6",
      "value": " 1/1 [00:00&lt;00:00,  7.22ba/s]"
     }
    },
    "c815bfd265f4480298c39c76b9eaf770": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_15aae23369674f82888ed9fbd99739f2",
      "max": 501200538,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3e7fbd1c0e534cb8abca18d1edfc9277",
      "value": 501200538
     }
    },
    "c92a19dfa84142af91522bc22f21fca6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cae29b9c6d45412fab70977fcd0f3234": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cbb3e9bf5d07406d9768a98a6f0b5b64": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cbbb20b5d01a4450bfb8dfbf8048d64f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cced5f1cccc2400a8fbfd7a6eaedc666": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cedca6e55b84443e82f3d01471d61048": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a0a2918e9772475cac51124b3b83fcaf",
      "placeholder": "​",
      "style": "IPY_MODEL_4fae966b76844c869cdea1e53891e26f",
      "value": "100%"
     }
    },
    "cf9597523c024514b9b3e66bc77e3fa8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d1ecc3d380fc4758b03190b23686a2f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d25cca081db3469b80163d6707f5a37d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_360d6eb0e41543dba6d457912e32a77d",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_788badadfd834f61926a39a43ef1d517",
      "value": 3
     }
    },
    "d314c0bb87e04893b96de0e18766d3ab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d5c8ff9e3bd849059fa7b30eab5fc940": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d5d015711ae04d2f801577fc50af6c15": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d6426fea2eda41dd9a31cb3f35b0877e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a51b461c062f4636bfa4b48823d0709b",
      "placeholder": "​",
      "style": "IPY_MODEL_f651eecbb6d44c24820cf6fe5ab92e7b",
      "value": "Downloading: 100%"
     }
    },
    "d731cfb34124448bbd8baab3d27b75db": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d9a0852554284d36b6b121f579b06b41": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e1f08cf954ae4aea818c90d893486c77": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f01fdef82047471e8c1b780cae5379cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f237ed04039945e9aa224d1b9d04e1b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f44d2beebfe44186b0ac8016e89e4b49": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f485d2b19ffa4585a1da20986f28af29": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f651eecbb6d44c24820cf6fe5ab92e7b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f8a0053903c64e75ac25eab5b24d5871": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f8abc3e44ae3428885aafbea2b37384c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_54c0ad5ab737433190c4a824be128a48",
      "placeholder": "​",
      "style": "IPY_MODEL_f237ed04039945e9aa224d1b9d04e1b5",
      "value": " 3/3 [00:00&lt;00:00, 52.79it/s]"
     }
    },
    "fa35b3acd9ce4cb098fcd69bb405db00": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fbdb7c7250d846b2880005a9012c484b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}