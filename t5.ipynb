{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T10:27:34.438413Z",
     "iopub.status.busy": "2022-05-05T10:27:34.438012Z",
     "iopub.status.idle": "2022-05-05T10:27:35.004781Z",
     "shell.execute_reply": "2022-05-05T10:27:35.004285Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu May  5 12:27:34 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 510.60.02    Driver Version: 510.60.02    CUDA Version: 11.6     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:03:00.0  On |                  N/A |\r\n",
      "| 46%   49C    P8    42W / 350W |    308MiB / 24576MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A      1677      G   /usr/lib/xorg/Xorg                186MiB |\r\n",
      "|    0   N/A  N/A      4718      G   ...ome-remote-desktop-daemon        4MiB |\r\n",
      "|    0   N/A  N/A      7285      G   /usr/bin/gnome-shell               39MiB |\r\n",
      "|    0   N/A  N/A      8831      G   ...on/Bin/AgentConnectix.bin        4MiB |\r\n",
      "|    0   N/A  N/A    699207      G   ...veSuggestionsOnlyOnDemand       41MiB |\r\n",
      "|    0   N/A  N/A   1263001      G   ...113052261268123669,131072       28MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T10:27:35.007888Z",
     "iopub.status.busy": "2022-05-05T10:27:35.007694Z",
     "iopub.status.idle": "2022-05-05T10:27:36.800272Z",
     "shell.execute_reply": "2022-05-05T10:27:36.799481Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "from typing import Callable, Dict, Optional\n",
    "import matplotlib.pylab as plt\n",
    "from onnxruntime import IOBinding\n",
    "import numpy as np\n",
    "import onnx\n",
    "import torch\n",
    "from onnx import GraphProto, ModelProto, helper\n",
    "from torch.nn import Linear\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, PretrainedConfig, T5ForConditionalGeneration, TensorType\n",
    "from transformers.generation_utils import GenerationMixin\n",
    "from transformers.modeling_outputs import BaseModelOutputWithPastAndCrossAttentions, Seq2SeqLMOutput\n",
    "from transformers.models.t5.modeling_t5 import T5Stack\n",
    "\n",
    "from transformer_deploy.backends.ort_utils import create_model_for_provider, inference_onnx_binding\n",
    "from transformer_deploy.backends.pytorch_utils import convert_to_onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Loading Hugging Face model / tokenizer\n",
    "\n",
    "We use a specific branch of OnnxRuntime with a better management of if/else/then ONNX node:\n",
    "\n",
    "```shell\n",
    "git clone --recursive https://github.com/Microsoft/onnxruntime\n",
    "cd onnxruntime\n",
    "git fetch origin hari/location_plan_implicit_inputs\n",
    "git checkout -b hari/location_plan_implicit_inputs FETCH_HEAD\n",
    "CUDACXX=/usr/local/cuda-11.4/bin/nvcc ./build.sh \\\n",
    "    --config Release \\\n",
    "    --build_wheel \\\n",
    "    --parallel \\\n",
    "    --use_cuda \\\n",
    "    --cuda_home /usr/local/cuda-11.4 \\\n",
    "    --cudnn_home /usr/lib/x86_\n",
    "    -linux-gnu/ \\\n",
    "    --skip_test\n",
    "```\n",
    "\n",
    "> to clear previous compilation, delete content of `./build` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T10:27:36.804760Z",
     "iopub.status.busy": "2022-05-05T10:27:36.804251Z",
     "iopub.status.idle": "2022-05-05T10:27:48.522070Z",
     "shell.execute_reply": "2022-05-05T10:27:48.521553Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"t5-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "input_ids: torch.Tensor = tokenizer(\"Studies show that\", return_tensors=TensorType.PYTORCH).input_ids\n",
    "input_ids = input_ids.to(\"cuda\")\n",
    "model: T5ForConditionalGeneration = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "model = model.eval()\n",
    "model = model.to(\"cuda\")\n",
    "model.config.use_cache = True\n",
    "out_enc: BaseModelOutputWithPastAndCrossAttentions = model.encoder(input_ids=input_ids)\n",
    "out_full: Seq2SeqLMOutput = model(input_ids=input_ids, decoder_input_ids=input_ids)\n",
    "num_layers = model.config.num_layers\n",
    "\n",
    "\n",
    "def are_equal(a: torch.Tensor, b: torch.Tensor, atol: float = 2e-1) -> None:\n",
    "    assert np.allclose(a=a.detach().cpu().numpy(), b=b.detach().cpu().numpy(), atol=atol), f\"{a}\\n\\nVS\\n\\n{b}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Export to ONNX\n",
    "\n",
    "## Export encoder part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T10:27:48.526348Z",
     "iopub.status.busy": "2022-05-05T10:27:48.526123Z",
     "iopub.status.idle": "2022-05-05T10:27:54.744704Z",
     "shell.execute_reply": "2022-05-05T10:27:54.744172Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = model.to(\"cuda\")\n",
    "\n",
    "convert_to_onnx(\n",
    "    model_pytorch=model.encoder,\n",
    "    output_path=\"test-enc.onnx\",\n",
    "    inputs_pytorch={\"input_ids\": input_ids},\n",
    "    var_output_seq=True,\n",
    "    quantization=False,\n",
    ")\n",
    "\n",
    "enc_onnx = create_model_for_provider(\"test-enc.onnx\", \"CUDAExecutionProvider\")\n",
    "enc_onnx_out = inference_onnx_binding(\n",
    "    model_onnx=enc_onnx,\n",
    "    inputs={\"input_ids\": input_ids},\n",
    "    device=input_ids.device.type,\n",
    ")[\"output\"]\n",
    "\n",
    "are_equal(a=enc_onnx_out, b=out_enc.last_hidden_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Export decoder\n",
    "\n",
    "### Wrapper to include some post processing on the decoder output\n",
    "\n",
    "The post processing is mainly a projection of the decoder output on a matrix with one of its dimension equal to model vocabulary size, so we have scores for each possible token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T10:27:54.748230Z",
     "iopub.status.busy": "2022-05-05T10:27:54.747848Z",
     "iopub.status.idle": "2022-05-05T10:27:54.778206Z",
     "shell.execute_reply": "2022-05-05T10:27:54.777669Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "\n",
    "class ExportT5(torch.nn.Module):\n",
    "    def __init__(self, decoder: T5Stack, lm_head: Linear):\n",
    "        super(ExportT5, self).__init__()\n",
    "        self.decoder = decoder\n",
    "        self.lm_head = lm_head\n",
    "\n",
    "    def forward(self, input_ids: torch.Tensor, encoder_hidden_states: torch.Tensor, past_key_values: Tuple = None):\n",
    "        out_dec = self.decoder.forward(\n",
    "            input_ids=input_ids, encoder_hidden_states=encoder_hidden_states, past_key_values=past_key_values\n",
    "        )\n",
    "        # Rescale output before projecting on vocab\n",
    "        out_dec[\"last_hidden_state\"] = out_dec[\"last_hidden_state\"] * (model.model_dim**-0.5)\n",
    "        out_dec[\"last_hidden_state\"] = self.lm_head(out_dec[\"last_hidden_state\"])\n",
    "        return out_dec\n",
    "\n",
    "\n",
    "model.cuda()\n",
    "model_decoder = ExportT5(decoder=model.decoder, lm_head=model.lm_head).eval()\n",
    "out_model_export: torch.Tensor = model_decoder(input_ids=input_ids, encoder_hidden_states=out_enc.last_hidden_state)\n",
    "\n",
    "are_equal(a=out_model_export[\"last_hidden_state\"], b=out_full.logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Export decoder part to ONNX\n",
    "\n",
    "Export 2 versions of the decoder, one without cache support and one with it.\n",
    "Both models share most of their weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T10:27:54.781330Z",
     "iopub.status.busy": "2022-05-05T10:27:54.780978Z",
     "iopub.status.idle": "2022-05-05T10:28:18.495033Z",
     "shell.execute_reply": "2022-05-05T10:28:18.494501Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/geantvert/.local/share/virtualenvs/fast_transformer/lib/python3.9/site-packages/transformers/modeling_utils.py:529: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if causal_mask.shape[1] < attention_mask.shape[1]:\n",
      "In-place op on output of tensor.shape. See https://pytorch.org/docs/master/onnx.html#avoid-inplace-operations-when-using-tensor-shape-in-tracing-mode\n",
      "In-place op on output of tensor.shape. See https://pytorch.org/docs/master/onnx.html#avoid-inplace-operations-when-using-tensor-shape-in-tracing-mode\n"
     ]
    }
   ],
   "source": [
    "model_decoder.cuda()\n",
    "# decoder output one step before\n",
    "out_dec_pytorch = model_decoder(input_ids=input_ids[:, :-1], encoder_hidden_states=out_enc.last_hidden_state)\n",
    "\n",
    "model_inputs = {\n",
    "    \"input_ids\": input_ids[:, -1:].type(torch.int32),\n",
    "    \"encoder_hidden_states\": out_enc.last_hidden_state,\n",
    "    \"past_key_values\": out_dec_pytorch.past_key_values,\n",
    "}\n",
    "\n",
    "# TODO replace hard coded axis names by generated one when generation works as expected\n",
    "input_names = [\"input_ids\", \"encoder_hidden_states\"]\n",
    "\n",
    "for i in range(num_layers):\n",
    "    input_names.append(f\"past_key_values.{i}.decoder.key\")\n",
    "    input_names.append(f\"past_key_values.{i}.decoder.value\")\n",
    "    input_names.append(f\"past_key_values.{i}.encoder.key\")\n",
    "    input_names.append(f\"past_key_values.{i}.encoder.value\")\n",
    "\n",
    "output_names = [\"logits\"]\n",
    "\n",
    "for i in range(num_layers):\n",
    "    output_names.append(f\"present.{i}.decoder.key\")\n",
    "    output_names.append(f\"present.{i}.decoder.value\")\n",
    "    output_names.append(f\"present.{i}.encoder.key\")\n",
    "    output_names.append(f\"present.{i}.encoder.value\")\n",
    "\n",
    "dynamic_axis = {\n",
    "    \"input_ids\": {0: \"batch\", 1: \"encoder_sequence\"},\n",
    "    \"encoder_hidden_states\": {0: \"batch\", 1: \"encoder_sequence\"},\n",
    "    \"logits\": {0: \"batch\", 1: \"decoder_sequence\"},\n",
    "}\n",
    "\n",
    "\n",
    "for i in range(num_layers):\n",
    "    dynamic_axis[f\"past_key_values.{i}.decoder.key\"] = {0: \"batch\", 2: \"past_decoder_sequence\"}\n",
    "    dynamic_axis[f\"past_key_values.{i}.decoder.value\"] = {0: \"batch\", 2: \"past_decoder_sequence\"}\n",
    "    dynamic_axis[f\"past_key_values.{i}.encoder.key\"] = {0: \"batch\", 2: \"past_encoder_sequence\"}\n",
    "    dynamic_axis[f\"past_key_values.{i}.encoder.value\"] = {0: \"batch\", 2: \"past_encoder_sequence\"}\n",
    "\n",
    "    dynamic_axis[f\"present.{i}.decoder.key\"] = {0: \"batch\", 2: \"past_decoder_sequence + sequence\"}\n",
    "    dynamic_axis[f\"present.{i}.decoder.value\"] = {0: \"batch\", 2: \"past_decoder_sequence + sequence\"}\n",
    "    dynamic_axis[f\"present.{i}.encoder.key\"] = {0: \"batch\", 2: \"past_encoder_sequence\"}\n",
    "    dynamic_axis[f\"present.{i}.encoder.value\"] = {0: \"batch\", 2: \"past_encoder_sequence\"}\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.config.return_dict = True\n",
    "    model.eval()\n",
    "\n",
    "    # export can works with named args but the dict containing named args as to be last element of the args tuple\n",
    "    torch.onnx.export(\n",
    "        model_decoder,\n",
    "        (model_inputs,),\n",
    "        f=\"test-dec-cache.onnx\",\n",
    "        input_names=input_names,\n",
    "        output_names=output_names,\n",
    "        dynamic_axes=dynamic_axis,\n",
    "        do_constant_folding=True,\n",
    "        opset_version=13,\n",
    "    )\n",
    "\n",
    "model_inputs_no_cache = {\n",
    "    \"input_ids\": input_ids.type(dtype=torch.int32),\n",
    "    \"encoder_hidden_states\": out_enc.last_hidden_state,\n",
    "}\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.config.return_dict = True\n",
    "    model.eval()\n",
    "\n",
    "    # export can works with named args but the dict containing named args as to be last element of the args tuple\n",
    "    torch.onnx.export(\n",
    "        model_decoder,\n",
    "        (model_inputs_no_cache,),\n",
    "        f=\"test-dec-no-cache.onnx\",\n",
    "        input_names=list(model_inputs_no_cache.keys()),\n",
    "        output_names=output_names,\n",
    "        dynamic_axes={k: v for k, v in dynamic_axis.items() if \"past_key_values\" not in k},\n",
    "        do_constant_folding=True,\n",
    "        opset_version=13,\n",
    "    )\n",
    "_ = model_decoder.cpu()  # free cuda memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Conversion to FP16\n",
    "\n",
    "The only truly random input is `input ids` (aka token ids).\n",
    "The range of realistic values of `input ids` is known: each dimension can only be a positive integer lower than the vocabulary size.\n",
    "For other inputs of the model (ouput of encoder, past states), it's a bit more complicated.\n",
    "In theory it can be any value in the FP32 range, but because of how models are initialized and trained, most of them are close to 0.\n",
    "To avoid too  much guessing, we have decided to just take the output of the real model being fed random `input ids`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T10:28:18.499475Z",
     "iopub.status.busy": "2022-05-05T10:28:18.499121Z",
     "iopub.status.idle": "2022-05-05T10:31:34.545742Z",
     "shell.execute_reply": "2022-05-05T10:31:34.545072Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from transformer_deploy.backends.ort_utils import get_keep_fp32_nodes\n",
    "from transformer_deploy.backends.ort_utils import convert_fp16\n",
    "\n",
    "\n",
    "def get_random_input_no_cache() -> Dict[str, torch.Tensor]:\n",
    "    batch = 2\n",
    "    seq_len = 512\n",
    "    random_input_ids = torch.randint(\n",
    "        low=2, high=tokenizer.vocab_size, size=(batch, seq_len), dtype=torch.int32, device=\"cuda\"\n",
    "    )\n",
    "    inputs = {\"input_ids\": random_input_ids}\n",
    "    encoder_hidden_states = inference_onnx_binding(\n",
    "        model_onnx=enc_onnx,\n",
    "        inputs=inputs,\n",
    "        device=\"cuda\",\n",
    "        clone_tensor=False,\n",
    "    )[\"output\"]\n",
    "    inputs[\"encoder_hidden_states\"] = encoder_hidden_states\n",
    "    return inputs\n",
    "\n",
    "\n",
    "keep_fp32_no_cache = get_keep_fp32_nodes(\n",
    "    onnx_model_path=\"test-dec-no-cache.onnx\", get_input=get_random_input_no_cache, nb_try=1000\n",
    ")\n",
    "\n",
    "onnx_model_no_cache_fp16 = onnx.load(\"test-dec-no-cache.onnx\")\n",
    "onnx_model_no_cache_fp16 = convert_fp16(onnx_model=onnx_model_no_cache_fp16, nodes_to_exclude=keep_fp32_no_cache)\n",
    "onnx.save(onnx_model_no_cache_fp16, \"test-dec-no-cache-fp16.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T10:31:34.551129Z",
     "iopub.status.busy": "2022-05-05T10:31:34.550747Z",
     "iopub.status.idle": "2022-05-05T10:35:11.336731Z",
     "shell.execute_reply": "2022-05-05T10:35:11.335642Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dec_no_cache_ort_model = create_model_for_provider(\"test-dec-no-cache.onnx\", \"CUDAExecutionProvider\")\n",
    "\n",
    "# thread sur FP16 marche pas\n",
    "# https://github.com/microsoft/onnxruntime/issues/11119=\n",
    "# use info from tokenizer size and max shape provided through the command line\n",
    "def get_random_input_cache() -> Dict[str, torch.Tensor]:\n",
    "    inputs = get_random_input_no_cache()\n",
    "    dec_past_states = inference_onnx_binding(\n",
    "        model_onnx=dec_no_cache_ort_model,\n",
    "        inputs=inputs,\n",
    "        device=\"cuda\",\n",
    "        clone_tensor=False,\n",
    "    )\n",
    "    for k, v in dec_past_states.items():\n",
    "        if k == \"logits\":\n",
    "            continue\n",
    "        new_k = k.replace(\"present\", \"past_key_values\")\n",
    "        inputs[new_k] = v\n",
    "    batch, _ = inputs[\"input_ids\"].shape\n",
    "    complement = torch.randint(low=0, high=tokenizer.vocab_size, size=(batch, 1), dtype=torch.int32, device=\"cuda\")\n",
    "    inputs[\"input_ids\"] = torch.concat(tensors=[inputs[\"input_ids\"], complement], dim=1)\n",
    "    return inputs\n",
    "\n",
    "\n",
    "keep_fp32_cache = get_keep_fp32_nodes(\n",
    "    onnx_model_path=\"test-dec-cache.onnx\", get_input=get_random_input_cache, nb_try=1000\n",
    ")\n",
    "\n",
    "onnx_model_cache_fp16 = onnx.load(\"test-dec-cache.onnx\")\n",
    "onnx_model_cache_fp16 = convert_fp16(onnx_model=onnx_model_cache_fp16, nodes_to_exclude=keep_fp32_cache)\n",
    "onnx.save(onnx_model_cache_fp16, \"test-dec-cache-fp16.onnx\")\n",
    "del dec_no_cache_ort_model  # free cuda memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Merge ONNX computation graph to deduplicate weights\n",
    "\n",
    "TODO remove unecessary initializer to avoid warning messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T10:35:11.342398Z",
     "iopub.status.busy": "2022-05-05T10:35:11.342084Z",
     "iopub.status.idle": "2022-05-05T10:35:19.301911Z",
     "shell.execute_reply": "2022-05-05T10:35:19.300757Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: cache_node_onnx::Slice_2276 - size: 0.01\n",
      "name: cache_node_onnx::Slice_2277 - size: 0.01\n",
      "name: cache_node_onnx::Slice_2287 - size: 0.01\n",
      "name: cache_node_onnx::Slice_2288 - size: 0.01\n"
     ]
    }
   ],
   "source": [
    "prefix = \"cache_node_\"\n",
    "mapping_initializer_cache_to_no_cache = dict()\n",
    "to_add = list()\n",
    "for node_cache in onnx_model_cache_fp16.graph.initializer:\n",
    "    found = False\n",
    "    for node_no_cache in onnx_model_no_cache_fp16.graph.initializer:\n",
    "        if node_cache.raw_data == node_no_cache.raw_data:\n",
    "            found = True\n",
    "            mapping_initializer_cache_to_no_cache[node_cache.name] = node_no_cache.name\n",
    "            break\n",
    "    if not found:\n",
    "        node_cache.name = prefix + node_cache.name\n",
    "        to_add.append(node_cache)\n",
    "        mapping_initializer_cache_to_no_cache[node_cache.name] = node_cache.name\n",
    "        print(f\"name: {node_cache.name} - size: {len(node_cache.raw_data)/1024:.2f}\")\n",
    "\n",
    "onnx_model_no_cache_fp16.graph.initializer.extend(to_add)\n",
    "# I/O model names should not be prefixed\n",
    "model_io_names = [n.name for n in list(onnx_model_cache_fp16.graph.input) + list(onnx_model_cache_fp16.graph.output)]\n",
    "\n",
    "for node in onnx_model_cache_fp16.graph.node:\n",
    "    for index, input_name in enumerate(node.input):\n",
    "        if input_name in model_io_names:\n",
    "            continue\n",
    "        node.input[index] = mapping_initializer_cache_to_no_cache.get(input_name, prefix + input_name)\n",
    "    for index, output_name in enumerate(node.output):\n",
    "        if output_name in model_io_names:\n",
    "            continue\n",
    "        node.output[index] = prefix + output_name\n",
    "    node.name = prefix + node.name\n",
    "model_io_names = [n.name for n in list(onnx_model_cache_fp16.graph.input) + list(onnx_model_cache_fp16.graph.output)]\n",
    "\n",
    "prefix = \"init_\"\n",
    "cache = dict()\n",
    "for node in onnx_model_no_cache_fp16.graph.initializer:\n",
    "    if node.name in model_io_names:\n",
    "        new_name = prefix + node.name\n",
    "        cache[node.name] = new_name\n",
    "        node.name = new_name\n",
    "\n",
    "for node in onnx_model_no_cache_fp16.graph.node:\n",
    "    for input_index, n in enumerate(node.input):\n",
    "        node.input[input_index] = cache.get(n, n)\n",
    "\n",
    "# mandatory for subgraph in if/else node\n",
    "assert len(onnx_model_cache_fp16.graph.output) == len(onnx_model_no_cache_fp16.graph.output)\n",
    "\n",
    "graph_cache: onnx.GraphProto = onnx.helper.make_graph(\n",
    "    nodes=list(onnx_model_cache_fp16.graph.node),\n",
    "    name=\"graph-cache\",\n",
    "    inputs=[],\n",
    "    outputs=list(onnx_model_cache_fp16.graph.output),\n",
    "    initializer=[],\n",
    ")\n",
    "\n",
    "graph_no_cache: onnx.GraphProto = onnx.helper.make_graph(\n",
    "    nodes=list(onnx_model_no_cache_fp16.graph.node),\n",
    "    name=\"graph-no-cache\",\n",
    "    inputs=[],\n",
    "    outputs=list(onnx_model_no_cache_fp16.graph.output),\n",
    "    initializer=[],\n",
    ")\n",
    "\n",
    "enable_cache_input = onnx.helper.make_tensor_value_info(name=\"enable_cache\", elem_type=onnx.TensorProto.BOOL, shape=[1])\n",
    "\n",
    "if_node = onnx.helper.make_node(\n",
    "    op_type=\"If\",\n",
    "    inputs=[\"enable_cache\"],\n",
    "    outputs=[o.name for o in list(onnx_model_no_cache_fp16.graph.output)],\n",
    "    then_branch=graph_cache,\n",
    "    else_branch=graph_no_cache,\n",
    ")\n",
    "\n",
    "if_graph_def: GraphProto = helper.make_graph(\n",
    "    nodes=[if_node],\n",
    "    name=\"if-model\",\n",
    "    inputs=list(onnx_model_cache_fp16.graph.input) + [enable_cache_input],\n",
    "    outputs=list(onnx_model_no_cache_fp16.graph.output),\n",
    "    initializer=list(onnx_model_no_cache_fp16.graph.initializer),\n",
    ")\n",
    "\n",
    "\n",
    "model_def: ModelProto = helper.make_model(\n",
    "    if_graph_def, producer_name=\"onnx-example\", opset_imports=[helper.make_opsetid(onnx.defs.ONNX_DOMAIN, 13)]\n",
    ")\n",
    "onnx.save(model_def, \"test-dec-if.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "When a name appears in both the initializer list and the graph input list, a runtime MAY allow a caller to specify a value for this (input) name overriding the value specified in the initializer and a runtime MAY allow users to omit specifying a value for this (input) name, choosing the value specified in the initializer. Names of constants that are not meant to be overridden by the caller should appear only in the initializer list and not in the graph input list. In models with IR version >= 4, in nested subgraphs used as attribute values, users MUST NOT use the same name as both a subgraph initializer and subgraph input unless the corresponding op's specification explicitly allows it. In models with IR version <= 3, users MAY use the same name as both a subgraph initializer and subgraph input, but this is restricted to support constants via initializers that are not intended to correspond to any actual inputs passed from the node into the subgraph. In particular, the control-flow operator semantics determines the set of inputs supplied to the execution of the subgraph, and these input names MUST NOT appear as subgraph initializers. Subgraph initializer names must appear in the graph input list after the actual inputs. This allows the actual inputs and formal inputs to be matched positionally.\n",
    "https://github.com/onnx/onnx/blob/ee4888c24510787bb8c61ebcba43ef252744e648/docs/IR.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Check ONNX decoder output\n",
    "\n",
    "Compare ONNX output with and without cache, plus compare with Pytorch output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T10:35:19.306176Z",
     "iopub.status.busy": "2022-05-05T10:35:19.305882Z",
     "iopub.status.idle": "2022-05-05T10:35:20.780358Z",
     "shell.execute_reply": "2022-05-05T10:35:20.779016Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-05 11:35:20.128309369 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Div_803'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.128328267 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Div_954'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.128332213 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Div_702'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.128335633 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Div_1709'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.128338993 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Div_652'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.128344573 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Div_2212'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.128349846 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Div_1004'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.128353678 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Div_1457'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.128360636 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Div_2061'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.128364330 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Div_870'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.128368153 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Div_1323'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.128372468 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Div_853'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.128376150 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Div_1155'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.128381210 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Div_1625'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.128384818 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Div_1910'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.128388609 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Div_568'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.128391931 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Div_320'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.128397131 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Div_2229'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.128400671 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Div_1407'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.128407202 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Div_1021'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.128414042 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Div_1105'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.128418429 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Div_1172'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.128422157 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Div_719'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.128426513 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Div_1306'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.128431903 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Div_1558'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.128435543 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Div_1608'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.128439691 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Div_551'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.128444361 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Div_1256'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.128447631 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Div_1776'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.128451010 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Div_1860'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.128454490 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Div_467'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.128457788 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Div_1474'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.128461157 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Div_1927'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.128465618 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Div_2011'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.128469923 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Div_2078'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.128473330 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Div_1759'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.128477153 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Div_2162'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.128813364 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Div_2485'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.128819030 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Div_2386'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.128825270 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Div_1563'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.128828871 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Div_1037'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.128833284 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Div_856'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.128836680 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Div_839'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.128839906 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Div_757'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.128843379 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Div_675'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.128846823 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Div_658'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.128850764 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Div_576'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.128854352 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Div_2123'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.128858474 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Div_494'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.128861930 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Div_1218'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.128865226 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Div_938'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.128869501 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Div_252'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.128876037 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Div_1020'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.128879406 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Div_1761'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.128883614 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Div_477'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.128887244 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Div_376'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.128891455 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Div_1925'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.128895127 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Div_2468'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.128899650 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Div_1119'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.128904463 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Div_1744'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.128907857 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Div_2304'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.128913744 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Div_1201'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.128917071 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Div_1580'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.128922576 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Div_1382'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.128925825 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Div_1399'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.128929233 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Div_2024'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.128933190 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Div_1481'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.128936844 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Div_1300'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.128942235 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Div_1662'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.128945850 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Div_2106'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.128950761 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Div_1843'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.128954655 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Div_1942'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.128958147 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Div_2205'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.128962776 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Div_2287'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187352642 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Pow_2223'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187364632 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Pow_2206'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187368577 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Div_409'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187371765 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing "
     ]
    }
   ],
   "source": [
    "model = model.cuda()\n",
    "model_decoder = model_decoder.cuda()\n",
    "input_ids = input_ids.cuda()\n",
    "model = model.eval()\n",
    "model_decoder = model_decoder.eval()\n",
    "enc_onnx = create_model_for_provider(\"test-enc.onnx\", \"CUDAExecutionProvider\")\n",
    "enc_onnx_binding: IOBinding = enc_onnx.io_binding()\n",
    "dec_onnx = create_model_for_provider(model_def.SerializeToString(), \"CUDAExecutionProvider\")\n",
    "dec_onnx_binding: IOBinding = dec_onnx.io_binding()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Benchmark new model on real scenario\n",
    "\n",
    "TODO: print graph of cache / no cache latency for each seq len + show how to justify what we measure\n",
    "TODO: convert the model to FP16 + add some explanation regarding aggressive conversion https://pytorch.org/docs/stable/amp.html?utm_source=pocket_mylist\n",
    "TODO: add experiment with TensorRT in mixed precision\n",
    "TODO: try https://github.com/microsoft/onnxruntime/pull/11320 + https://github.com/microsoft/onnxruntime/pull/8702 + https://github.com/microsoft/onnxruntime/issues/11254"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T10:35:20.784906Z",
     "iopub.status.busy": "2022-05-05T10:35:20.784560Z",
     "iopub.status.idle": "2022-05-05T10:35:20.827464Z",
     "shell.execute_reply": "2022-05-05T10:35:20.826999Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "initializer 'cache_node_onnx::Pow_948'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187375310 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Add_1857'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187380298 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Add_2209'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187383946 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Pow_1451'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187387639 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Add_1924'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187390793 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Pow_562'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187394191 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Pow_1619'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187398469 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Add_2226'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187401919 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Pow_797'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187405037 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Pow_545'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187408972 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Add_2008'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187412163 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Pow_461'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187415537 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Pow_847'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187419747 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Pow_646'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187423112 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Unsqueeze_252'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187426983 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Mul_411'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187430123 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Pow_1250'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187433912 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Pow_1015'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187437803 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Add_1622'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187440858 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Pow_864'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187444630 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Pow_713'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187449609 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Pow_696'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187453406 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Pow_998'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187457333 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Pow_1770'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187460498 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Pow_314'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187464981 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Add_1320'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187468644 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Unsqueeze_254'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187471954 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Pow_2156'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187476150 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Pow_1552'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187480285 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Pow_1300'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187484306 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::ConstantOfShape_266'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187487572 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Pow_1166'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187491967 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Pow_2005'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187495210 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Pow_1854'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187498483 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Pow_1317'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187501967 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Pow_1401'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187505080 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Pow_1099'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187508122 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Add_1404'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187511387 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Add_1454'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187514519 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Pow_1468'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187518449 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Add_1471'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187521558 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Pow_1602'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187525614 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Add_1605'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187529587 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Add_1907'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187532791 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Pow_1703'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187535931 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Pow_2055'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187539170 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Add_1706'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187542494 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Pow_1753'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187545710 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Add_1756'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187549293 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Add_1773'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187552861 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Pow_1904'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187556205 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Pow_1921'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187560294 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Add_2058'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187563582 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Pow_1149'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187566773 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Pow_2072'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187569912 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Add_2075'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187573398 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Add_1555'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187576525 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Add_2159'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187910324 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Add_2482'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187916213 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Pow_2479'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187919541 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Add_2465'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187923103 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Add_2383'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187926129 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Pow_2380'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187931987 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Pow_751'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187935836 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Pow_1656'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187939083 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Pow_570'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187943811 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Pow_1755'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187947237 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Pow_2281'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187950795 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Pow_471'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187954495 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Add_1577'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187957791 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_202'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187961643 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Pow_1212'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187964813 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Add_1560'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187967869 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Pow_932'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187971023 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Unsqueeze_200'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187974372 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Add_1758'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187977947 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Add_1922'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187981063 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Pow_652'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187984174 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Pow_1393'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187989073 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Div_335'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187992511 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Add_2021'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.187995634 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Pow_1031'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.188000036 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Pow_669'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.188003957 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Add_2202'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.188007536 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Pow_833'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.188011135 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Pow_2100'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.188014278 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Pow_370'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.188017484 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Mul_337'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.188033364 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Pow_2199'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.188037196 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Add_1379'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.188051866 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Pow_1195'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.188055553 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Add_2301'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.188059043 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Pow_1294'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.188062244 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Add_1396'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.188065382 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Add_1939'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.188068774 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Add_1840'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.188072369 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Pow_1376'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.188075622 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Pow_488'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.188079292 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Pow_1475'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.188082951 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Pow_2462'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.188086503 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Add_1297'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.188089869 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Pow_1014'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.188093225 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Pow_1557'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.188096387 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Pow_1574'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.188099652 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Pow_1113'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.188116951 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Add_1659'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.188120431 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Pow_850'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.188123667 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Pow_246'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.188126960 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Pow_1936'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.188130233 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Add_1478'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.188134151 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Pow_1738'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.188137473 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::ConstantOfShape_214'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.188140965 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Pow_2117'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.188144268 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Add_1741'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.188147839 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Pow_1837'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.188151473 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Pow_1919'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.188155547 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Pow_2018'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.188159067 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Add_2103'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.188162368 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Add_2120'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.188166822 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Add_2284'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.188170366 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Pow_2298'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.243528259 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'cache_node_onnx::Expand_267'. It is not used by any node and should be removed from the model.\n",
      "2022-05-05 11:35:20.243853133 [W:onnxruntime:, graph.cc:3515 CleanUnusedInitializersAndNodeArgs] Removing initializer 'onnx::Expand_215'. It is not used by any node and should be removed from the model.\n"
     ]
    }
   ],
   "source": [
    "with torch.inference_mode():\n",
    "    out_enc_pytorch: BaseModelOutputWithPastAndCrossAttentions = model.encoder(input_ids=input_ids)\n",
    "    previous_step_pytorch: BaseModelOutputWithPastAndCrossAttentions = model_decoder(\n",
    "        input_ids=input_ids[:, :-1], encoder_hidden_states=out_enc_pytorch.last_hidden_state\n",
    "    )\n",
    "    out_dec_pytorch: BaseModelOutputWithPastAndCrossAttentions = model_decoder(\n",
    "        input_ids=input_ids, encoder_hidden_states=out_enc_pytorch.last_hidden_state\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T10:35:20.832601Z",
     "iopub.status.busy": "2022-05-05T10:35:20.832380Z",
     "iopub.status.idle": "2022-05-05T10:35:20.857646Z",
     "shell.execute_reply": "2022-05-05T10:35:20.857216Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def decoder_pytorch_inference(decoder_input_ids: torch.Tensor, encoder_hidden_states: torch.Tensor, **_):\n",
    "    with torch.inference_mode():\n",
    "        return model_decoder(input_ids=decoder_input_ids, encoder_hidden_states=encoder_hidden_states)\n",
    "\n",
    "\n",
    "def decoder_onnx_inference(\n",
    "    decoder_input_ids: torch.Tensor,\n",
    "    encoder_hidden_states: torch.Tensor,\n",
    "    enable_cache: torch.Tensor,\n",
    "    past_key_values: Optional[torch.Tensor],\n",
    "):\n",
    "    inputs_onnx_dict = {\n",
    "        \"input_ids\": decoder_input_ids,\n",
    "        \"encoder_hidden_states\": encoder_hidden_states,\n",
    "        \"enable_cache\": enable_cache,\n",
    "    }\n",
    "\n",
    "    if past_key_values is not None:\n",
    "        for index, (k_dec, v_dec, k_enc, v_enc) in enumerate(past_key_values):\n",
    "            inputs_onnx_dict[f\"past_key_values.{index}.decoder.key\"] = k_dec\n",
    "            inputs_onnx_dict[f\"past_key_values.{index}.decoder.value\"] = v_dec\n",
    "            inputs_onnx_dict[f\"past_key_values.{index}.encoder.key\"] = k_enc\n",
    "            inputs_onnx_dict[f\"past_key_values.{index}.encoder.value\"] = v_enc\n",
    "\n",
    "    result_dict = inference_onnx_binding(\n",
    "        model_onnx=dec_onnx,\n",
    "        inputs=inputs_onnx_dict,\n",
    "        binding=dec_onnx_binding,  # recycle the binding\n",
    "        device=decoder_input_ids.device.type,\n",
    "        clone_tensor=False,  # no memory copy -> best perf and lowest memory footprint!\n",
    "    )\n",
    "    past_states = list()\n",
    "    for index in range(model.config.num_layers):\n",
    "        kv = (\n",
    "            result_dict[f\"present.{index}.decoder.key\"],\n",
    "            result_dict[f\"present.{index}.decoder.value\"],\n",
    "            result_dict[f\"present.{index}.encoder.key\"],\n",
    "            result_dict[f\"present.{index}.encoder.value\"],\n",
    "        )\n",
    "        past_states.append(kv)\n",
    "    return BaseModelOutputWithPastAndCrossAttentions(\n",
    "        last_hidden_state=result_dict[\"logits\"],\n",
    "        past_key_values=past_states,\n",
    "    )\n",
    "\n",
    "\n",
    "out_dec_onnx_no_cache = decoder_onnx_inference(\n",
    "    decoder_input_ids=input_ids,\n",
    "    encoder_hidden_states=out_enc_pytorch.last_hidden_state,\n",
    "    enable_cache=torch.tensor([False], device=\"cuda\", dtype=torch.bool),\n",
    "    past_key_values=None,\n",
    ")\n",
    "are_equal(a=out_dec_onnx_no_cache.last_hidden_state[:, -1:, :], b=out_dec_pytorch.last_hidden_state[:, -1:, :])\n",
    "\n",
    "# check that past states are identical between ONNX and Pytorch\n",
    "assert len(out_dec_onnx_no_cache.past_key_values) == len(out_dec_pytorch.past_key_values)\n",
    "for (o_dec_k, o_dev_v, o_enc_k, o_enc_v), (p_dec_k, p_dev_v, p_enc_k, p_enc_v) in zip(\n",
    "    out_dec_onnx_no_cache.past_key_values, out_dec_pytorch.past_key_values\n",
    "):\n",
    "    are_equal(a=o_dec_k, b=p_dec_k)\n",
    "    are_equal(a=o_dev_v, b=p_dev_v)\n",
    "    are_equal(a=o_enc_k, b=p_enc_k)\n",
    "    are_equal(a=o_enc_v, b=p_enc_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T10:35:20.861461Z",
     "iopub.status.busy": "2022-05-05T10:35:20.861311Z",
     "iopub.status.idle": "2022-05-05T10:35:20.880311Z",
     "shell.execute_reply": "2022-05-05T10:35:20.879875Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "out_dec_onnx_cache = decoder_onnx_inference(\n",
    "    decoder_input_ids=input_ids[:, -1:],\n",
    "    encoder_hidden_states=out_enc_pytorch.last_hidden_state,\n",
    "    enable_cache=torch.tensor([True], device=\"cuda\", dtype=torch.bool),\n",
    "    past_key_values=previous_step_pytorch.past_key_values,\n",
    ")\n",
    "\n",
    "are_equal(a=out_dec_onnx_cache.last_hidden_state[:, -1:, :], b=out_dec_pytorch.last_hidden_state[:, -1:, :])\n",
    "\n",
    "# check that past states are identical between ONNX and Pytorch\n",
    "assert len(out_dec_onnx_cache.past_key_values) == len(out_dec_pytorch.past_key_values)\n",
    "for (o_dec_k, o_dev_v, o_enc_k, o_enc_v), (p_dec_k, p_dev_v, p_enc_k, p_enc_v) in zip(\n",
    "    out_dec_onnx_cache.past_key_values, out_dec_pytorch.past_key_values\n",
    "):\n",
    "    are_equal(a=o_dec_k, b=p_dec_k)\n",
    "    are_equal(a=o_dev_v, b=p_dev_v)\n",
    "    are_equal(a=o_enc_k, b=p_enc_k)\n",
    "    are_equal(a=o_enc_v, b=p_enc_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T10:35:20.883424Z",
     "iopub.status.busy": "2022-05-05T10:35:20.883276Z",
     "iopub.status.idle": "2022-05-05T10:35:22.020117Z",
     "shell.execute_reply": "2022-05-05T10:35:22.019641Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> study shows that 80% of the world's population is affluent or faecially affiliated.</s>\n",
      "<pad><extra_id_0>.<extra_id_1>. Studies show that 80% of the world's population is influenced by dietary habits. Research shows that the majority of people who are overweight or obese are more likely to be obese than their peers.</s>\n"
     ]
    }
   ],
   "source": [
    "def encoder_onnx_inference(input_ids: torch.Tensor, **_) -> BaseModelOutputWithPastAndCrossAttentions:\n",
    "    last_hidden_state = inference_onnx_binding(\n",
    "        model_onnx=enc_onnx,  # noqa: F821\n",
    "        inputs={\"input_ids\": input_ids},\n",
    "        device=input_ids.device.type,\n",
    "        binding=enc_onnx_binding,\n",
    "    )[\"output\"]\n",
    "    return BaseModelOutputWithPastAndCrossAttentions(last_hidden_state=last_hidden_state.type(torch.float32))\n",
    "\n",
    "\n",
    "def encoder_pytorch_inference(input_ids, **_) -> BaseModelOutputWithPastAndCrossAttentions:\n",
    "    with torch.inference_mode():\n",
    "        res = model.encoder(input_ids=input_ids).type(torch.float32)\n",
    "        return res\n",
    "\n",
    "\n",
    "# https://github.com/NVIDIA/TensorRT/blob/main/demo/HuggingFace/T5/export.py\n",
    "class ExtT5(torch.nn.Module, GenerationMixin):\n",
    "    def __init__(self, config: PretrainedConfig, device: torch.device, encoder_func: Callable, decoder_func: Callable):\n",
    "        super(ExtT5, self).__init__()\n",
    "        self.main_input_name = \"input_ids\"  # https://github.com/huggingface/transformers/pull/14803\n",
    "        self.config: PretrainedConfig = config\n",
    "        self.device: torch.device = device\n",
    "\n",
    "        self.encoder_func = encoder_func\n",
    "        self.decoder_func = decoder_func\n",
    "        self.use_cache = True\n",
    "        self.timings = list()\n",
    "\n",
    "    def get_encoder(self):\n",
    "        return self.encoder_func\n",
    "\n",
    "    def get_decoder(self):\n",
    "        return self.decoder_func\n",
    "\n",
    "    def set_cache(self, enable: bool) -> None:\n",
    "        self.use_cache = enable\n",
    "\n",
    "    # from transformers library (modeling_t5.py)\n",
    "    def _reorder_cache(self, past, beam_idx):\n",
    "        reordered_decoder_past = ()\n",
    "        for layer_past_states in past:\n",
    "            # get the correct batch idx from layer past batch dim\n",
    "            # batch dim of `past` is at 2nd position\n",
    "            reordered_layer_past_states = ()\n",
    "            for layer_past_state in layer_past_states:\n",
    "                # need to set correct `past` for each of the four key / value states\n",
    "                reordered_layer_past_states = reordered_layer_past_states + (\n",
    "                    layer_past_state.index_select(0, beam_idx),\n",
    "                )\n",
    "\n",
    "            assert reordered_layer_past_states[0].shape == layer_past_states[0].shape\n",
    "            assert len(reordered_layer_past_states) == len(layer_past_states)\n",
    "\n",
    "            reordered_decoder_past = reordered_decoder_past + (reordered_layer_past_states,)\n",
    "        return reordered_decoder_past\n",
    "\n",
    "    def prepare_inputs_for_generation(self, input_ids, past=None, use_cache=None, **kwargs) -> Dict[str, torch.Tensor]:\n",
    "        params = {\n",
    "            \"encoder_hidden_states\": kwargs[\"encoder_outputs\"][\"last_hidden_state\"],\n",
    "        }\n",
    "        if past is None:  # this is the 1st inferred token\n",
    "            self.timings = list()\n",
    "        if not self.use_cache:\n",
    "            past = None\n",
    "        if past is None:\n",
    "            params[self.main_input_name] = input_ids\n",
    "            params[\"enable_cache\"] = torch.tensor([False], device=\"cuda\", dtype=torch.bool)\n",
    "        else:\n",
    "            params[self.main_input_name] = input_ids[:, -1:]\n",
    "            params[\"enable_cache\"] = torch.tensor([True], device=\"cuda\", dtype=torch.bool)\n",
    "            params[\"past_key_values\"] = past\n",
    "\n",
    "        return params\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: torch.Tensor,\n",
    "        encoder_hidden_states: torch.Tensor,\n",
    "        enable_cache: torch.Tensor,\n",
    "        past_key_values: Optional[torch.Tensor] = None,\n",
    "        **_,\n",
    "    ):\n",
    "        start_timer = time()\n",
    "        dec_output = self.get_decoder()(\n",
    "            decoder_input_ids=input_ids,\n",
    "            encoder_hidden_states=encoder_hidden_states,\n",
    "            enable_cache=enable_cache,\n",
    "            past_key_values=past_key_values,\n",
    "        )\n",
    "        self.timings.append(time() - start_timer)\n",
    "        return Seq2SeqLMOutput(logits=dec_output.last_hidden_state, past_key_values=dec_output.past_key_values)\n",
    "\n",
    "\n",
    "model_gen = (\n",
    "    ExtT5(\n",
    "        config=model.config,\n",
    "        device=model.device,\n",
    "        encoder_func=encoder_onnx_inference,  # encoder_pytorch_inference\n",
    "        decoder_func=decoder_onnx_inference,  # decoder_pytorch_inference\n",
    "    )\n",
    "    .cuda()\n",
    "    .eval()\n",
    ")\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "with torch.inference_mode():\n",
    "    print(\n",
    "        tokenizer.decode(\n",
    "            model_gen.generate(\n",
    "                inputs=input_ids,\n",
    "                min_length=30,\n",
    "                max_length=60,\n",
    "                num_beams=4,\n",
    "                no_repeat_ngram_size=2,\n",
    "            )[0],\n",
    "            skip_special_tokens=False,\n",
    "        )\n",
    "    )\n",
    "    print(\n",
    "        tokenizer.decode(\n",
    "            model.generate(\n",
    "                input_ids=input_ids,\n",
    "                min_length=30,\n",
    "                max_length=60,\n",
    "                num_beams=4,\n",
    "                no_repeat_ngram_size=2,\n",
    "            )[0],\n",
    "            skip_special_tokens=False,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T10:35:22.024026Z",
     "iopub.status.busy": "2022-05-05T10:35:22.023620Z",
     "iopub.status.idle": "2022-05-05T10:38:01.084668Z",
     "shell.execute_reply": "2022-05-05T10:38:01.084204Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX: 45.13586139678955\n",
      "model: 42.57213044166565\n",
      "ONNX + cache: 13.34917950630188\n",
      "model: 11.047776699066162\n",
      "Pytorch: 78.02505421638489\n",
      "model: 76.64945149421692\n",
      "Pytorch + cache: 22.538686990737915\n",
      "model: 20.461787700653076\n"
     ]
    }
   ],
   "source": [
    "from nvtx import nvtx\n",
    "from copy import copy\n",
    "\n",
    "content_len = 1400\n",
    "num_beam = 4\n",
    "\n",
    "with nvtx.annotate(\"ONNX\", color=\"red\"):\n",
    "    model_gen.set_cache(enable=False)\n",
    "    start = time()\n",
    "    model_gen.generate(inputs=input_ids, max_length=content_len, num_beams=num_beam, min_length=content_len)\n",
    "    print(f\"ONNX: {time() - start}\")\n",
    "    print(f\"model: {sum(model_gen.timings)}\")\n",
    "    timing_onnx_no_cache = model_gen.timings\n",
    "\n",
    "with nvtx.annotate(\"ONNX\", color=\"red\"):\n",
    "    model_gen.set_cache(enable=True)\n",
    "    start = time()\n",
    "    model_gen.generate(inputs=input_ids, max_length=content_len, num_beams=num_beam, min_length=content_len)\n",
    "    print(f\"ONNX + cache: {time() - start}\")\n",
    "    print(f\"model: {sum(model_gen.timings)}\")\n",
    "    timing_onnx_cache = model_gen.timings\n",
    "\n",
    "# monckey patching of forward function to add a timer per generated token\n",
    "old_fw = model.forward\n",
    "timing_pytorch = list()\n",
    "\n",
    "\n",
    "def new_fw(self, *args, **kwargs):\n",
    "    timer_start = time()\n",
    "    res = old_fw(self, *args, **kwargs)\n",
    "    torch.cuda.synchronize()  # makes timings correct without having significant impact on e2e latency\n",
    "    timing_pytorch.append(time() - timer_start)\n",
    "    return res\n",
    "\n",
    "\n",
    "model.forward = new_fw.__get__(model)\n",
    "\n",
    "with nvtx.annotate(\"Pytorch\", color=\"orange\"):\n",
    "    model.config.use_cache = False\n",
    "    with torch.inference_mode():\n",
    "        with torch.cuda.amp.autocast():\n",
    "            start = time()\n",
    "            model.generate(inputs=input_ids, max_length=content_len, num_beams=num_beam, min_length=content_len)\n",
    "            torch.cuda.synchronize()\n",
    "            print(f\"Pytorch: {time() - start}\")\n",
    "            print(f\"model: {sum(timing_pytorch)}\")\n",
    "    timing_pytorch_no_cache = copy(timing_pytorch)\n",
    "    timing_pytorch.clear()\n",
    "\n",
    "with nvtx.annotate(\"Pytorch + cache\", color=\"green\"):\n",
    "    model.config.use_cache = True\n",
    "    with torch.inference_mode():\n",
    "        with torch.cuda.amp.autocast():\n",
    "            start = time()\n",
    "            model.generate(inputs=input_ids, max_length=content_len, num_beams=num_beam, min_length=content_len)\n",
    "            torch.cuda.synchronize()\n",
    "            print(f\"Pytorch + cache: {time() - start}\")\n",
    "            print(f\"model: {sum(timing_pytorch)}\")\n",
    "    timing_pytorch_cache = copy(timing_pytorch)\n",
    "    timing_pytorch.clear()\n",
    "model.forward = old_fw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T10:38:01.088067Z",
     "iopub.status.busy": "2022-05-05T10:38:01.087717Z",
     "iopub.status.idle": "2022-05-05T10:38:01.310385Z",
     "shell.execute_reply": "2022-05-05T10:38:01.309929Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fb94cb71fd0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "axis = range(len(timing_onnx_no_cache))\n",
    "plt.scatter(axis, timing_onnx_no_cache, marker=\"o\", color=\"red\", label=\"ONNX\", s=1)\n",
    "plt.scatter(axis, timing_onnx_cache, marker=\"o\", color=\"purple\", label=\"ONNX + cache\", s=1)\n",
    "plt.scatter(axis, timing_pytorch_no_cache, marker=\"o\", color=\"cyan\", label=\"Pytroch\", s=1)\n",
    "plt.scatter(axis, timing_pytorch_cache, marker=\"o\", color=\"green\", label=\"Pytroch + cache\", s=1)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T10:38:01.313039Z",
     "iopub.status.busy": "2022-05-05T10:38:01.312900Z",
     "iopub.status.idle": "2022-05-05T10:38:01.513830Z",
     "shell.execute_reply": "2022-05-05T10:38:01.513286Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fb93c349850>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "axis = range(len(timing_onnx_no_cache))\n",
    "plt.scatter(axis, np.cumsum(timing_onnx_no_cache), marker=\"o\", color=\"red\", label=\"ONNX\", s=1)\n",
    "plt.scatter(axis, np.cumsum(timing_onnx_cache), marker=\"o\", color=\"purple\", label=\"ONNX + cache\", s=1)\n",
    "plt.scatter(axis, np.cumsum(timing_pytorch_no_cache), marker=\"o\", color=\"cyan\", label=\"Pytroch\", s=1)\n",
    "plt.scatter(axis, np.cumsum(timing_pytorch_cache), marker=\"o\", color=\"green\", label=\"Pytroch + cache\", s=1)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# TODO change axis name to better describe what they are, in particular manage encoder and decoder models with common names\n",
    "\n",
    "\n",
    "link to https://github.com/microsoft/onnxruntime/pull/10651 !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}