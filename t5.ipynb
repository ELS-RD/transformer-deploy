{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from time import time\n",
    "from typing import Callable, Dict, Set\n",
    "\n",
    "import numpy as np\n",
    "import onnx\n",
    "import tensorrt as trt\n",
    "import torch\n",
    "from onnx import ModelProto\n",
    "from tensorrt import ICudaEngine\n",
    "from tensorrt.tensorrt import Logger, Runtime\n",
    "from torch.nn import Linear\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, PretrainedConfig, T5ForConditionalGeneration, TensorType\n",
    "from transformers.generation_utils import GenerationMixin\n",
    "from transformers.modeling_outputs import BaseModelOutputWithPastAndCrossAttentions, Seq2SeqLMOutput\n",
    "from transformers.models.t5.modeling_t5 import T5Stack\n",
    "\n",
    "from transformer_deploy.backends.ort_utils import create_model_for_provider, inference_onnx_binding, optimize_onnx\n",
    "from transformer_deploy.backends.pytorch_utils import convert_to_onnx\n",
    "from transformer_deploy.backends.trt_utils import (\n",
    "    TensorRTShape,\n",
    "    add_output_nodes,\n",
    "    build_engine,\n",
    "    get_adjency_dict,\n",
    "    get_fix_fp16_network_func,\n",
    "    get_list_fp32_nodes,\n",
    "    load_engine,\n",
    "    save_engine,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "model_name = \"t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "input_ids: torch.Tensor = tokenizer(\"Studies show that\", return_tensors=TensorType.PYTORCH).input_ids\n",
    "input_ids = input_ids.to(\"cuda\")\n",
    "model: T5ForConditionalGeneration = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "model = model.eval()\n",
    "model = model.to(\"cuda\")\n",
    "out_enc: BaseModelOutputWithPastAndCrossAttentions = model.encoder(input_ids=input_ids)\n",
    "out_full: Seq2SeqLMOutput = model(input_ids=input_ids, decoder_input_ids=input_ids)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/geantvert/.local/share/virtualenvs/fast_transformer/lib/python3.9/site-packages/transformers/modeling_utils.py:529: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if causal_mask.shape[1] < attention_mask.shape[1]:\n"
     ]
    }
   ],
   "source": [
    "class ExportT5(torch.nn.Module):\n",
    "    def __init__(self, decoder: T5Stack, lm_head: Linear):\n",
    "        super(ExportT5, self).__init__()\n",
    "        self.decoder = decoder\n",
    "        self.lm_head = lm_head\n",
    "\n",
    "    def forward(self, input_ids: torch.Tensor, encoder_hidden_states: torch.Tensor):\n",
    "        out_dec = self.decoder.forward(input_ids=input_ids, encoder_hidden_states=encoder_hidden_states)\n",
    "        # Rescale output before projecting on vocab\n",
    "        out_dec = out_dec[\"last_hidden_state\"] * (model.model_dim**-0.5)\n",
    "        out_lm = self.lm_head(out_dec)\n",
    "        return out_lm\n",
    "\n",
    "\n",
    "model = model.to(\"cuda\")\n",
    "\n",
    "convert_to_onnx(\n",
    "    model_pytorch=model.encoder,\n",
    "    output_path=\"test-enc.onnx\",\n",
    "    inputs_pytorch={\"input_ids\": input_ids},\n",
    "    var_output_seq=True,\n",
    "    quantization=False,\n",
    ")\n",
    "optimize_onnx(\n",
    "    onnx_path=\"test-enc.onnx\", onnx_optim_model_path=\"test-enc-opt.onnx\", architecture=\"bert\", use_cuda=True, fp16=True\n",
    ")\n",
    "\n",
    "enc_onnx = create_model_for_provider(\"test-enc-opt.onnx\", \"CUDAExecutionProvider\")\n",
    "enc_onnx_out = inference_onnx_binding(\n",
    "    model_onnx=enc_onnx,\n",
    "    inputs={\"input_ids\": input_ids},\n",
    "    device=input_ids.device.type,\n",
    "    output_shape=tuple(input_ids.shape) + (int(model.encoder.config.d_model),),\n",
    ")[\"output\"]\n",
    "assert np.allclose(enc_onnx_out.detach().cpu().numpy(), out_enc.last_hidden_state.detach().cpu().numpy(), atol=1e-2)\n",
    "\n",
    "model_to_export = ExportT5(decoder=model.decoder, lm_head=model.lm_head).eval()\n",
    "out_model_export: torch.Tensor = model_to_export(input_ids=input_ids, encoder_hidden_states=out_enc.last_hidden_state)\n",
    "assert np.allclose(out_model_export.detach().cpu().numpy(), out_full.logits.detach().cpu().numpy(), atol=1e-5)\n",
    "\n",
    "inputs_onnx = {\"input_ids\": input_ids, \"encoder_hidden_states\": out_enc.last_hidden_state}\n",
    "\n",
    "convert_to_onnx(\n",
    "    model_pytorch=model_to_export,\n",
    "    output_path=\"test-dec.onnx\",\n",
    "    inputs_pytorch=inputs_onnx,\n",
    "    var_output_seq=False,\n",
    "    quantization=False,\n",
    "    fix_output_dim_size=False,  # specific to decoder part\n",
    ")\n",
    "optimize_onnx(\n",
    "    onnx_path=\"test-dec.onnx\",\n",
    "    onnx_optim_model_path=\"test-dec-opt.onnx\",\n",
    "    architecture=\"bert\",\n",
    "    use_cuda=True,\n",
    "    fp16=True,\n",
    "    num_attention_heads=model.config.num_heads,\n",
    "    hidden_size=model.config.d_model,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> Studien studies show that</s>\n",
      "<pad> Studien studies show that</s>\n",
      "11.376280784606934\n",
      "15.102983236312866\n"
     ]
    }
   ],
   "source": [
    "model = model.to(\"cuda\")\n",
    "enc_onnx = create_model_for_provider(\"test-enc-opt.onnx\", \"CUDAExecutionProvider\")\n",
    "dec_onnx = create_model_for_provider(\"test-dec-opt.onnx\", \"CUDAExecutionProvider\")\n",
    "\n",
    "\n",
    "def decoder_pytorch_inference(input_ids: torch.Tensor, last_hidden_state: torch.Tensor):\n",
    "    out_dec = model.decoder(input_ids=input_ids, encoder_hidden_states=last_hidden_state)[\"last_hidden_state\"]\n",
    "    # Rescale output before projecting on vocab\n",
    "    out_dec = out_dec * (model.model_dim**-0.5)\n",
    "    out_lm = model.lm_head(out_dec)\n",
    "    return out_lm\n",
    "\n",
    "\n",
    "def decoder_onnx_inference(input_ids: torch.Tensor, last_hidden_state: torch.Tensor):\n",
    "    result_dict = inference_onnx_binding(\n",
    "        model_onnx=dec_onnx,\n",
    "        inputs={\"input_ids\": input_ids, \"encoder_hidden_states\": last_hidden_state},\n",
    "        device=input_ids.device.type,\n",
    "        output_shape=tuple(input_ids.shape) + (int(model.config.vocab_size),),\n",
    "    )\n",
    "    return result_dict[\"output\"]\n",
    "\n",
    "\n",
    "def decoder_onnx_standard_inference(input_ids: torch.Tensor, last_hidden_state: torch.Tensor):\n",
    "    result_list = dec_onnx.run(\n",
    "        None, {\"input_ids\": input_ids.type(torch.int32).numpy(), \"encoder_hidden_states\": last_hidden_state.numpy()}\n",
    "    )\n",
    "    return torch.from_numpy(result_list[0])\n",
    "\n",
    "\n",
    "dec_onnx_out = decoder_onnx_inference(input_ids=input_ids, last_hidden_state=out_enc.last_hidden_state)\n",
    "assert np.allclose(dec_onnx_out.detach().cpu().numpy(), out_full.logits.detach().cpu().numpy(), atol=1e-1)\n",
    "\n",
    "\n",
    "def encoder_onnx_inference(input_ids: torch.Tensor, **_) -> BaseModelOutputWithPastAndCrossAttentions:\n",
    "    result = inference_onnx_binding(\n",
    "        model_onnx=enc_onnx,  # noqa: F821\n",
    "        inputs={\"input_ids\": input_ids},\n",
    "        output_shape=tuple(input_ids.shape) + (int(model.encoder.config.d_model),),\n",
    "        device=input_ids.device.type,\n",
    "    )\n",
    "    return BaseModelOutputWithPastAndCrossAttentions(last_hidden_state=result[\"output\"])\n",
    "\n",
    "\n",
    "def encoder_pytorch_inference(input_ids, **_) -> BaseModelOutputWithPastAndCrossAttentions:\n",
    "    return model.encoder(input_ids=input_ids)\n",
    "\n",
    "\n",
    "# https://github.com/NVIDIA/TensorRT/blob/main/demo/HuggingFace/T5/export.py\n",
    "class ExtT5(torch.nn.Module, GenerationMixin):\n",
    "    def __init__(self, config: PretrainedConfig, device: torch.device, encoder_func: Callable, decoder_func: Callable):\n",
    "        super(ExtT5, self).__init__()\n",
    "        self.main_input_name = \"input_ids\"  # https://github.com/huggingface/transformers/pull/14803\n",
    "        self.config: PretrainedConfig = config\n",
    "        self.device: torch.device = device\n",
    "\n",
    "        self.encoder_func = encoder_func\n",
    "        self.decoder_func = decoder_func\n",
    "\n",
    "    def get_encoder(self):\n",
    "        return self.encoder_func\n",
    "\n",
    "    def get_decoder(self):\n",
    "        return self.decoder_func\n",
    "\n",
    "    def prepare_inputs_for_generation(self, input_ids, **kwargs):\n",
    "        return {\n",
    "            self.main_input_name: input_ids,\n",
    "            \"encoder_hidden_states\": kwargs[\"encoder_outputs\"][\"last_hidden_state\"],\n",
    "        }\n",
    "\n",
    "    def forward(self, input_ids: torch.Tensor, encoder_hidden_states: torch.Tensor, **_):\n",
    "        dec_output = self.get_decoder()(input_ids=input_ids, last_hidden_state=encoder_hidden_states)\n",
    "        return Seq2SeqLMOutput(logits=dec_output)\n",
    "\n",
    "\n",
    "model_gen = (\n",
    "    ExtT5(\n",
    "        config=model.config,\n",
    "        device=model.device,\n",
    "        encoder_func=encoder_onnx_inference,  # encoder_pytorch_inference\n",
    "        decoder_func=decoder_onnx_inference,  # decoder_pytorch_inference\n",
    "    )\n",
    "    .cuda()\n",
    "    .eval()\n",
    ")\n",
    "\n",
    "# model = model.eval()\n",
    "with torch.inference_mode():\n",
    "    out_enc: BaseModelOutputWithPastAndCrossAttentions = model.encoder(input_ids=input_ids)\n",
    "    a = model_gen(input_ids=input_ids, encoder_hidden_states=out_enc.last_hidden_state).logits\n",
    "    b = model(input_ids=input_ids, decoder_input_ids=input_ids).logits\n",
    "    assert np.allclose(a.detach().cpu().numpy(), b.detach().cpu().numpy(), atol=1e-1)\n",
    "\n",
    "    print(\n",
    "        tokenizer.decode(\n",
    "            model_gen.generate(inputs=input_ids, max_length=20, num_beams=7, no_repeat_ngram_size=2)[0],\n",
    "            skip_special_tokens=False,\n",
    "        )\n",
    "    )\n",
    "    print(\n",
    "        tokenizer.decode(\n",
    "            model.generate(inputs=input_ids, max_length=20, num_beams=7, no_repeat_ngram_size=2)[0],\n",
    "            skip_special_tokens=False,\n",
    "        )\n",
    "    )\n",
    "\n",
    "start = time()\n",
    "for _ in range(3):\n",
    "    model_gen.generate(inputs=input_ids, max_length=500, num_beams=5, no_repeat_ngram_size=2, min_length=500)\n",
    "print(time() - start)\n",
    "\n",
    "model.config.use_cache = True\n",
    "with torch.inference_mode():\n",
    "    start = time()\n",
    "    for _ in range(3):\n",
    "        model.generate(inputs=input_ids, max_length=500, num_beams=5, no_repeat_ngram_size=2, min_length=500)\n",
    "    print(time() - start)\n",
    "\n",
    "model = model.cpu()\n",
    "del enc_onnx\n",
    "del dec_onnx\n",
    "\n",
    "trt_logger: Logger = trt.Logger(trt.Logger.ERROR)\n",
    "runtime: Runtime = trt.Runtime(trt_logger)\n",
    "trt_model_name = \"trt-t5-dec.plan\"\n",
    "\n",
    "# create only of does not exist because it's slow to run...\n",
    "\n",
    "# 768 for base model, 512 for small, make it dependent from the Pytorch model configuration\n",
    "input_id_shape = TensorRTShape(min_shape=[5, 1], optimal_shape=[5, 500], max_shape=[5, 500], input_name=\"input_ids\")\n",
    "encoder_hidden_states_shape = TensorRTShape(\n",
    "    min_shape=[5, 1, 512], optimal_shape=[5, 500 // 2, 512], max_shape=[5, 500, 512], input_name=\"encoder_hidden_states\"\n",
    ")\n",
    "\n",
    "\n",
    "model = model.cuda()\n",
    "model_onnx: ModelProto = onnx.load(\"test-dec.onnx\")\n",
    "model_onnx_all_nodes = add_output_nodes(model=model_onnx)\n",
    "onnx_graph: Dict[str, Set[str]] = get_adjency_dict(model=model_onnx)\n",
    "ort_model_all_nodes = create_model_for_provider(model_onnx_all_nodes.SerializeToString(), \"CUDAExecutionProvider\")\n",
    "\n",
    "\n",
    "# use info from tokenizer size and max shape provided through the command line\n",
    "def get_random_input():\n",
    "    input = torch.randint(high=tokenizer.vocab_size, size=(5, 500), dtype=torch.int32, device=\"cuda\")\n",
    "    hidden_state = model.encoder(input_ids=input).last_hidden_state.detach().cpu().numpy()\n",
    "    return {\"input_ids\": input.detach().cpu().numpy(), \"encoder_hidden_states\": hidden_state}\n",
    "\n",
    "\n",
    "keep_fp32 = get_list_fp32_nodes(\n",
    "    onnx_graph=onnx_graph, model=ort_model_all_nodes, get_input=get_random_input, nb_try=200\n",
    ")\n",
    "model = model.cpu()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-48.0837, -14.2924, -20.4697,  ..., -67.6401, -67.8845, -67.8307],\n",
      "        [-54.2150, -14.2975, -21.5249,  ..., -66.5756, -66.9168, -66.7166],\n",
      "        [-35.6373,  -5.6440, -15.6157,  ..., -49.5720, -49.8802, -49.7263],\n",
      "        [-31.3241,  -3.7928, -11.2605,  ..., -43.0666, -43.3176, -43.1935]],\n",
      "       device='cuda:0')\n",
      "1.600128173828125\n",
      "0.7323088645935059\n",
      "1.230060338973999\n"
     ]
    }
   ],
   "source": [
    "engine: ICudaEngine = build_engine(\n",
    "    runtime=runtime,\n",
    "    onnx_file_path=\"test-dec.onnx\",\n",
    "    logger=trt_logger,\n",
    "    workspace_size=20000 * 1024**2,\n",
    "    fp16=True,\n",
    "    int8=False,\n",
    "    input_shapes=[input_id_shape, encoder_hidden_states_shape],\n",
    "    fp16_fix=get_fix_fp16_network_func(keep_fp32=keep_fp32),\n",
    ")\n",
    "save_engine(engine, trt_model_name)\n",
    "\n",
    "tensorrt_model = load_engine(runtime=runtime, engine_file_path=trt_model_name)\n",
    "a = tensorrt_model(\n",
    "    {\n",
    "        \"input_ids\": input_ids.type(torch.int32).repeat((5, 1)),\n",
    "        \"encoder_hidden_states\": out_enc.last_hidden_state.repeat((5, 1, 1)),\n",
    "    }\n",
    ")\n",
    "print(a[0])\n",
    "\n",
    "benchmark_input = torch.ones((5, 500), dtype=torch.int32, device=\"cuda\")\n",
    "benchmark_enc_output = out_enc.last_hidden_state.repeat((5, 1, 1))\n",
    "for _ in range(10):\n",
    "    tensorrt_model(\n",
    "        {\n",
    "            \"input_ids\": benchmark_input,\n",
    "            \"encoder_hidden_states\": benchmark_enc_output,\n",
    "        }\n",
    "    )\n",
    "start = time()\n",
    "for _ in range(100):\n",
    "    tensorrt_model(\n",
    "        {\n",
    "            \"input_ids\": benchmark_input,\n",
    "            \"encoder_hidden_states\": benchmark_enc_output,\n",
    "        }\n",
    "    )\n",
    "print(time() - start)\n",
    "\n",
    "dec_onnx = create_model_for_provider(\"test-dec-opt.onnx\", \"CUDAExecutionProvider\")\n",
    "dec_onnx_out = decoder_onnx_inference(input_ids=input_ids, last_hidden_state=out_enc.last_hidden_state)\n",
    "\n",
    "\n",
    "for _ in range(10):\n",
    "    decoder_onnx_inference(input_ids=benchmark_input, last_hidden_state=benchmark_enc_output)\n",
    "start = time()\n",
    "for _ in range(100):\n",
    "    decoder_onnx_inference(input_ids=benchmark_input, last_hidden_state=benchmark_enc_output)\n",
    "print(time() - start)\n",
    "\n",
    "model.cuda()\n",
    "for _ in range(10):\n",
    "    model.decoder(input_ids=benchmark_input, encoder_hidden_states=benchmark_enc_output)\n",
    "start = time()\n",
    "for _ in range(100):\n",
    "    model.decoder(input_ids=benchmark_input, encoder_hidden_states=benchmark_enc_output)\n",
    "print(time() - start)\n",
    "\n",
    "# TensorRT, ONNX Runtime, Pytorch\n",
    "\n",
    "# sequence 500\n",
    "# 0.8640644550323486\n",
    "# 0.6695075035095215\n",
    "# 1.1308434009552002\n",
    "\n",
    "# sequence 250\n",
    "# 0.9177014827728271\n",
    "# 0.6861860752105713\n",
    "# 1.1923034191131592"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 2.7558e-02,  1.5035e-01, -1.0642e-01,  1.3436e-01, -2.7034e-03,\n          1.0121e-01, -3.7072e-02, -1.1961e-01,  4.2827e-01, -6.8828e-02,\n          4.7860e-03,  1.0388e-01, -1.9117e-01, -9.1395e-02,  8.0236e-01,\n         -2.9004e-02, -8.3236e-03, -4.1821e-02,  5.1209e-02, -8.1611e-02,\n          5.2725e-02,  7.5980e-02, -8.5656e-02,  2.2240e+00,  4.7778e-02,\n         -7.0944e-02, -3.6483e-02,  2.8398e-01, -3.3781e-02, -1.3103e-01,\n          4.6392e-02, -4.0270e-02, -5.6167e-02, -1.5688e-02,  4.1200e-01,\n         -3.9407e-02, -1.1113e-01, -7.7969e-02, -1.3417e-01,  1.9564e-01,\n         -4.9984e-02, -5.9329e-02,  2.2479e-01,  7.3668e-02, -5.7873e-02,\n          1.4900e-02, -6.9493e-01,  1.7280e-02,  1.0609e-01,  9.2358e-02,\n         -1.3377e-01, -5.1072e-02, -8.8388e-02,  1.4478e-01, -1.1261e-01,\n          4.1928e-03,  5.3930e-02, -7.4811e-02,  5.8460e-02,  2.1837e-02,\n          8.2831e-02,  9.2348e-02, -2.5649e-02, -8.6028e-02, -1.2986e-02,\n         -4.3584e-02, -4.8884e-02, -3.3386e-02,  5.5349e-01,  1.8710e-01,\n         -3.0446e-02,  5.1245e-02,  5.5034e-02, -5.5080e-02, -1.7116e-03,\n          9.5299e-02, -4.5908e-02, -1.2584e-02,  8.4189e-02,  2.0390e-01,\n         -2.0322e-01,  8.3806e-02,  5.3210e-02, -8.4752e-02, -4.7789e-02,\n         -1.1201e-01, -2.8879e-02, -3.3881e-02, -1.7329e-01,  6.1102e-01,\n         -1.2889e-02, -9.4040e-02,  8.2499e-02, -7.6344e-02, -8.5806e-02,\n          2.5688e-02, -1.5681e-02, -1.1451e-02,  6.4907e-03, -2.3519e-02,\n          3.4917e-02, -5.8727e-02,  1.3254e-02,  1.5825e-01,  4.7590e-02,\n          1.0409e-01,  6.9138e-02,  3.9837e-02, -3.2700e-02, -9.1413e-02,\n         -1.0145e-01,  1.4211e-03, -4.9003e-03,  7.6215e-02, -7.3899e-02,\n         -8.5377e-02,  2.2540e-02, -4.9561e-02,  3.2881e-02, -2.2287e-02,\n         -6.8049e-02, -2.0162e-02,  1.6643e-02,  2.7118e-04, -2.5598e-02,\n          4.4508e-01, -9.3383e-02,  3.1402e-02, -1.0722e-01, -7.8249e-02,\n          2.4561e-02,  1.1590e-02, -6.1977e-02, -8.2639e-03, -4.8054e-02,\n          2.7819e-02, -5.3643e-02,  6.1974e-01, -8.0894e-02,  1.1800e-02,\n         -3.8681e-02, -9.5972e-02,  8.1281e-02, -6.7938e-02,  5.6997e-02,\n          6.1085e-02,  9.6156e-02,  2.4264e-02,  1.5556e-02, -3.0101e+00,\n          1.2210e-01, -1.4733e-02,  8.8266e-02, -1.0615e-02,  9.5372e-02,\n          3.4785e-02, -4.5652e-02,  3.7928e-02,  7.2694e-02, -6.9918e+00,\n         -9.0426e-02,  5.7168e-02,  9.9028e-02,  4.6014e-02, -1.1359e-01,\n         -1.3036e-01,  1.4493e-01,  3.3658e-01, -5.2206e-02,  4.0246e-02,\n          2.0170e-02, -5.1977e-02,  4.4187e-02, -7.7361e-02,  1.9363e-02,\n          6.2262e-02, -6.1391e-02,  1.8870e-03, -3.3080e-02,  2.0343e-03,\n          3.4712e-02,  4.9128e-02,  2.6168e-03,  6.7538e-02, -3.0646e-01,\n         -1.0470e-01,  8.9288e-02,  1.2655e-01, -9.8930e-02, -2.5814e-02,\n         -1.1663e+00, -2.1569e-01,  3.9756e-03, -5.4395e-02,  4.2298e-03,\n         -1.4125e-02, -7.4977e-03, -6.1164e-02,  1.7089e-02, -6.3246e-02,\n         -3.2219e-02, -4.2473e-02, -3.9572e-02, -3.2147e-02, -7.0602e-02,\n          1.7271e-03,  3.1442e-02, -5.3144e-02, -4.6806e-02, -7.4991e-02,\n          1.7826e-02,  3.7886e-02, -5.9538e-02, -1.5893e-01, -6.2725e-02,\n         -2.4954e-02, -1.1495e-02, -5.6767e-02,  1.7637e-02, -5.2201e-02,\n         -3.3890e-02,  1.0832e-01, -3.6066e-02, -1.4835e-01,  7.2391e-03,\n          1.9350e-02, -2.5393e-01,  4.7064e-02, -1.2885e-01, -5.2605e-02,\n          3.4596e-02, -3.2223e-02,  2.3422e-02,  7.2860e-02, -2.5571e-01,\n         -6.5474e-02,  1.2896e-01,  8.3955e-02, -9.2654e-02,  7.1887e-02,\n          2.8062e-01,  4.2431e-02,  2.2218e-02,  4.0215e-02, -1.6136e-01,\n          9.2229e-01,  8.5288e-02,  4.6689e-04, -6.1003e-01,  4.4943e-02,\n          5.1845e-02,  1.8363e-02,  5.8040e-02, -6.6558e-02, -1.2740e-02,\n         -4.8374e-02, -7.0576e-03, -7.4274e-02, -2.5041e-01,  9.4789e-02,\n         -2.0065e-02,  5.5635e-03,  1.0549e-01,  6.3857e-01, -1.2988e-02,\n          6.1025e-02, -9.9692e-02,  8.6344e-02,  5.2507e-03, -8.4472e-02,\n          6.4332e-02, -3.9105e-02,  2.0621e-01,  5.0989e-01,  6.3143e-02,\n         -2.0267e-02, -4.0145e-02,  6.0277e-03, -5.9656e-02, -1.2237e-01,\n         -4.2363e-01,  3.2023e-02, -3.3462e-02, -5.3224e-03,  6.4035e-02,\n         -2.4841e-02,  7.4523e-02,  4.0785e-02,  5.0653e-02,  1.5206e-02,\n         -2.3787e-01,  4.2905e-04,  5.5600e-02,  1.7442e-01, -2.0597e+00,\n          2.2187e-01, -8.1337e-02, -3.3713e-02,  1.3336e-02,  3.6996e-02,\n          7.0871e-02,  1.7253e-02,  6.7578e-02,  1.5223e-02, -4.0918e-02,\n          4.6613e-02, -1.5509e-01, -3.2361e-01,  4.6950e-01, -9.7088e-02,\n         -2.0382e-02,  1.8947e-01, -7.4724e-01,  1.4031e-01, -9.4198e-02,\n         -5.9677e-02,  3.4392e-02,  4.5680e-02, -2.0871e-01, -6.9111e-02,\n         -1.0838e-01, -1.4020e-01, -9.6648e-02, -2.4828e-01, -2.9278e+00,\n          4.8934e-02,  7.4296e-02,  6.2194e-02,  1.5646e-02,  8.0211e-02,\n          8.4065e-02, -8.2835e-02, -1.4783e-01,  6.2116e-02,  6.1863e-03,\n         -8.3127e-02, -1.6525e-01, -4.2172e-02, -8.7703e-02, -1.0587e-01,\n          6.6061e-02, -1.2229e-01, -6.8209e-03,  1.3168e-01, -1.0773e-02,\n         -1.7031e-01,  2.6722e-02, -3.8696e-02,  7.6689e-02, -5.8725e-02,\n          1.9595e-01, -1.2188e-02,  5.9784e-02,  5.0740e-02,  2.5466e-02,\n         -2.7911e-01, -1.2255e-01,  2.8395e-02,  3.9120e-02,  1.3815e-01,\n         -9.5946e-02,  1.9945e-02,  6.0094e-02, -1.4042e-01, -5.9581e-02,\n         -1.0952e-01, -7.3304e-02, -3.3756e-01, -1.6652e-03,  8.1181e-04,\n          6.8361e-02,  1.6927e-01, -6.6210e-02,  1.1466e-02, -3.0490e-01,\n         -1.2575e-01,  8.7528e-03, -8.2843e-02,  3.2838e-03, -2.1481e-01,\n          4.4152e-02, -1.1502e+00, -2.0167e-01, -2.2349e-02,  1.5185e-01,\n          5.1614e-02,  1.1127e-01,  2.4280e-02, -2.7464e-01, -8.6794e-03,\n          1.2796e-02,  2.3091e-02, -1.4170e-01,  1.2471e-02, -6.3778e-02,\n         -1.0977e-01,  4.8351e-02,  7.4095e-02,  5.8914e-02,  7.7498e-02,\n          2.7251e-01,  1.8195e-01,  7.3700e-02, -1.1701e-01, -5.5508e-02,\n          2.0029e-02, -5.6784e-02, -3.5544e-02, -1.6008e-02,  4.2423e-02,\n          2.4862e-01, -1.2843e-01, -9.1526e-02, -9.2777e-02, -1.5552e-02,\n          2.1962e-02,  5.6796e-02,  3.9258e-01,  1.6204e-02,  2.8135e-02,\n          5.0101e-02, -1.0456e-01, -8.2916e-02,  2.7435e-02, -1.5171e-01,\n         -7.9315e-02,  3.0147e-02, -1.7285e-02, -1.2829e-01,  2.7650e-02,\n          5.3211e-02, -5.4338e-02,  1.0162e-01, -1.9675e-02, -9.0279e-02,\n         -4.6922e-02,  1.6096e-03,  1.9443e-02,  3.8715e-02, -4.2711e-02,\n         -7.7991e-02,  4.1426e-02,  8.2201e-03,  1.5081e-01,  3.3575e-03,\n         -2.2131e-02,  3.8794e-03, -1.0341e-01, -1.3226e-01,  9.7978e-04,\n          8.5674e-02, -6.0801e-02, -5.3318e-02, -1.8344e-01,  4.9798e-02,\n          2.9513e-02,  5.8625e-02, -1.1644e-02,  5.6686e-02, -2.3213e-02,\n          5.9430e-02,  3.0600e-02, -7.0081e-02, -9.4119e-02,  1.2767e-01,\n         -9.1701e-02,  5.3907e-02,  1.4844e-01,  5.5191e-02, -4.8491e-02,\n         -7.4864e-02, -4.8856e-03, -1.1108e-01,  2.9740e-02, -1.3206e-01,\n         -1.0341e-01, -5.5583e-02, -3.4414e-01, -9.1679e-03, -3.5313e-02,\n         -1.3231e-01,  4.7432e-02,  8.9266e-02, -1.2552e-01,  5.9633e-02,\n         -5.4128e-02, -9.0885e-03, -1.9906e-01, -4.2343e-03, -8.0676e-03,\n          1.4961e-03, -7.9238e-02,  6.1884e-02,  4.9478e-02, -7.5517e-02,\n          1.7999e-02,  8.1206e-02, -1.8421e-01, -6.5564e-02, -6.8393e-02,\n         -2.1154e-01, -7.4016e-01, -3.8952e-02,  1.1902e-01,  3.7813e-02,\n         -1.3577e-01, -1.5776e-01, -1.4139e-02,  4.6991e-02,  6.5095e-02,\n          3.4050e-04,  5.8639e-02]], device='cuda:0', grad_fn=<SliceBackward0>)"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_enc: BaseModelOutputWithPastAndCrossAttentions = model.encoder(input_ids=input_ids)\n",
    "model.decoder(\n",
    "    input_ids=input_ids, encoder_hidden_states=out_enc.last_hidden_state, past_key_values=None\n",
    ").last_hidden_state[:, -1, :]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 2.7559e-02,  1.5035e-01, -1.0642e-01,  1.3436e-01, -2.7034e-03,\n          1.0121e-01, -3.7072e-02, -1.1961e-01,  4.2827e-01, -6.8828e-02,\n          4.7861e-03,  1.0388e-01, -1.9117e-01, -9.1395e-02,  8.0236e-01,\n         -2.9004e-02, -8.3238e-03, -4.1821e-02,  5.1210e-02, -8.1611e-02,\n          5.2724e-02,  7.5980e-02, -8.5656e-02,  2.2240e+00,  4.7778e-02,\n         -7.0944e-02, -3.6484e-02,  2.8398e-01, -3.3781e-02, -1.3103e-01,\n          4.6392e-02, -4.0270e-02, -5.6167e-02, -1.5688e-02,  4.1200e-01,\n         -3.9406e-02, -1.1113e-01, -7.7969e-02, -1.3417e-01,  1.9564e-01,\n         -4.9984e-02, -5.9328e-02,  2.2479e-01,  7.3668e-02, -5.7874e-02,\n          1.4900e-02, -6.9493e-01,  1.7280e-02,  1.0609e-01,  9.2357e-02,\n         -1.3377e-01, -5.1072e-02, -8.8387e-02,  1.4478e-01, -1.1260e-01,\n          4.1932e-03,  5.3930e-02, -7.4811e-02,  5.8460e-02,  2.1838e-02,\n          8.2830e-02,  9.2348e-02, -2.5650e-02, -8.6029e-02, -1.2986e-02,\n         -4.3583e-02, -4.8884e-02, -3.3387e-02,  5.5351e-01,  1.8710e-01,\n         -3.0447e-02,  5.1245e-02,  5.5034e-02, -5.5080e-02, -1.7118e-03,\n          9.5299e-02, -4.5908e-02, -1.2584e-02,  8.4189e-02,  2.0390e-01,\n         -2.0322e-01,  8.3806e-02,  5.3210e-02, -8.4752e-02, -4.7789e-02,\n         -1.1201e-01, -2.8879e-02, -3.3881e-02, -1.7330e-01,  6.1102e-01,\n         -1.2889e-02, -9.4040e-02,  8.2499e-02, -7.6344e-02, -8.5807e-02,\n          2.5688e-02, -1.5682e-02, -1.1451e-02,  6.4908e-03, -2.3518e-02,\n          3.4917e-02, -5.8727e-02,  1.3254e-02,  1.5825e-01,  4.7590e-02,\n          1.0409e-01,  6.9139e-02,  3.9837e-02, -3.2700e-02, -9.1413e-02,\n         -1.0145e-01,  1.4212e-03, -4.8999e-03,  7.6215e-02, -7.3899e-02,\n         -8.5377e-02,  2.2540e-02, -4.9561e-02,  3.2881e-02, -2.2287e-02,\n         -6.8049e-02, -2.0161e-02,  1.6643e-02,  2.7154e-04, -2.5598e-02,\n          4.4508e-01, -9.3383e-02,  3.1402e-02, -1.0722e-01, -7.8250e-02,\n          2.4561e-02,  1.1590e-02, -6.1978e-02, -8.2641e-03, -4.8054e-02,\n          2.7818e-02, -5.3643e-02,  6.1974e-01, -8.0894e-02,  1.1800e-02,\n         -3.8681e-02, -9.5972e-02,  8.1281e-02, -6.7938e-02,  5.6997e-02,\n          6.1085e-02,  9.6156e-02,  2.4264e-02,  1.5555e-02, -3.0102e+00,\n          1.2210e-01, -1.4733e-02,  8.8266e-02, -1.0616e-02,  9.5372e-02,\n          3.4785e-02, -4.5652e-02,  3.7928e-02,  7.2694e-02, -6.9918e+00,\n         -9.0425e-02,  5.7168e-02,  9.9027e-02,  4.6014e-02, -1.1359e-01,\n         -1.3036e-01,  1.4493e-01,  3.3658e-01, -5.2206e-02,  4.0246e-02,\n          2.0170e-02, -5.1978e-02,  4.4187e-02, -7.7361e-02,  1.9363e-02,\n          6.2263e-02, -6.1392e-02,  1.8873e-03, -3.3080e-02,  2.0337e-03,\n          3.4712e-02,  4.9128e-02,  2.6168e-03,  6.7538e-02, -3.0646e-01,\n         -1.0470e-01,  8.9288e-02,  1.2655e-01, -9.8930e-02, -2.5814e-02,\n         -1.1664e+00, -2.1569e-01,  3.9758e-03, -5.4394e-02,  4.2295e-03,\n         -1.4125e-02, -7.4978e-03, -6.1164e-02,  1.7089e-02, -6.3246e-02,\n         -3.2219e-02, -4.2474e-02, -3.9572e-02, -3.2148e-02, -7.0602e-02,\n          1.7266e-03,  3.1441e-02, -5.3143e-02, -4.6806e-02, -7.4992e-02,\n          1.7826e-02,  3.7886e-02, -5.9538e-02, -1.5893e-01, -6.2725e-02,\n         -2.4954e-02, -1.1496e-02, -5.6767e-02,  1.7637e-02, -5.2200e-02,\n         -3.3890e-02,  1.0832e-01, -3.6066e-02, -1.4835e-01,  7.2392e-03,\n          1.9350e-02, -2.5393e-01,  4.7064e-02, -1.2885e-01, -5.2606e-02,\n          3.4595e-02, -3.2223e-02,  2.3422e-02,  7.2860e-02, -2.5571e-01,\n         -6.5474e-02,  1.2896e-01,  8.3955e-02, -9.2654e-02,  7.1888e-02,\n          2.8062e-01,  4.2430e-02,  2.2217e-02,  4.0215e-02, -1.6136e-01,\n          9.2231e-01,  8.5289e-02,  4.6700e-04, -6.0995e-01,  4.4942e-02,\n          5.1844e-02,  1.8363e-02,  5.8039e-02, -6.6558e-02, -1.2741e-02,\n         -4.8374e-02, -7.0576e-03, -7.4275e-02, -2.5042e-01,  9.4788e-02,\n         -2.0065e-02,  5.5633e-03,  1.0549e-01,  6.3857e-01, -1.2988e-02,\n          6.1024e-02, -9.9692e-02,  8.6343e-02,  5.2502e-03, -8.4473e-02,\n          6.4332e-02, -3.9104e-02,  2.0621e-01,  5.0988e-01,  6.3144e-02,\n         -2.0267e-02, -4.0145e-02,  6.0277e-03, -5.9656e-02, -1.2237e-01,\n         -4.2363e-01,  3.2023e-02, -3.3462e-02, -5.3217e-03,  6.4035e-02,\n         -2.4842e-02,  7.4523e-02,  4.0784e-02,  5.0653e-02,  1.5206e-02,\n         -2.3787e-01,  4.2893e-04,  5.5599e-02,  1.7442e-01, -2.0597e+00,\n          2.2187e-01, -8.1338e-02, -3.3712e-02,  1.3336e-02,  3.6996e-02,\n          7.0870e-02,  1.7253e-02,  6.7578e-02,  1.5224e-02, -4.0918e-02,\n          4.6613e-02, -1.5509e-01, -3.2361e-01,  4.6951e-01, -9.7088e-02,\n         -2.0382e-02,  1.8947e-01, -7.4723e-01,  1.4031e-01, -9.4199e-02,\n         -5.9677e-02,  3.4392e-02,  4.5680e-02, -2.0871e-01, -6.9111e-02,\n         -1.0838e-01, -1.4020e-01, -9.6648e-02, -2.4828e-01, -2.9278e+00,\n          4.8934e-02,  7.4296e-02,  6.2194e-02,  1.5646e-02,  8.0212e-02,\n          8.4066e-02, -8.2836e-02, -1.4783e-01,  6.2116e-02,  6.1861e-03,\n         -8.3127e-02, -1.6525e-01, -4.2172e-02, -8.7703e-02, -1.0587e-01,\n          6.6060e-02, -1.2229e-01, -6.8211e-03,  1.3168e-01, -1.0773e-02,\n         -1.7031e-01,  2.6723e-02, -3.8696e-02,  7.6689e-02, -5.8725e-02,\n          1.9595e-01, -1.2188e-02,  5.9785e-02,  5.0739e-02,  2.5466e-02,\n         -2.7911e-01, -1.2255e-01,  2.8395e-02,  3.9120e-02,  1.3815e-01,\n         -9.5946e-02,  1.9945e-02,  6.0094e-02, -1.4042e-01, -5.9581e-02,\n         -1.0952e-01, -7.3303e-02, -3.3756e-01, -1.6650e-03,  8.1169e-04,\n          6.8362e-02,  1.6927e-01, -6.6210e-02,  1.1466e-02, -3.0490e-01,\n         -1.2575e-01,  8.7527e-03, -8.2844e-02,  3.2840e-03, -2.1481e-01,\n          4.4152e-02, -1.1502e+00, -2.0167e-01, -2.2349e-02,  1.5185e-01,\n          5.1614e-02,  1.1127e-01,  2.4280e-02, -2.7464e-01, -8.6785e-03,\n          1.2796e-02,  2.3091e-02, -1.4170e-01,  1.2471e-02, -6.3778e-02,\n         -1.0977e-01,  4.8350e-02,  7.4094e-02,  5.8915e-02,  7.7498e-02,\n          2.7250e-01,  1.8195e-01,  7.3699e-02, -1.1701e-01, -5.5508e-02,\n          2.0029e-02, -5.6784e-02, -3.5544e-02, -1.6007e-02,  4.2423e-02,\n          2.4862e-01, -1.2843e-01, -9.1527e-02, -9.2774e-02, -1.5552e-02,\n          2.1962e-02,  5.6796e-02,  3.9258e-01,  1.6204e-02,  2.8135e-02,\n          5.0101e-02, -1.0456e-01, -8.2916e-02,  2.7435e-02, -1.5170e-01,\n         -7.9315e-02,  3.0147e-02, -1.7284e-02, -1.2829e-01,  2.7650e-02,\n          5.3210e-02, -5.4339e-02,  1.0162e-01, -1.9675e-02, -9.0280e-02,\n         -4.6922e-02,  1.6096e-03,  1.9443e-02,  3.8715e-02, -4.2711e-02,\n         -7.7992e-02,  4.1426e-02,  8.2198e-03,  1.5082e-01,  3.3577e-03,\n         -2.2130e-02,  3.8794e-03, -1.0341e-01, -1.3226e-01,  9.8023e-04,\n          8.5674e-02, -6.0801e-02, -5.3319e-02, -1.8344e-01,  4.9798e-02,\n          2.9513e-02,  5.8624e-02, -1.1644e-02,  5.6686e-02, -2.3213e-02,\n          5.9430e-02,  3.0600e-02, -7.0081e-02, -9.4119e-02,  1.2767e-01,\n         -9.1701e-02,  5.3907e-02,  1.4844e-01,  5.5190e-02, -4.8491e-02,\n         -7.4864e-02, -4.8855e-03, -1.1108e-01,  2.9740e-02, -1.3206e-01,\n         -1.0341e-01, -5.5583e-02, -3.4414e-01, -9.1684e-03, -3.5313e-02,\n         -1.3231e-01,  4.7432e-02,  8.9266e-02, -1.2552e-01,  5.9633e-02,\n         -5.4128e-02, -9.0889e-03, -1.9906e-01, -4.2343e-03, -8.0673e-03,\n          1.4961e-03, -7.9238e-02,  6.1884e-02,  4.9478e-02, -7.5516e-02,\n          1.7998e-02,  8.1206e-02, -1.8421e-01, -6.5565e-02, -6.8392e-02,\n         -2.1154e-01, -7.4017e-01, -3.8952e-02,  1.1902e-01,  3.7814e-02,\n         -1.3577e-01, -1.5776e-01, -1.4138e-02,  4.6991e-02,  6.5095e-02,\n          3.4050e-04,  5.8638e-02]], device='cuda:0', grad_fn=<SliceBackward0>)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_dec_pytorch = model.decoder(input_ids=input_ids[:, :-1], encoder_hidden_states=out_enc.last_hidden_state)\n",
    "model.decoder(\n",
    "    input_ids=input_ids[:, -1:],\n",
    "    encoder_hidden_states=out_enc.last_hidden_state,\n",
    "    past_key_values=out_dec_pytorch.past_key_values,\n",
    ").last_hidden_state[:, -1, :]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# from itertools import chain\n",
    "# from transformers.onnx.features import FeaturesManager\n",
    "#\n",
    "# feature = \"seq2seq-lm-with-past\"\n",
    "# model = FeaturesManager.get_model_from_feature(feature, model_name)\n",
    "# model_kind, model_onnx_config = FeaturesManager.check_supported_model_or_raise(model, feature=feature)\n",
    "# onnx_config = model_onnx_config(model.config)\n",
    "#\n",
    "# with torch.no_grad():\n",
    "#     model.config.return_dict = True\n",
    "#     model.eval()\n",
    "#\n",
    "#     # Check if we need to override certain configuration item\n",
    "#     if onnx_config.values_override is not None:\n",
    "#         for override_config_key, override_config_value in onnx_config.values_override.items():\n",
    "#             setattr(model.config, override_config_key, override_config_value)\n",
    "#\n",
    "#     # Ensure inputs match\n",
    "#     model_inputs = onnx_config.generate_dummy_inputs(tokenizer, framework=TensorType.PYTORCH)\n",
    "#     for k, v in model_inputs.items():\n",
    "#         if isinstance(v, torch.Tensor):\n",
    "#             model_inputs[k] = model_inputs[k].type(torch.int32)\n",
    "#     onnx_outputs = list(onnx_config.outputs.keys())\n",
    "#\n",
    "#     onnx_config.patch_ops()\n",
    "#\n",
    "#     # export can works with named args but the dict containing named args as to be last element of the args tuple\n",
    "#     torch.onnx.export(\n",
    "#         model,\n",
    "#         (model_inputs,),\n",
    "#         f=\"test-dec-cache.onnx\",\n",
    "#         input_names=list(onnx_config.inputs.keys()),\n",
    "#         output_names=onnx_outputs,\n",
    "#         dynamic_axes={name: axes for name, axes in chain(onnx_config.inputs.items(), onnx_config.outputs.items())},\n",
    "#         do_constant_folding=True,\n",
    "#         use_external_data_format=onnx_config.use_external_data_format(model.num_parameters()),\n",
    "#         enable_onnx_checker=True,\n",
    "#         opset_version=13,\n",
    "#     )\n",
    "#\n",
    "#     onnx_config.restore_ops()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/geantvert/.local/share/virtualenvs/fast_transformer/lib/python3.9/site-packages/torch/onnx/utils.py:90: UserWarning: 'enable_onnx_checker' is deprecated and ignored. It will be removed in the next PyTorch release. To proceed despite ONNX checker failures, catch torch.onnx.ONNXCheckerError.\n",
      "  warnings.warn(\"'enable_onnx_checker' is deprecated and ignored. It will be removed in \"\n",
      "/home/geantvert/.local/share/virtualenvs/fast_transformer/lib/python3.9/site-packages/torch/onnx/utils.py:103: UserWarning: `use_external_data_format' is deprecated and ignored. Will be removed in next PyTorch release. The code will work as it is False if models are not larger than 2GB, Otherwise set to False because of size limits imposed by Protocol Buffers.\n",
      "  warnings.warn(\"`use_external_data_format' is deprecated and ignored. Will be removed in next \"\n",
      "/home/geantvert/.local/share/virtualenvs/fast_transformer/lib/python3.9/site-packages/transformers/modeling_utils.py:529: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if causal_mask.shape[1] < attention_mask.shape[1]:\n"
     ]
    }
   ],
   "source": [
    "model.cuda()\n",
    "out_dec_pytorch = model.decoder(input_ids=input_ids[:, :-1], encoder_hidden_states=out_enc.last_hidden_state)\n",
    "\n",
    "model.cuda()\n",
    "\n",
    "model_inputs = {\n",
    "    \"input_ids\": input_ids[:, -1:].type(torch.int32),\n",
    "    \"encoder_hidden_states\": out_enc.last_hidden_state,\n",
    "    \"past_key_values\": out_dec_pytorch.past_key_values,\n",
    "}\n",
    "\n",
    "input_names = [\n",
    "    \"input_ids\",\n",
    "    \"encoder_hidden_states\",\n",
    "    \"past_key_values.0.decoder.key\",\n",
    "    \"past_key_values.0.decoder.value\",\n",
    "    \"past_key_values.0.encoder.key\",\n",
    "    \"past_key_values.0.encoder.value\",\n",
    "    \"past_key_values.1.decoder.key\",\n",
    "    \"past_key_values.1.decoder.value\",\n",
    "    \"past_key_values.1.encoder.key\",\n",
    "    \"past_key_values.1.encoder.value\",\n",
    "    \"past_key_values.2.decoder.key\",\n",
    "    \"past_key_values.2.decoder.value\",\n",
    "    \"past_key_values.2.encoder.key\",\n",
    "    \"past_key_values.2.encoder.value\",\n",
    "    \"past_key_values.3.decoder.key\",\n",
    "    \"past_key_values.3.decoder.value\",\n",
    "    \"past_key_values.3.encoder.key\",\n",
    "    \"past_key_values.3.encoder.value\",\n",
    "    \"past_key_values.4.decoder.key\",\n",
    "    \"past_key_values.4.decoder.value\",\n",
    "    \"past_key_values.4.encoder.key\",\n",
    "    \"past_key_values.4.encoder.value\",\n",
    "    \"past_key_values.5.decoder.key\",\n",
    "    \"past_key_values.5.decoder.value\",\n",
    "    \"past_key_values.5.encoder.key\",\n",
    "    \"past_key_values.5.encoder.value\",\n",
    "]\n",
    "\n",
    "output_names = [\n",
    "    \"logits\",\n",
    "    \"present.0.decoder.key\",\n",
    "    \"present.0.decoder.value\",\n",
    "    \"present.0.encoder.key\",\n",
    "    \"present.0.encoder.value\",\n",
    "    \"present.1.decoder.key\",\n",
    "    \"present.1.decoder.value\",\n",
    "    \"present.1.encoder.key\",\n",
    "    \"present.1.encoder.value\",\n",
    "    \"present.2.decoder.key\",\n",
    "    \"present.2.decoder.value\",\n",
    "    \"present.2.encoder.key\",\n",
    "    \"present.2.encoder.value\",\n",
    "    \"present.3.decoder.key\",\n",
    "    \"present.3.decoder.value\",\n",
    "    \"present.3.encoder.key\",\n",
    "    \"present.3.encoder.value\",\n",
    "    \"present.4.decoder.key\",\n",
    "    \"present.4.decoder.value\",\n",
    "    \"present.4.encoder.key\",\n",
    "    \"present.4.encoder.value\",\n",
    "    \"present.5.decoder.key\",\n",
    "    \"present.5.decoder.value\",\n",
    "    \"present.5.encoder.key\",\n",
    "    \"present.5.encoder.value\",\n",
    "]\n",
    "\n",
    "dynamic_axis = {\n",
    "    \"input_ids\": {0: \"batch\", 1: \"encoder_sequence\"},\n",
    "    \"encoder_hidden_states\": {0: \"batch\", 1: \"encoder_sequence\"},\n",
    "    \"past_key_values.0.decoder.key\": {0: \"batch\", 2: \"past_decoder_sequence\"},\n",
    "    \"past_key_values.0.decoder.value\": {0: \"batch\", 2: \"past_decoder_sequence\"},\n",
    "    \"past_key_values.0.encoder.key\": {0: \"batch\", 2: \"past_encoder_sequence\"},\n",
    "    \"past_key_values.0.encoder.value\": {0: \"batch\", 2: \"past_encoder_sequence\"},\n",
    "    \"past_key_values.1.decoder.key\": {0: \"batch\", 2: \"past_decoder_sequence\"},\n",
    "    \"past_key_values.1.decoder.value\": {0: \"batch\", 2: \"past_decoder_sequence\"},\n",
    "    \"past_key_values.1.encoder.key\": {0: \"batch\", 2: \"past_encoder_sequence\"},\n",
    "    \"past_key_values.1.encoder.value\": {0: \"batch\", 2: \"past_encoder_sequence\"},\n",
    "    \"past_key_values.2.decoder.key\": {0: \"batch\", 2: \"past_decoder_sequence\"},\n",
    "    \"past_key_values.2.decoder.value\": {0: \"batch\", 2: \"past_decoder_sequence\"},\n",
    "    \"past_key_values.2.encoder.key\": {0: \"batch\", 2: \"past_encoder_sequence\"},\n",
    "    \"past_key_values.2.encoder.value\": {0: \"batch\", 2: \"past_encoder_sequence\"},\n",
    "    \"past_key_values.3.decoder.key\": {0: \"batch\", 2: \"past_decoder_sequence\"},\n",
    "    \"past_key_values.3.decoder.value\": {0: \"batch\", 2: \"past_decoder_sequence\"},\n",
    "    \"past_key_values.3.encoder.key\": {0: \"batch\", 2: \"past_encoder_sequence\"},\n",
    "    \"past_key_values.3.encoder.value\": {0: \"batch\", 2: \"past_encoder_sequence\"},\n",
    "    \"past_key_values.4.decoder.key\": {0: \"batch\", 2: \"past_decoder_sequence\"},\n",
    "    \"past_key_values.4.decoder.value\": {0: \"batch\", 2: \"past_decoder_sequence\"},\n",
    "    \"past_key_values.4.encoder.key\": {0: \"batch\", 2: \"past_encoder_sequence\"},\n",
    "    \"past_key_values.4.encoder.value\": {0: \"batch\", 2: \"past_encoder_sequence\"},\n",
    "    \"past_key_values.5.decoder.key\": {0: \"batch\", 2: \"past_decoder_sequence\"},\n",
    "    \"past_key_values.5.decoder.value\": {0: \"batch\", 2: \"past_decoder_sequence\"},\n",
    "    \"past_key_values.5.encoder.key\": {0: \"batch\", 2: \"past_encoder_sequence\"},\n",
    "    \"past_key_values.5.encoder.value\": {0: \"batch\", 2: \"past_encoder_sequence\"},\n",
    "    \"logits\": {0: \"batch\", 1: \"decoder_sequence\"},\n",
    "    \"present.0.decoder.key\": {0: \"batch\", 2: \"past_decoder_sequence + sequence\"},\n",
    "    \"present.0.decoder.value\": {0: \"batch\", 2: \"past_decoder_sequence + sequence\"},\n",
    "    \"present.0.encoder.key\": {0: \"batch\", 2: \"past_encoder_sequence\"},\n",
    "    \"present.0.encoder.value\": {0: \"batch\", 2: \"past_encoder_sequence\"},\n",
    "    \"present.1.decoder.key\": {0: \"batch\", 2: \"past_decoder_sequence + sequence\"},\n",
    "    \"present.1.decoder.value\": {0: \"batch\", 2: \"past_decoder_sequence + sequence\"},\n",
    "    \"present.1.encoder.key\": {0: \"batch\", 2: \"past_encoder_sequence\"},\n",
    "    \"present.1.encoder.value\": {0: \"batch\", 2: \"past_encoder_sequence\"},\n",
    "    \"present.2.decoder.key\": {0: \"batch\", 2: \"past_decoder_sequence + sequence\"},\n",
    "    \"present.2.decoder.value\": {0: \"batch\", 2: \"past_decoder_sequence + sequence\"},\n",
    "    \"present.2.encoder.key\": {0: \"batch\", 2: \"past_encoder_sequence\"},\n",
    "    \"present.2.encoder.value\": {0: \"batch\", 2: \"past_encoder_sequence\"},\n",
    "    \"present.3.decoder.key\": {0: \"batch\", 2: \"past_decoder_sequence + sequence\"},\n",
    "    \"present.3.decoder.value\": {0: \"batch\", 2: \"past_decoder_sequence + sequence\"},\n",
    "    \"present.3.encoder.key\": {0: \"batch\", 2: \"past_encoder_sequence\"},\n",
    "    \"present.3.encoder.value\": {0: \"batch\", 2: \"past_encoder_sequence\"},\n",
    "    \"present.4.decoder.key\": {0: \"batch\", 2: \"past_decoder_sequence + sequence\"},\n",
    "    \"present.4.decoder.value\": {0: \"batch\", 2: \"past_decoder_sequence + sequence\"},\n",
    "    \"present.4.encoder.key\": {0: \"batch\", 2: \"past_encoder_sequence\"},\n",
    "    \"present.4.encoder.value\": {0: \"batch\", 2: \"past_encoder_sequence\"},\n",
    "    \"present.5.decoder.key\": {0: \"batch\", 2: \"past_decoder_sequence + sequence\"},\n",
    "    \"present.5.decoder.value\": {0: \"batch\", 2: \"past_decoder_sequence + sequence\"},\n",
    "    \"present.5.encoder.key\": {0: \"batch\", 2: \"past_encoder_sequence\"},\n",
    "    \"present.5.encoder.value\": {0: \"batch\", 2: \"past_encoder_sequence\"},\n",
    "}\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.config.return_dict = True\n",
    "    model.eval()\n",
    "\n",
    "    # export can works with named args but the dict containing named args as to be last element of the args tuple\n",
    "    torch.onnx.export(\n",
    "        model.decoder,\n",
    "        (model_inputs,),\n",
    "        f=\"test-dec-cache.onnx\",\n",
    "        input_names=input_names,\n",
    "        output_names=output_names,\n",
    "        dynamic_axes=dynamic_axis,\n",
    "        do_constant_folding=True,\n",
    "        use_external_data_format=False,\n",
    "        enable_onnx_checker=True,\n",
    "        opset_version=13,\n",
    "    )\n",
    "\n",
    "model_inputs_no_cache = {\n",
    "    \"input_ids\": input_ids.type(torch.int32),\n",
    "    \"encoder_hidden_states\": out_enc.last_hidden_state,\n",
    "}\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.config.return_dict = True\n",
    "    model.eval()\n",
    "\n",
    "    # export can works with named args but the dict containing named args as to be last element of the args tuple\n",
    "    torch.onnx.export(\n",
    "        model.decoder,\n",
    "        (model_inputs_no_cache,),\n",
    "        f=\"test-dec-no-cache.onnx\",\n",
    "        input_names=list(model_inputs_no_cache.keys()),\n",
    "        output_names=output_names,\n",
    "        dynamic_axes={k: v for k, v in dynamic_axis.items() if \"past_key_values\" not in k},\n",
    "        do_constant_folding=True,\n",
    "        use_external_data_format=False,\n",
    "        enable_onnx_checker=True,\n",
    "        opset_version=13,\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[[ 2.75505669e-02,  1.50334492e-01, -1.06381610e-01,\n          1.34366244e-01, -2.70337425e-03,  1.01188630e-01,\n         -3.70661765e-02, -1.19580179e-01,  4.28272367e-01,\n         -6.88373074e-02,  4.79299482e-03,  1.03876561e-01,\n         -1.91168815e-01, -9.14082751e-02,  8.02245319e-01,\n         -2.90097948e-02, -8.30157474e-03, -4.18420471e-02,\n          5.12353703e-02, -8.15958455e-02,  5.27289249e-02,\n          7.59666264e-02, -8.56558830e-02,  2.22404099e+00,\n          4.77618948e-02, -7.09001422e-02, -3.64811942e-02,\n          2.84006387e-01, -3.37912999e-02, -1.31012782e-01,\n          4.64338362e-02, -4.02517952e-02, -5.61397932e-02,\n         -1.57095678e-02,  4.12030399e-01, -3.93750966e-02,\n         -1.11142471e-01, -7.79706985e-02, -1.34205982e-01,\n          1.95660204e-01, -4.99962792e-02, -5.93461283e-02,\n          2.24776655e-01,  7.36797228e-02, -5.78797944e-02,\n          1.48978885e-02, -6.95030272e-01,  1.72866043e-02,\n          1.06056750e-01,  9.23829898e-02, -1.33778632e-01,\n         -5.10500260e-02, -8.84042680e-02,  1.44867465e-01,\n         -1.12630934e-01,  4.18289891e-03,  5.39499335e-02,\n         -7.48298243e-02,  5.84630221e-02,  2.18830574e-02,\n          8.28510746e-02,  9.23681408e-02, -2.56623570e-02,\n         -8.60406235e-02, -1.29731502e-02, -4.35564369e-02,\n         -4.88872454e-02, -3.33911590e-02,  5.53378284e-01,\n          1.87132001e-01, -3.04206461e-02,  5.12396544e-02,\n          5.50649501e-02, -5.50896712e-02, -1.71369372e-03,\n          9.52994972e-02, -4.58988585e-02, -1.25644580e-02,\n          8.41903165e-02,  2.03844219e-01, -2.03252688e-01,\n          8.38244483e-02,  5.32395020e-02, -8.47254694e-02,\n         -4.77962643e-02, -1.11990482e-01, -2.88542770e-02,\n         -3.38673629e-02, -1.73326656e-01,  6.11119390e-01,\n         -1.28954677e-02, -9.40872580e-02,  8.24993700e-02,\n         -7.63467252e-02, -8.58427063e-02,  2.57149804e-02,\n         -1.56978313e-02, -1.14580095e-02,  6.49371743e-03,\n         -2.35139504e-02,  3.48964855e-02, -5.87521829e-02,\n          1.32941362e-02,  1.58199355e-01,  4.75927293e-02,\n          1.04084663e-01,  6.91408888e-02,  3.98425832e-02,\n         -3.27266790e-02, -9.14220586e-02, -1.01452753e-01,\n          1.41455501e-03, -4.89438977e-03,  7.62228817e-02,\n         -7.39351287e-02, -8.53853077e-02,  2.25576740e-02,\n         -4.95822467e-02,  3.28806974e-02, -2.22904570e-02,\n         -6.80288151e-02, -2.01618802e-02,  1.66544877e-02,\n          2.85096787e-04, -2.56005712e-02,  4.45045084e-01,\n         -9.33915749e-02,  3.14040445e-02, -1.07239619e-01,\n         -7.82322660e-02,  2.45811976e-02,  1.16077932e-02,\n         -6.19486682e-02, -8.27611983e-03, -4.80316579e-02,\n          2.78309658e-02, -5.36613613e-02,  6.19741976e-01,\n         -8.08980092e-02,  1.18099879e-02, -3.86862233e-02,\n         -9.59619284e-02,  8.12875405e-02, -6.79112226e-02,\n          5.69731109e-02,  6.10916950e-02,  9.61923599e-02,\n          2.42913458e-02,  1.55501496e-02, -3.01053286e+00,\n          1.22078702e-01, -1.47193167e-02,  8.82110596e-02,\n         -1.06468052e-02,  9.53794271e-02,  3.47557738e-02,\n         -4.56553586e-02,  3.79417352e-02,  7.26638436e-02,\n         -6.99234724e+00, -9.04354453e-02,  5.71738593e-02,\n          9.90397707e-02,  4.60141525e-02, -1.13601066e-01,\n         -1.30356655e-01,  1.44960523e-01,  3.36552262e-01,\n         -5.22373058e-02,  4.02644686e-02,  2.01296583e-02,\n         -5.19665964e-02,  4.42011543e-02, -7.73665011e-02,\n          1.93538573e-02,  6.22397102e-02, -6.13869578e-02,\n          1.87150878e-03, -3.30779366e-02,  2.03479663e-03,\n          3.47195528e-02,  4.91127633e-02,  2.61692214e-03,\n          6.75373375e-02, -3.06474328e-01, -1.04688741e-01,\n          8.92900229e-02,  1.26531973e-01, -9.89445001e-02,\n         -2.58013718e-02, -1.16666865e+00, -2.15690717e-01,\n          3.95623362e-03, -5.43998480e-02,  4.23719734e-03,\n         -1.41153419e-02, -7.50378892e-03, -6.11306913e-02,\n          1.71125904e-02, -6.32590801e-02, -3.22151892e-02,\n         -4.24649641e-02, -3.95676456e-02, -3.21831144e-02,\n         -7.06271678e-02,  1.74716464e-03,  3.14379409e-02,\n         -5.31577580e-02, -4.67845239e-02, -7.49840140e-02,\n          1.78107992e-02,  3.78590487e-02, -5.94927482e-02,\n         -1.58945650e-01, -6.27402291e-02, -2.49362085e-02,\n         -1.15291663e-02, -5.67526594e-02,  1.75984614e-02,\n         -5.21787554e-02, -3.39149311e-02,  1.08341299e-01,\n         -3.60668488e-02, -1.48353875e-01,  7.23027950e-03,\n          1.93199962e-02, -2.53880173e-01,  4.70523648e-02,\n         -1.28829360e-01, -5.26054986e-02,  3.45744193e-02,\n         -3.21897976e-02,  2.34192405e-02,  7.28721842e-02,\n         -2.55722225e-01, -6.54517785e-02,  1.28955051e-01,\n          8.39653164e-02, -9.26485583e-02,  7.19099715e-02,\n          2.80648798e-01,  4.24059890e-02,  2.21914910e-02,\n          4.01960760e-02, -1.61395356e-01,  9.22247469e-01,\n          8.53097290e-02,  4.65283287e-04, -6.10001683e-01,\n          4.49052304e-02,  5.18388674e-02,  1.83407068e-02,\n          5.79948574e-02, -6.65492788e-02, -1.27804214e-02,\n         -4.83701676e-02, -7.04476750e-03, -7.42707253e-02,\n         -2.50386387e-01,  9.48228315e-02, -2.00548153e-02,\n          5.56071615e-03,  1.05463199e-01,  6.38803720e-01,\n         -1.29957581e-02,  6.10180087e-02, -9.96741578e-02,\n          8.63569379e-02,  5.24923159e-03, -8.44566450e-02,\n          6.43482208e-02, -3.91174629e-02,  2.06197068e-01,\n          5.09726822e-01,  6.31341562e-02, -2.02851221e-02,\n         -4.01217975e-02,  6.02266658e-03, -5.96888103e-02,\n         -1.22351632e-01, -4.23622698e-01,  3.19916047e-02,\n         -3.34796868e-02, -5.37158363e-03,  6.40288219e-02,\n         -2.48400960e-02,  7.45139942e-02,  4.08036597e-02,\n          5.06433621e-02,  1.52358506e-02, -2.37904429e-01,\n          4.17122123e-04,  5.56000136e-02,  1.74413249e-01,\n         -2.05990338e+00,  2.21864626e-01, -8.13438967e-02,\n         -3.37398164e-02,  1.33406371e-02,  3.70413736e-02,\n          7.08871037e-02,  1.72459632e-02,  6.75759614e-02,\n          1.52408499e-02, -4.09680754e-02,  4.66254056e-02,\n         -1.55101314e-01, -3.23641777e-01,  4.69440758e-01,\n         -9.70338881e-02, -2.03978717e-02,  1.89484656e-01,\n         -7.47351706e-01,  1.40296593e-01, -9.42021087e-02,\n         -5.96793965e-02,  3.43805067e-02,  4.56733406e-02,\n         -2.08695829e-01, -6.91013783e-02, -1.08380772e-01,\n         -1.40194729e-01, -9.66359973e-02, -2.48352885e-01,\n         -2.92813444e+00,  4.89294715e-02,  7.43332431e-02,\n          6.22023121e-02,  1.56397410e-02,  8.02663937e-02,\n          8.40593129e-02, -8.28332379e-02, -1.47811621e-01,\n          6.21178336e-02,  6.15502847e-03, -8.31501782e-02,\n         -1.65246010e-01, -4.22016755e-02, -8.77268687e-02,\n         -1.05901077e-01,  6.60945773e-02, -1.22300431e-01,\n         -6.82237092e-03,  1.31674394e-01, -1.07653327e-02,\n         -1.70249686e-01,  2.67399382e-02, -3.87064703e-02,\n          7.67047405e-02, -5.87392971e-02,  1.95931524e-01,\n         -1.21931992e-02,  5.97998910e-02,  5.07163927e-02,\n          2.54814923e-02, -2.79090285e-01, -1.22527845e-01,\n          2.83779725e-02,  3.91266085e-02,  1.38179570e-01,\n         -9.59347710e-02,  1.99452955e-02,  6.01068325e-02,\n         -1.40435591e-01, -5.96017279e-02, -1.09512679e-01,\n         -7.32924491e-02, -3.37557703e-01, -1.68209092e-03,\n          8.22439149e-04,  6.83650523e-02,  1.69284344e-01,\n         -6.62202984e-02,  1.14394808e-02, -3.04875851e-01,\n         -1.25754178e-01,  8.74009356e-03, -8.28580037e-02,\n          3.29438620e-03, -2.14821771e-01,  4.41380069e-02,\n         -1.15028191e+00, -2.01638788e-01, -2.23545264e-02,\n          1.51876837e-01,  5.15977852e-02,  1.11289926e-01,\n          2.42833514e-02, -2.74671018e-01, -8.68278276e-03,\n          1.27823809e-02,  2.31077652e-02, -1.41696304e-01,\n          1.24628963e-02, -6.37648478e-02, -1.09762974e-01,\n          4.83270399e-02,  7.41117969e-02,  5.89701198e-02,\n          7.75312185e-02,  2.72527397e-01,  1.81993008e-01,\n          7.37223700e-02, -1.17000736e-01, -5.55063337e-02,\n          2.00451426e-02, -5.67837805e-02, -3.55605371e-02,\n         -1.60436109e-02,  4.24101725e-02,  2.48647630e-01,\n         -1.28441647e-01, -9.15363953e-02, -9.27907526e-02,\n         -1.55872768e-02,  2.19560638e-02,  5.68239242e-02,\n          3.92632544e-01,  1.62125397e-02,  2.81373095e-02,\n          5.01115210e-02, -1.04565479e-01, -8.28984380e-02,\n          2.74525490e-02, -1.51698872e-01, -7.93095529e-02,\n          3.01573034e-02, -1.72931645e-02, -1.28296211e-01,\n          2.76031364e-02,  5.31899221e-02, -5.43122441e-02,\n          1.01620972e-01, -1.97175443e-02, -9.02794152e-02,\n         -4.69088852e-02,  1.62584218e-03,  1.94558427e-02,\n          3.87347713e-02, -4.27117571e-02, -7.79618323e-02,\n          4.14239839e-02,  8.21991451e-03,  1.50817811e-01,\n          3.37398378e-03, -2.21454725e-02,  3.88479885e-03,\n         -1.03438422e-01, -1.32273361e-01,  9.76363837e-04,\n          8.56895894e-02, -6.08130097e-02, -5.33081926e-02,\n         -1.83460295e-01,  4.97843362e-02,  2.95072906e-02,\n          5.86353578e-02, -1.16664600e-02,  5.66617697e-02,\n         -2.32321136e-02,  5.94319068e-02,  3.06207426e-02,\n         -7.00690895e-02, -9.40842032e-02,  1.27658740e-01,\n         -9.17317346e-02,  5.38925119e-02,  1.48466170e-01,\n          5.51729016e-02, -4.85163704e-02, -7.48542622e-02,\n         -4.85150795e-03, -1.11119539e-01,  2.97123399e-02,\n         -1.32060274e-01, -1.03436068e-01, -5.55926971e-02,\n         -3.44107360e-01, -9.16953012e-03, -3.53453010e-02,\n         -1.32327318e-01,  4.74584512e-02,  8.92623141e-02,\n         -1.25505969e-01,  5.96084595e-02, -5.41221239e-02,\n         -9.07916389e-03, -1.99068204e-01, -4.22884803e-03,\n         -8.08746554e-03,  1.49609242e-03, -7.92344362e-02,\n          6.18762821e-02,  4.94816601e-02, -7.54972547e-02,\n          1.79912765e-02,  8.11960176e-02, -1.84198350e-01,\n         -6.55509308e-02, -6.83902353e-02, -2.11571261e-01,\n         -7.40170181e-01, -3.89348604e-02,  1.19020164e-01,\n          3.78060639e-02, -1.35776162e-01, -1.57760769e-01,\n         -1.41327279e-02,  4.69983630e-02,  6.51002228e-02,\n          3.40436964e-04,  5.86275533e-02]]], dtype=float32)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ort_cache = create_model_for_provider(\"test-dec-cache.onnx\", \"CPUExecutionProvider\")\n",
    "input_cache = dict()\n",
    "input_cache[\"input_ids\"] = input_ids[:, -1:].type(torch.int32).detach().cpu().numpy()\n",
    "input_cache[\"encoder_hidden_states\"] = out_enc.last_hidden_state.detach().cpu().numpy()\n",
    "\n",
    "for index, (k_dec, v_dec, k_enc, v_enc) in enumerate(\n",
    "    out_dec_pytorch.past_key_values\n",
    "):  # type: int, (torch.Tensor, torch.Tensor)\n",
    "    input_cache[f\"past_key_values.{index}.decoder.key\"] = k_dec.detach().cpu().numpy()\n",
    "    input_cache[f\"past_key_values.{index}.decoder.value\"] = v_dec.detach().cpu().numpy()\n",
    "    input_cache[f\"past_key_values.{index}.encoder.key\"] = k_enc.detach().cpu().numpy()\n",
    "    input_cache[f\"past_key_values.{index}.encoder.value\"] = v_enc.detach().cpu().numpy()\n",
    "\n",
    "ort_cache.run([\"logits\"], input_cache)[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 2.75525041e-02,  1.50345430e-01, -1.06359817e-01,\n         1.34393737e-01, -2.70290324e-03,  1.01154290e-01,\n        -3.70912142e-02, -1.19571716e-01,  4.28286850e-01,\n        -6.88271821e-02,  4.81172651e-03,  1.03936262e-01,\n        -1.91179633e-01, -9.13849697e-02,  8.02286863e-01,\n        -2.90302038e-02, -8.30391422e-03, -4.18590121e-02,\n         5.12391813e-02, -8.15425068e-02,  5.27317710e-02,\n         7.59881586e-02, -8.56724158e-02,  2.22394609e+00,\n         4.77523841e-02, -7.09051266e-02, -3.65113840e-02,\n         2.84028798e-01, -3.37744802e-02, -1.30950078e-01,\n         4.64039519e-02, -4.02239226e-02, -5.61129078e-02,\n        -1.57098453e-02,  4.12064970e-01, -3.93597558e-02,\n        -1.11132994e-01, -7.79703557e-02, -1.34175435e-01,\n         1.95654750e-01, -5.00231534e-02, -5.93454726e-02,\n         2.24799022e-01,  7.36801848e-02, -5.79193681e-02,\n         1.48795638e-02, -6.95044875e-01,  1.72866061e-02,\n         1.06105231e-01,  9.23658311e-02, -1.33768499e-01,\n        -5.10568246e-02, -8.83957371e-02,  1.44844219e-01,\n        -1.12630114e-01,  4.18661907e-03,  5.39775193e-02,\n        -7.48278052e-02,  5.84747568e-02,  2.18867511e-02,\n         8.28425810e-02,  9.23545882e-02, -2.56785937e-02,\n        -8.60254914e-02, -1.29525010e-02, -4.35157716e-02,\n        -4.88993376e-02, -3.34092528e-02,  5.53082347e-01,\n         1.87169388e-01, -3.04014795e-02,  5.12229949e-02,\n         5.50691038e-02, -5.50873466e-02, -1.72933238e-03,\n         9.53077525e-02, -4.58726846e-02, -1.25537235e-02,\n         8.42113420e-02,  2.03788280e-01, -2.03280687e-01,\n         8.37993249e-02,  5.32580875e-02, -8.47289339e-02,\n        -4.77864668e-02, -1.11988924e-01, -2.88690049e-02,\n        -3.38642932e-02, -1.73342213e-01,  6.11217976e-01,\n        -1.29012605e-02, -9.41118822e-02,  8.24913904e-02,\n        -7.63568431e-02, -8.58277380e-02,  2.57324800e-02,\n        -1.56959984e-02, -1.14598423e-02,  6.49910467e-03,\n        -2.35230327e-02,  3.48915756e-02, -5.87216504e-02,\n         1.33533189e-02,  1.58142626e-01,  4.75808643e-02,\n         1.04147807e-01,  6.91227466e-02,  3.98164913e-02,\n        -3.27269509e-02, -9.13629681e-02, -1.01436920e-01,\n         1.42889470e-03, -4.90535982e-03,  7.62022734e-02,\n        -7.38751590e-02, -8.54117572e-02,  2.25752629e-02,\n        -4.95756939e-02,  3.28544304e-02, -2.22699363e-02,\n        -6.80069625e-02, -2.01732498e-02,  1.66551787e-02,\n         2.59173772e-04, -2.55761910e-02,  4.45100278e-01,\n        -9.34365541e-02,  3.14043760e-02, -1.07233368e-01,\n        -7.82172531e-02,  2.45569982e-02,  1.16280867e-02,\n        -6.19270764e-02, -8.28332640e-03, -4.80131134e-02,\n         2.78226938e-02, -5.36644459e-02,  6.19750440e-01,\n        -8.08968842e-02,  1.18280966e-02, -3.86963747e-02,\n        -9.59465429e-02,  8.13066214e-02, -6.79267272e-02,\n         5.69621697e-02,  6.10899776e-02,  9.61917117e-02,\n         2.42510475e-02,  1.55092906e-02, -3.01110697e+00,\n         1.22056842e-01, -1.47027634e-02,  8.82051140e-02,\n        -1.06118992e-02,  9.53946039e-02,  3.47642154e-02,\n        -4.56325673e-02,  3.79715599e-02,  7.26596192e-02,\n        -6.99188471e+00, -9.04614851e-02,  5.71301505e-02,\n         9.90365520e-02,  4.60186303e-02, -1.13636918e-01,\n        -1.30338281e-01,  1.44975662e-01,  3.36529732e-01,\n        -5.22567779e-02,  4.02312540e-02,  2.01239213e-02,\n        -5.19746765e-02,  4.42241989e-02, -7.73272142e-02,\n         1.93521529e-02,  6.22163378e-02, -6.13621250e-02,\n         1.87131029e-03, -3.30939367e-02,  2.04798346e-03,\n         3.47154401e-02,  4.91230637e-02,  2.61746137e-03,\n         6.75557405e-02, -3.06488752e-01, -1.04656808e-01,\n         8.92771631e-02,  1.26514882e-01, -9.89424288e-02,\n        -2.57684179e-02, -1.16660237e+00, -2.15711549e-01,\n         3.97001440e-03, -5.44523858e-02,  4.25717607e-03,\n        -1.41272191e-02, -7.49634486e-03, -6.11203611e-02,\n         1.70966703e-02, -6.32467419e-02, -3.22224684e-02,\n        -4.24607955e-02, -3.95277962e-02, -3.21434997e-02,\n        -7.06335530e-02,  1.72693527e-03,  3.14393006e-02,\n        -5.32052480e-02, -4.67548668e-02, -7.49510378e-02,\n         1.78103931e-02,  3.78908217e-02, -5.94760664e-02,\n        -1.58984259e-01, -6.27454519e-02, -2.49496400e-02,\n        -1.15265390e-02, -5.67881428e-02,  1.76070984e-02,\n        -5.21553122e-02, -3.38884257e-02,  1.08337052e-01,\n        -3.60284410e-02, -1.48370042e-01,  7.15907896e-03,\n         1.93031561e-02, -2.53975689e-01,  4.70539294e-02,\n        -1.28824383e-01, -5.26149981e-02,  3.45751606e-02,\n        -3.21960561e-02,  2.34251488e-02,  7.28561059e-02,\n        -2.55744010e-01, -6.54700249e-02,  1.28948197e-01,\n         8.39815140e-02, -9.26492140e-02,  7.18727410e-02,\n         2.80633181e-01,  4.23750430e-02,  2.21873503e-02,\n         4.01722826e-02, -1.61504418e-01,  9.22046900e-01,\n         8.53141695e-02,  4.49544372e-04, -6.10010147e-01,\n         4.49120253e-02,  5.18243499e-02,  1.83479823e-02,\n         5.79843074e-02, -6.65683672e-02, -1.28064668e-02,\n        -4.83950414e-02, -7.03629851e-03, -7.42524266e-02,\n        -2.50380576e-01,  9.48009193e-02, -2.00412795e-02,\n         5.54421078e-03,  1.05456039e-01,  6.38608634e-01,\n        -1.29954843e-02,  6.09989502e-02, -9.96466652e-02,\n         8.63597170e-02,  5.23152575e-03, -8.44422951e-02,\n         6.43347874e-02, -3.91532741e-02,  2.06218302e-01,\n         5.09740293e-01,  6.31520972e-02, -2.03020647e-02,\n        -4.01619934e-02,  6.04266208e-03, -5.97354770e-02,\n        -1.22375347e-01, -4.23603415e-01,  3.19825336e-02,\n        -3.34861130e-02, -5.35078719e-03,  6.40221536e-02,\n        -2.48311143e-02,  7.45262429e-02,  4.08379324e-02,\n         5.06355874e-02,  1.52351735e-02, -2.37854466e-01,\n         4.39543190e-04,  5.55985123e-02,  1.74413413e-01,\n        -2.05982542e+00,  2.21821740e-01, -8.13178793e-02,\n        -3.37684005e-02,  1.33460239e-02,  3.70665006e-02,\n         7.08881393e-02,  1.72557104e-02,  6.75779879e-02,\n         1.52157657e-02, -4.09650467e-02,  4.66020256e-02,\n        -1.55103117e-01, -3.23652029e-01,  4.69569623e-01,\n        -9.70486030e-02, -2.03913245e-02,  1.89450458e-01,\n        -7.47280657e-01,  1.40272111e-01, -9.42023769e-02,\n        -5.96820749e-02,  3.43740582e-02,  4.56683636e-02,\n        -2.08744422e-01, -6.91238716e-02, -1.08349793e-01,\n        -1.40200973e-01, -9.66232494e-02, -2.48376578e-01,\n        -2.92721009e+00,  4.89430092e-02,  7.43775070e-02,\n         6.22112080e-02,  1.56180840e-02,  8.03338066e-02,\n         8.40607285e-02, -8.28368291e-02, -1.47814646e-01,\n         6.21397942e-02,  6.15361799e-03, -8.31211507e-02,\n        -1.65244311e-01, -4.21942696e-02, -8.77531692e-02,\n        -1.05860166e-01,  6.61215633e-02, -1.22333057e-01,\n        -6.82517048e-03,  1.31646693e-01, -1.07650384e-02,\n        -1.70283750e-01,  2.67359670e-02, -3.87119651e-02,\n         7.67163485e-02, -5.87053411e-02,  1.95946380e-01,\n        -1.22149829e-02,  5.98173477e-02,  5.07026538e-02,\n         2.54496112e-02, -2.79118568e-01, -1.22504175e-01,\n         2.83647124e-02,  3.91363092e-02,  1.38195246e-01,\n        -9.59132090e-02,  1.99570395e-02,  6.01116456e-02,\n        -1.40446246e-01, -5.95645308e-02, -1.09538361e-01,\n        -7.32897744e-02, -3.37579221e-01, -1.68155541e-03,\n         8.18315952e-04,  6.83498755e-02,  1.69281498e-01,\n        -6.62061349e-02,  1.14258621e-02, -3.04878116e-01,\n        -1.25726089e-01,  8.71983543e-03, -8.28194544e-02,\n         3.30230291e-03, -2.14790583e-01,  4.41369154e-02,\n        -1.15015519e+00, -2.01656818e-01, -2.23674588e-02,\n         1.51894733e-01,  5.15866987e-02,  1.11286372e-01,\n         2.42880322e-02, -2.74702311e-01, -8.65047611e-03,\n         1.27743725e-02,  2.31231786e-02, -1.41736731e-01,\n         1.24927005e-02, -6.37518093e-02, -1.09748103e-01,\n         4.83378619e-02,  7.40863606e-02,  5.89499995e-02,\n         7.75079280e-02,  2.72497833e-01,  1.81951940e-01,\n         7.37153888e-02, -1.17002748e-01, -5.55442981e-02,\n         2.00549215e-02, -5.68005890e-02, -3.55444588e-02,\n        -1.60423648e-02,  4.23858948e-02,  2.48622447e-01,\n        -1.28413245e-01, -9.15375203e-02, -9.28874984e-02,\n        -1.55922119e-02,  2.19876487e-02,  5.68101369e-02,\n         3.92662317e-01,  1.61797833e-02,  2.81329360e-02,\n         5.01169488e-02, -1.04561433e-01, -8.29206482e-02,\n         2.74510682e-02, -1.51698038e-01, -7.92872012e-02,\n         3.01568527e-02, -1.72825120e-02, -1.28269017e-01,\n         2.76091788e-02,  5.32054566e-02, -5.43326885e-02,\n         1.01616934e-01, -1.96971111e-02, -9.02982354e-02,\n        -4.68863323e-02,  1.63905718e-03,  1.94554925e-02,\n         3.87209766e-02, -4.27465327e-02, -7.79868215e-02,\n         4.14327607e-02,  8.16964172e-03,  1.50805548e-01,\n         3.37248319e-03, -2.21278742e-02,  3.89005942e-03,\n        -1.03453651e-01, -1.32261842e-01,  9.80545999e-04,\n         8.56832191e-02, -6.08117282e-02, -5.33125736e-02,\n        -1.83408022e-01,  4.98094149e-02,  2.95175686e-02,\n         5.86179905e-02, -1.16728060e-02,  5.66623099e-02,\n        -2.32411548e-02,  5.94095439e-02,  3.06247082e-02,\n        -7.00768456e-02, -9.40817595e-02,  1.27663523e-01,\n        -9.17257071e-02,  5.38772009e-02,  1.48484007e-01,\n         5.51188700e-02, -4.85066399e-02, -7.48320594e-02,\n        -4.88153100e-03, -1.11133873e-01,  2.97415275e-02,\n        -1.32046983e-01, -1.03381433e-01, -5.56330755e-02,\n        -3.44192892e-01, -9.21703130e-03, -3.53262722e-02,\n        -1.32371664e-01,  4.74666208e-02,  8.92487243e-02,\n        -1.25509217e-01,  5.95943443e-02, -5.40795252e-02,\n        -9.09980014e-03, -1.99067801e-01, -4.21207258e-03,\n        -8.10946524e-03,  1.49610103e-03, -7.92162046e-02,\n         6.19022846e-02,  4.94997054e-02, -7.55154788e-02,\n         1.79715101e-02,  8.11718851e-02, -1.84155330e-01,\n        -6.55449405e-02, -6.83469549e-02, -2.11579353e-01,\n        -7.40108907e-01, -3.89463715e-02,  1.19014129e-01,\n         3.78471278e-02, -1.35801733e-01, -1.57718897e-01,\n        -1.41044613e-02,  4.69428450e-02,  6.50854930e-02,\n         3.40498518e-04,  5.86219318e-02]], dtype=float32)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ort_no_cache = create_model_for_provider(\"test-dec-no-cache.onnx\", \"CPUExecutionProvider\")\n",
    "input_no_cache = dict()\n",
    "input_no_cache[\"input_ids\"] = input_ids.type(torch.int32).detach().cpu().numpy()\n",
    "input_no_cache[\"encoder_hidden_states\"] = out_enc.last_hidden_state.detach().cpu().numpy()\n",
    "\n",
    "ort_no_cache.run([\"logits\"], input_no_cache)[0][:,-1,:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# ort_cache = create_model_for_provider(\"test-dec-cache.onnx\", \"CUDAExecutionProvider\")\n",
    "# input_cache = dict()\n",
    "# input_cache[\"input_ids\"] = input_ids[:, -1:]\n",
    "# input_cache[\"encoder_hidden_states\"] = out_enc.last_hidden_state.detach()\n",
    "#\n",
    "# for index, (k_dec, v_dec, k_enc, v_enc) in enumerate(\n",
    "#     out_dec_pytorch.past_key_values\n",
    "# ):  # type: int, (torch.Tensor, torch.Tensor, torch.Tensor)\n",
    "#     input_cache[f\"past_key_values.{index}.decoder.key\"] = k_dec.cuda()\n",
    "#     input_cache[f\"past_key_values.{index}.decoder.value\"] = v_dec.cuda()\n",
    "#     input_cache[f\"past_key_values.{index}.encoder.key\"] = k_enc.cuda()\n",
    "#     input_cache[f\"past_key_values.{index}.encoder.value\"] = v_enc.cuda()\n",
    "#\n",
    "#\n",
    "# print(inference_onnx_binding(model_onnx=ort_cache, inputs=input_cache, device=\"cuda\", output_shape={\"logits\": (1, 1, 512)})[\n",
    "#     \"logits\"\n",
    "# ])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# ort_cache = create_model_for_provider(\"test-dec-no-cache.onnx\", \"CUDAExecutionProvider\")\n",
    "# input_cache = dict()\n",
    "# input_cache[\"input_ids\"] = input_ids\n",
    "# input_cache[\"encoder_hidden_states\"] = out_enc.last_hidden_state.detach()\n",
    "#\n",
    "# print(inference_onnx_binding(model_onnx=ort_cache, inputs=input_cache, device=\"cuda\", output_shape={\"logits\": (1, 4, 512)})[\n",
    "#     \"logits\"\n",
    "# ][:,-1,:])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import onnx\n",
    "from onnx import GraphProto, ModelProto, NodeProto, TensorProto, ValueInfoProto, helper\n",
    "\n",
    "onnx_model_cache = onnx.load(\"test-dec-cache.onnx\")\n",
    "onnx_model_no_cache = onnx.load(\"test-dec-no-cache.onnx\")\n",
    "\n",
    "\n",
    "prefix = \"cache_node_\"\n",
    "mapping_initializer_cache_to_no_cache = dict()\n",
    "to_add = list()\n",
    "for node_cache in onnx_model_cache.graph.initializer:\n",
    "    found = False\n",
    "    for node_no_cache in onnx_model_no_cache.graph.initializer:\n",
    "        if node_cache.raw_data == node_no_cache.raw_data:\n",
    "            found = True\n",
    "            mapping_initializer_cache_to_no_cache[node_cache.name] = node_no_cache.name\n",
    "            break\n",
    "    if not found:\n",
    "        node_cache.name = prefix + node_cache.name\n",
    "        to_add.append(node_cache)\n",
    "        mapping_initializer_cache_to_no_cache[node_cache.name] = node_cache.name\n",
    "        print(f\"name: {node_cache.name} - size: {len(node_cache.raw_data)/1024:.2f}\")\n",
    "\n",
    "onnx_model_no_cache.graph.initializer.extend(to_add)\n",
    "# I/O model names should not be prefixed\n",
    "model_io_names = [n.name for n in list(onnx_model_cache.graph.input) + list(onnx_model_cache.graph.output)]\n",
    "\n",
    "for node in onnx_model_cache.graph.node:\n",
    "    for index, input_name in enumerate(node.input):\n",
    "        if input_name in model_io_names:\n",
    "            continue\n",
    "        node.input[index] = mapping_initializer_cache_to_no_cache.get(input_name, prefix + input_name)\n",
    "    for index, output_name in enumerate(node.output):\n",
    "        if output_name in model_io_names:\n",
    "            continue\n",
    "        node.output[index] = prefix + output_name\n",
    "    node.name = prefix + node.name\n",
    "model_io_names = [n.name for n in list(onnx_model_cache.graph.input) + list(onnx_model_cache.graph.output)]\n",
    "\n",
    "prefix = \"init_\"\n",
    "cache = dict()\n",
    "for node in onnx_model_no_cache.graph.initializer:\n",
    "    if node.name in model_io_names:\n",
    "        new_name = prefix + node.name\n",
    "        cache[node.name] = new_name\n",
    "        node.name = new_name\n",
    "\n",
    "for node in onnx_model_no_cache.graph.node:\n",
    "    for index, n in enumerate(node.input):\n",
    "        node.input[index] = cache.get(n, n)\n",
    "\n",
    "# mandatory for subgraph in if/else node\n",
    "assert len(onnx_model_cache.graph.output) == len(onnx_model_no_cache.graph.output)\n",
    "\n",
    "graph_cache: onnx.GraphProto = onnx.helper.make_graph(\n",
    "    nodes=list(onnx_model_cache.graph.node),\n",
    "    name=\"graph-cache\",\n",
    "    inputs=[],\n",
    "    outputs=list(onnx_model_cache.graph.output),\n",
    "    initializer=[],\n",
    ")\n",
    "\n",
    "graph_no_cache: onnx.GraphProto = onnx.helper.make_graph(\n",
    "    nodes=list(onnx_model_no_cache.graph.node),\n",
    "    name=\"graph-no-cache\",\n",
    "    inputs=[],\n",
    "    outputs=list(onnx_model_no_cache.graph.output),\n",
    "    initializer=[],\n",
    ")\n",
    "\n",
    "enable_cache = onnx.helper.make_tensor_value_info(name=\"enable_cache\", elem_type=onnx.TensorProto.BOOL, shape=[1])\n",
    "\n",
    "if_node = onnx.helper.make_node(\n",
    "    op_type=\"If\",\n",
    "    inputs=[\"enable_cache\"],\n",
    "    outputs=[o.name for o in list(onnx_model_no_cache.graph.output)],\n",
    "    then_branch=graph_cache,\n",
    "    else_branch=graph_no_cache,\n",
    ")\n",
    "\n",
    "if_graph_def: GraphProto = helper.make_graph(\n",
    "    nodes=[if_node],\n",
    "    name=\"if-model\",\n",
    "    inputs=list(onnx_model_cache.graph.input) + [enable_cache],\n",
    "    outputs=list(onnx_model_no_cache.graph.output),\n",
    "    initializer=list(onnx_model_no_cache.graph.initializer) ,\n",
    ")\n",
    "\n",
    "model_def: ModelProto = helper.make_model(if_graph_def, producer_name=\"onnx-example\")\n",
    "\n",
    "onnx.checker.check_model(model_def)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# out_enc: BaseModelOutputWithPastAndCrossAttentions = model.encoder(input_ids=input_ids)\n",
    "# out_dec_pytorch = model.decoder(input_ids=input_ids[:, :-1], encoder_hidden_states=out_enc.last_hidden_state)\n",
    "#\n",
    "# ort_cache = create_model_for_provider(model_def.SerializeToString(), \"CPUExecutionProvider\")\n",
    "# input_cache = dict()\n",
    "# input_cache[\"input_ids\"] = input_ids.type(torch.int32).detach().cpu().numpy()\n",
    "# input_cache[\"encoder_hidden_states\"] = out_enc.last_hidden_state.detach().cpu().numpy()\n",
    "# input_cache[\"enable_cache\"] = np.array([False])\n",
    "#\n",
    "# for index, (k_dec, v_dec, k_enc, v_enc) in enumerate(\n",
    "#     out_dec_pytorch.past_key_values\n",
    "# ):  # type: int, (torch.Tensor, torch.Tensor)\n",
    "#     input_cache[f\"past_key_values.{index}.decoder.key\"] = k_dec.detach().cpu().numpy()\n",
    "#     input_cache[f\"past_key_values.{index}.decoder.value\"] = v_dec.detach().cpu().numpy()\n",
    "#     input_cache[f\"past_key_values.{index}.encoder.key\"] = k_enc.detach().cpu().numpy()\n",
    "#     input_cache[f\"past_key_values.{index}.encoder.value\"] = v_enc.detach().cpu().numpy()\n",
    "#\n",
    "# print(ort_cache.run([\"logits\"], input_cache)[0][:,-1,:][:, :10])\n",
    "# print(ort_cache.run([\"logits\"], input_cache)[0].shape)\n",
    "#\n",
    "#\n",
    "# input_cache[\"enable_cache\"] = np.array([True])\n",
    "# input_cache[\"input_ids\"] = input_cache[\"input_ids\"][:, -1:]\n",
    "# print(ort_cache.run([\"logits\"], input_cache)[0][:,-1,:][:, :10])\n",
    "# print(ort_cache.run([\"logits\"], input_cache)[0].shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "input_ids_benchmark = torch.ones((4, 1000), dtype=torch.int32, device=\"cuda\")\n",
    "out_enc: BaseModelOutputWithPastAndCrossAttentions = model.encoder(input_ids=input_ids_benchmark)  #\n",
    "out_dec_pytorch = model.decoder(input_ids=input_ids_benchmark[:, :-1], encoder_hidden_states=out_enc.last_hidden_state)\n",
    "\n",
    "ort_cache = create_model_for_provider(model_def.SerializeToString(), \"CUDAExecutionProvider\")\n",
    "input_cache = dict()\n",
    "input_cache[\"input_ids\"] = input_ids_benchmark.type(torch.int32)\n",
    "input_cache[\"encoder_hidden_states\"] = out_enc.last_hidden_state\n",
    "input_cache[\"enable_cache\"] = torch.tensor([False], device=\"cuda\", dtype=torch.bool)\n",
    "\n",
    "for index, (k_dec, v_dec, k_enc, v_enc) in enumerate(\n",
    "    out_dec_pytorch.past_key_values\n",
    "):  # type: int, (torch.Tensor, torch.Tensor)\n",
    "    input_cache[f\"past_key_values.{index}.decoder.key\"] = k_dec\n",
    "    input_cache[f\"past_key_values.{index}.decoder.value\"] = v_dec\n",
    "    input_cache[f\"past_key_values.{index}.encoder.key\"] = k_enc\n",
    "    input_cache[f\"past_key_values.{index}.encoder.value\"] = v_enc\n",
    "\n",
    "\n",
    "start = time()\n",
    "for _ in range(10):\n",
    "    result_dict = inference_onnx_binding(\n",
    "    model_onnx=ort_cache,\n",
    "    inputs=input_cache,\n",
    "    device=input_ids.device.type,\n",
    "    output_shape={\"logits\" : tuple(input_cache[\"input_ids\"].shape) + (int(model.config.d_model),)},\n",
    "    )\n",
    "print(time()-start)\n",
    "print(result_dict[\"logits\"][:,-1:,:][0, :, :10])\n",
    "\n",
    "input_cache[\"enable_cache\"] = torch.tensor([True], device=\"cuda\", dtype=torch.bool)\n",
    "input_cache[\"input_ids\"] = input_cache[\"input_ids\"][:, -1:].type(torch.int32)\n",
    "start = time()\n",
    "for _ in range(10):\n",
    "    result_dict = inference_onnx_binding(\n",
    "    model_onnx=ort_cache,\n",
    "    inputs=input_cache,\n",
    "    device=input_ids.device.type,\n",
    "    output_shape={\"logits\" : tuple(input_cache[\"input_ids\"].shape) + (int(model.config.d_model),)},\n",
    "    )\n",
    "print(time()-start)\n",
    "print(result_dict[\"logits\"][:,-1:,:][0, :, :10])\n",
    "\n",
    "del input_ids_benchmark\n",
    "del ort_cache\n",
    "del input_cache\n",
    "del out_enc\n",
    "del out_dec_pytorch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "del input_ids_benchmark\n",
    "del out_enc\n",
    "del out_dec_pytorch\n",
    "del input_cache\n",
    "del ort_cache"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# tout_enc: BaseModelOutputWithPastAndCrossAttentions = model.encoder(input_ids=torch.range(1, 1000, dtype=torch.int32, device=\"cuda\").unsqueeze(0))\n",
    "# out_dec_pytorch = model.decoder(input_ids=torch.range(1, 1000, dtype=torch.int32, device=\"cuda\").unsqueeze(0), encoder_hidden_states=out_enc.last_hidden_state)\n",
    "#\n",
    "# ort_cache = create_model_for_provider(model_def.SerializeToString(), \"CUDAExecutionProvider\")\n",
    "# input_cache = dict()\n",
    "# input_cache[\"input_ids\"] = input_ids.type(torch.int32)\n",
    "# input_cache[\"encoder_hidden_states\"] = out_enc.last_hidden_state\n",
    "# input_cache[\"enable_cache\"] = torch.tensor([False], device=\"cuda\", dtype=torch.bool)\n",
    "#\n",
    "# for index, (k_dec, v_dec, k_enc, v_enc) in enumerate(\n",
    "#     out_dec_pytorch.past_key_values\n",
    "# ):  # type: int, (torch.Tensor, torch.Tensor)\n",
    "#     input_cache[f\"past_key_values.{index}.decoder.key\"] = torch.zeros((1,8,1,64), dtype=torch.float32, device=\"cuda\") # k_dec.detach().cpu().numpy()\n",
    "#     input_cache[f\"past_key_values.{index}.decoder.value\"] = torch.zeros((1,8,1,64), dtype=torch.float32, device=\"cuda\") # v_dec.detach().cpu().numpy()\n",
    "#     input_cache[f\"past_key_values.{index}.encoder.key\"] = torch.zeros((1,8,1,64), dtype=torch.float32, device=\"cuda\") # k_enc.detach().cpu().numpy()\n",
    "#     input_cache[f\"past_key_values.{index}.encoder.value\"] = torch.zeros((1,8,1,64), dtype=torch.float32, device=\"cuda\") # v_enc.detach().cpu().numpy()\n",
    "#\n",
    "#\n",
    "# start = time()\n",
    "# for _ in range(10):\n",
    "#     result_dict = inference_onnx_binding(\n",
    "#     model_onnx=ort_cache,\n",
    "#     inputs=input_cache,\n",
    "#     device=input_ids.device.type,\n",
    "#     output_shape={\"logits\" : tuple(input_ids.shape) + (int(model.config.vocab_size),)},\n",
    "#     )\n",
    "# print(time()-start)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# out_enc: BaseModelOutputWithPastAndCrossAttentions = model.encoder(input_ids=torch.range(1, 1000, dtype=torch.int32, device=\"cuda\").unsqueeze(0))\n",
    "# out_dec_pytorch = model.decoder(input_ids=torch.range(1, 1000, dtype=torch.int32, device=\"cuda\").unsqueeze(0), encoder_hidden_states=out_enc.last_hidden_state)\n",
    "#\n",
    "# ort_cache = create_model_for_provider(model_def.SerializeToString(), \"CUDAExecutionProvider\")\n",
    "# input_cache = dict()\n",
    "# input_cache[\"input_ids\"] = input_ids[:, :-1].type(torch.int32).detach().cpu().numpy()\n",
    "# input_cache[\"encoder_hidden_states\"] = out_enc.last_hidden_state.detach().cpu().numpy()\n",
    "# input_cache[\"enable_cache\"] = torch.tensor([False], device=\"cuda\", dtype=torch.bool)\n",
    "#\n",
    "# for index, (k_dec, v_dec, k_enc, v_enc) in enumerate(\n",
    "#     out_dec_pytorch.past_key_values\n",
    "# ):  # type: int, (torch.Tensor, torch.Tensor)\n",
    "#     input_cache[f\"past_key_values.{index}.decoder.key\"] = k_dec.detach().cpu().numpy()\n",
    "#     input_cache[f\"past_key_values.{index}.decoder.value\"] = v_dec.detach().cpu().numpy()\n",
    "#     input_cache[f\"past_key_values.{index}.encoder.key\"] = k_enc.detach().cpu().numpy()\n",
    "#     input_cache[f\"past_key_values.{index}.encoder.value\"] = v_enc.detach().cpu().numpy()\n",
    "#\n",
    "#\n",
    "# start = time()\n",
    "# for _ in range(10):\n",
    "#     ort_cache.run([\"logits\"], input_cache)\n",
    "# print(time()-start)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}