{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method to perform Nvidia GPU INT-8 quantization on most transformers model (encoder based)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantization is one of the most effective and generic approach to make model inference faster.\n",
    "Basically, it replaces high precision float numbers in model tensors encoded in 32 or 16 bits by lower precision ones encoded in 8 bits or less:\n",
    "\n",
    "* it takes less memory\n",
    "* computation is easier / faster\n",
    "\n",
    "It can be applied to any model in theory, and, if done well, it should not decrease its accuracy.\n",
    "\n",
    "The purpose of this notebook is to show 2 processes to perform quantization on most `transformer` architectures.\n",
    "\n",
    "**TL;DR, we benchmarked Pytorch and Nvidia TensorRT, on both CPU and GPU, with/without quantization, our methods provide the fastest inference by large margin**.\n",
    "\n",
    "| Framework                  | Precision | Latency (ms) | Accuracy | Speedup    | Hardware |\n",
    "|:---------------------------|-----------|--------------|----------|:-----------|:--------:|\n",
    "| Pytorch                    | FP32      | 4000         | 86.8 %   | X 0.02     |   CPU    |\n",
    "| Pytorch                    | FP16      | 4005         | 86.8 %   | X 0.02     |   CPU    |\n",
    "| Pytorch                    | **INT-8** | 3670         | 86.8 %   | X 0.02     | **CPU**  |\n",
    "| Pytorch                    | FP32      | 80           | 86.8 %   | X 1        |   GPU    |\n",
    "| Pytorch                    | FP16      | 58           | 86.8 %   | X 1.38     |   GPU    |\n",
    "| ONNX Runtime               | FP32      | 74           | 86.8 %   | X 1.08     |   GPU    |\n",
    "| ONNX Runtime               | FP16      | 34           | 86.8 %   | X 2.35     |   GPU    |\n",
    "| ONNX Runtime               | FP32      | 3767         | 86.8 %   | X 0.02     |   CPU    |\n",
    "| ONNX Runtime               | FP16      | 4607         | 86.8 %   | X 0.02     |   CPU    |\n",
    "| ONNX Runtime               | **INT-8** | 3712         | 86.8 %   | X 0.02     | **CPU**  |\n",
    "| TensorRT                   | FP16      | 30           | 86.8 %   | X 2.67     |   GPU    |\n",
    "| TensorRT (**our method 1**)| **INT-8** | 15           | 84.4 %   | **X 5.33** | **GPU**  |\n",
    "| TensorRT (**our method 2**)| **INT-8** | 16           | 85.8 %   | **X 5.00** | **GPU**  |\n",
    "\n",
    "> measures done on a Nvidia RTX 3090 GPU + 12 cores i7 Intel CPU (support AVX-2 instructions)\n",
    ">\n",
    "> architecture `Roberta-base` with batch of size 32 / seq len 256, similar results obtained for other sizes/seq len not included in the table.\n",
    ">\n",
    "> accuracy obtained after a single epoch, no LR search or any hyper parameter optimization\n",
    ">\n",
    "> CPU measures are a bit unfair, it's still possible to push performance a bit by adding lots of (Python related) complexities and using last generation CPU, still those measurements are indicative of orders of magnitude to expect from Pytorch+CPU deployment.\n",
    ">\n",
    "> same kind of acceleration is observed on all seq len / batch sizes\n",
    "\n",
    "\n",
    "## A (very) short intro to INT-8 quantization\n",
    "\n",
    "Basic idea behind model quantization is to replace tensors made of float numbers (usually encoded on 32 bits) by lower precision representation (integers encoded on 8 bits for Nvidia GPUs).\n",
    "Therefore computation is faster and model memory footprint is lower. Making tensor storage smaller makes memory transfer faster... and is also a source of computation acceleration.\n",
    "This technic is very interesting for its trade-off: you reduce inference time significantly, and when dataset is large enough, it costs close to nothing in accuracy.\n",
    "\n",
    "Replacing float numbers by integers is done through a mapping.\n",
    "This step is called `calibration`, and its purpose is to compute for each tensor or each channel of a tensor (one of its dimensions) a range of all possible values and then define a scale and a distribution center to map float numbers to 8 bits integers.\n",
    "The process is well described in this [Nvidia presentation](https://on-demand.gputechconf.com/gtc/2017/presentation/s7310-8-bit-inference-with-tensorrt.pdf).\n",
    "\n",
    "There are several ways to perform quantization, depending of how and when the `calibration` is performed:\n",
    "\n",
    "* dynamically: the mapping is done during the inference, there are some overhead but it's easy to put in place and usually the accuracy is preserved,\n",
    "* statically, after training (`post training quantization` or `PTQ`): this way is efficient, but it may have a significant accuracy cost,\n",
    "* statically, before training (`quantization aware training` or `QAT`): this way is efficient and has a low accuracy cost as the weights will take care of the result\n",
    "\n",
    "In this guide we will focus on the third option: `QAT`.\n",
    "\n",
    "During the quantization aware *training*:\n",
    "\n",
    "* in the inside, Pytorch will train with high precision float numbers,\n",
    "* on the outside, Pytorch will simulate that a quantization has already been applied and output results accordingly (for loss computation for instance)\n",
    "\n",
    "The simulation process is done through the add of quantization / dequantization nodes, most often called `QDQ`, it's an abbreviation you will see often in quantization world.\n",
    "\n",
    "You can check this [high quality blog post](https://leimao.github.io/article/Neural-Networks-Quantization/) for more information.\n",
    "\n",
    "## Why this notebook?\n",
    "\n",
    "CPU quantization is supported out of the box by `Pytorch` and `ONNX Runtime`.\n",
    "**GPU quantization on the other side requires specific tools and process to be applied**.\n",
    "\n",
    "In the specific case of `transformer` models, until recently (december 2021), the only way shown by Nvidia is to build manually the graph of our models in `TensorRT`. This is a low level approach, based on GPU capacity knowledge (which operators are supported, etc.). It's certainly out of reach of most NLP practitioners and is very time consuming to update/adapt to new architectures.\n",
    "\n",
    "Hopefully, Nvidia added to Hugging Face `transformer` library a new model called `QDQBert` few weeks ago.\n",
    "Basically, it's a vanilla `Bert` architecture which supports INT-8 quantization.\n",
    "It doesn't support any other architecture out of the box, like `Albert`, `Roberta`, or `Electra`.\n",
    "Nvidia also provide a demo dedicated to the SQuaD task.\n",
    "\n",
    "This open the door to extension of the approach to other architectures.\n",
    "\n",
    "To be both simple and cover most use cases, in this notebook we will see:\n",
    "\n",
    "* how to perform GPU quantization on **any** transformer model (not just Bert) using a simple trick, a `transplatation`\n",
    "* how to perform GPU quantization on `QDQRoberta`, a custom model similar to `QDQBert` and supported by `transformer-deploy` library\n",
    "* how to apply quantization to a common task like classification (which is easier to understand than question answering)\n",
    "* measure performance gain (latency)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project setup\n",
    "\n",
    "### Dependencies installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We install `master` branch of `transfomers` library to use a new model: **QDQBert** and `transformer-deploy` to leverage `TensorRT` models (TensorRT API is not something simple to master, it's highly advised to use a wrapper). Your machine should have Nvidia CUDA 11.X, TensorRT 8.2.1 and cuBLAS installed. It's said to be tricky to install, in my experience, just follow Nvidia instructions **and nothing else**, it should work out of the box. Docker image with TensorRT 8.2.1 has not yet been released, this notebook will be updated when it's ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "MOsHUjgdIrIW"
   },
   "outputs": [],
   "source": [
    "#! pip install git+https://github.com/huggingface/transformers\n",
    "#! pip install git+https://github.com/ELS-RD/transformer-deploy\n",
    "#! pip install sklearn datasets\n",
    "#! pip install pytorch-quantization --extra-index-url https://pypi.ngc.nvidia.com\n",
    "# or install pytorch-quantization from https://github.com/NVIDIA/TensorRT/tree/master/tools/pytorch-quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the GPU is enabled and usable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2OzrD4f-3ydk",
    "outputId": "54cc2ea6-6969-4e01-f9f9-78c5fc91ff85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Dec  9 19:47:47 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 495.29.05    Driver Version: 495.29.05    CUDA Version: 11.5     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:03:00.0  On |                  N/A |\r\n",
      "| 67%   55C    P8    45W / 350W |    286MiB / 24267MiB |      6%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A      1944      G   /usr/lib/xorg/Xorg                148MiB |\r\n",
      "|    0   N/A  N/A      7816      G   /usr/bin/gnome-shell               40MiB |\r\n",
      "|    0   N/A  N/A    529613      G   ...518105.log --shared-files       13MiB |\r\n",
      "|    0   N/A  N/A    540908      G   ...AAAAAAAAA= --shared-files       49MiB |\r\n",
      "|    0   N/A  N/A   1378576      G   ...AAAAAAAAA= --shared-files       31MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "ac14ba24dcf3404db9fd303dbb24d7a5",
      "4e91efae49b64f038fd3fbfcfd2be510",
      "17b83e0d0fb947d7bf20319ff930e8fc",
      "1da1d80871f545bbb21bf5a84d2120a0",
      "c593f2e45e244637821cc5721788bf2c",
      "cbbb20b5d01a4450bfb8dfbf8048d64f",
      "854cfd13416543fba8221093b903658b",
      "7ec6da801d0d45c4bb80eeab5518e124",
      "8585eab4b3fe4992bd7e7c4596e2483b",
      "990482eebca2424bb5ecbd114007e02c",
      "c92a19dfa84142af91522bc22f21fca6",
      "78601982b0e04b80adaa502db2ef685a",
      "167874df55014291be95cd390b1e60d3",
      "d6426fea2eda41dd9a31cb3f35b0877e",
      "163146c2f23440bcbf782116a35b5684",
      "0dab554959dc44b3b313ee8ae91ca88d",
      "f651eecbb6d44c24820cf6fe5ab92e7b",
      "a51b461c062f4636bfa4b48823d0709b",
      "cced5f1cccc2400a8fbfd7a6eaedc666",
      "cf9597523c024514b9b3e66bc77e3fa8",
      "f01fdef82047471e8c1b780cae5379cc",
      "e1f08cf954ae4aea818c90d893486c77"
     ]
    },
    "id": "KPMoLPBn_1vN",
    "outputId": "58dca4e7-fc5c-4fd1-a8d4-755aa1e956cb"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import transformers\n",
    "import datasets\n",
    "from typing import OrderedDict as OD, List, Dict, Union\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    PreTrainedModel,\n",
    "    QDQBertForSequenceClassification,\n",
    "    BertForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    IntervalStrategy,\n",
    "    AutoTokenizer,\n",
    "    PreTrainedTokenizer,\n",
    ")\n",
    "from datasets import load_dataset, load_metric\n",
    "from transformer_deploy.QDQModels.QDQRoberta import QDQRobertaForSequenceClassification\n",
    "import pytorch_quantization.nn as quant_nn\n",
    "from pytorch_quantization.tensor_quant import QuantDescriptor\n",
    "from pytorch_quantization import calib\n",
    "import logging\n",
    "from datasets import DatasetDict\n",
    "from transformer_deploy.backends.trt_utils import build_engine, get_binding_idxs, infer_tensorrt, load_engine\n",
    "from transformer_deploy.backends.ort_utils import convert_to_onnx\n",
    "from collections import OrderedDict\n",
    "from transformer_deploy.benchmarks.utils import track_infer_time, print_timings\n",
    "from pycuda._driver import Stream\n",
    "import tensorrt as trt\n",
    "from tensorrt.tensorrt import IExecutionContext, Logger, Runtime\n",
    "import pycuda.autoinit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set logging to `error` to make the `notebook` more readable on Github."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_level = logging.ERROR\n",
    "logging.getLogger().setLevel(log_level)\n",
    "datasets.utils.logging.set_verbosity(log_level)\n",
    "transformers.utils.logging.set_verbosity(log_level)\n",
    "transformers.utils.logging.enable_default_handler()\n",
    "transformers.utils.logging.enable_explicit_format()\n",
    "trt_logger: Logger = trt.Logger(trt.Logger.ERROR)\n",
    "transformers.logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rEJBSTyZIrIb"
   },
   "source": [
    "### Download data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part is inspired from an [official Notebooks from Hugging Face](https://github.com/huggingface/notebooks/blob/master/examples/text_classification.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "zVvslsfMIrIh"
   },
   "outputs": [],
   "source": [
    "task = \"mnli\"\n",
    "num_labels = 3\n",
    "model_checkpoint = \"roberta-base\"\n",
    "batch_size = 32\n",
    "max_seq_len = 256\n",
    "validation_key = \"validation_matched\"\n",
    "timings: Dict[str, List[float]] = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W7QYTpxXIrIl"
   },
   "source": [
    "We will use the [ðŸ¤— Datasets](https://github.com/huggingface/datasets) library to download the data and get the metric we need to use for evaluation (to compare our model to the benchmark)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "IreSlFmlIrIm"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff977d13b16d44ddbf9536d565248621",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
       "        num_rows: 392702\n",
       "    })\n",
       "    validation_matched: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
       "        num_rows: 9815\n",
       "    })\n",
       "    validation_mismatched: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
       "        num_rows: 9832\n",
       "    })\n",
       "    test_matched: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
       "        num_rows: 9796\n",
       "    })\n",
       "    test_mismatched: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
       "        num_rows: 9847\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"glue\", task)\n",
    "metric = load_metric(\"glue\", task)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n9qywopnIrJH"
   },
   "source": [
    "### Preprocessing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YVx71GdAIrJH"
   },
   "source": [
    "Before we can feed those texts to our model, we need to preprocess them. This is done by a ðŸ¤— Transformers `Tokenizer` which will (as the name indicates) tokenize the inputs (including converting the tokens to their corresponding IDs in the pretrained vocabulary) and put it in a format the model expects, as well as generate the other inputs that model requires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "referenced_widgets": [
      "b6be028de2ae4ff691538eedb33793af",
      "a3e2c73d393d4e58a371f3da3dd80e6d",
      "b4d3f284fc4c4061b58d43a738f9bc78",
      "8a11c8fed672470b8335dc575a4a220e",
      "08286a6371584b4186014ecb5d5f164d",
      "68c4c867096d41a78740fdee30edcadb",
      "7d520bdde27742abb42803843721d101",
      "f8a0053903c64e75ac25eab5b24d5871",
      "93dbcc6d23a743bab0da8af6ee5e2825",
      "d1ecc3d380fc4758b03190b23686a2f1",
      "2d3a08166846438db79b0f89314fe76a",
      "5e2185bd6e4f4a10b89ac606868a43bd",
      "f44d2beebfe44186b0ac8016e89e4b49",
      "2eac6b4817e14d7fae396e6458b940fa",
      "af16284f77594397a69ad0e322b5e736",
      "a20579a9e7364fb485d79bdc4feb54dc",
      "cae29b9c6d45412fab70977fcd0f3234",
      "927ad6ade85a402594074fa90ab558c2",
      "30646fa2c0dc494e9dbcbd4dc598410e",
      "7a75099f99054645bf3fc1b778dac7e6",
      "d5d015711ae04d2f801577fc50af6c15",
      "4b13c3b3435f4689b29d48e0a35bebd6",
      "be4affe852b348de8fe1362582b08da9",
      "c6c100b71f26405fb960598feb5eee03",
      "99e94791043b4499b06601f7524f9b14",
      "26bc2038bed74279813ab5af09a2724c",
      "9bc6e14b912249e3b7d02f31bcc74667",
      "196ffc99ad5a40109d9b1cfe12032b62",
      "d5c8ff9e3bd849059fa7b30eab5fc940",
      "7ff32d18c9f0473893a6a6b2941c54b0",
      "0022faf286b44e858e638ccd5ded38b0",
      "6e54ce781ca54ad283911fa4774e3361",
      "969b6fdac1d6418d89a683db1e6ec6b2",
      "092db03992f24951b494fbb81da5b9d6",
      "023900ca566446eab5905b25b16a3de7",
      "994cf2338c7c4899952e25723445693c",
      "6aa2f5d46f1f454198d8e69517549ff1",
      "72b8f11065254e5ca488cd346b5add54",
      "c7bd52ef524c4d279dfcaa3aebe4a2c5",
      "d9a0852554284d36b6b121f579b06b41",
      "4320b12de9d14c459cc88319e2d7622a",
      "7b483d17d1d14fdd922600f0c906fc2f",
      "14648b8262944f5faac134a7c0184e47",
      "10678736bd534c63aebda414da01b4db"
     ]
    },
    "id": "eXNLu_-nIrJI",
    "outputId": "10b2f739-6277-44c2-fd31-0de3a9ab9fa8"
   },
   "outputs": [],
   "source": [
    "tokenizer: PreTrainedTokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2C0hcmp9IrJQ"
   },
   "source": [
    "We can them write the function that will preprocess our samples. We just feed them to the `tokenizer` with the argument `truncation=True` and `padding=\"max_length\"`. This will ensure that all sequences have the same size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "vc0BSBLIIrJQ"
   },
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"premise\"], examples[\"hypothesis\"], truncation=True, padding=\"max_length\", max_length=max_seq_len\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "referenced_widgets": [
      "65017db07d7f4e798ede741cc92488f0",
      "6fa74604c68543a38392fa0e1587f707",
      "86cc326e574a4fada7224e6f0c209e9a",
      "af5b646f89024c139c695a1f058fb772",
      "37cda4cae81a4d94aa831fb40b5c3b26",
      "28b7346a9b8c4b198dd9dbea1be013b6",
      "561b1ede331a40c1a2bff9422e8eea0e",
      "aecf7f063234416abf3f24766481cb89",
      "21ef195fa88f49c4a2c057f8028177a2",
      "5b1ad9f5d02c4b298a02ce6041692057",
      "56fd7584b0844590936519ec3851922e",
      "bbe3a471efb04ea8b5aabc4be819d585",
      "59418bbeb20547e5b5e1a5728262c757",
      "a61d366d91c34697a55f62b754e1f3a5",
      "1bea379404df429b9852b62a938661ae",
      "c801e1727de44b67aa7cb1c3d970e1fe",
      "b8722dc10d4447fe9630cbf169260cc8",
      "a9b98fd93fcd4fc4a2b2aa88c82835d0",
      "300f01e3547648f3983a83d3d3118c54",
      "a4c444f06c0847c09a44917084d3908d",
      "7c875ecd9cb54405a6c45969bcb4b4c6",
      "4552ee8ca6bd4a0b956651cc23f4ff3c",
      "3bfff454943b4b04a12ec29bbe28e0aa",
      "154200a8bc0b44fe8d0419fd56c6539d",
      "cedca6e55b84443e82f3d01471d61048",
      "a7d355f456eb4d3995dd91c5917a72c1",
      "b264b220d9c444bd9da46a7e6c8fd5ed",
      "4fae966b76844c869cdea1e53891e26f",
      "a0a2918e9772475cac51124b3b83fcaf",
      "a02624219ee84f50b1a3032eaa030a39",
      "5f032f56105f463a8680aa2482d0b162",
      "7701ec898fd443f1b35b187aea3651e9",
      "8399339998564d21ba5db6f0514c02c6"
     ]
    },
    "id": "DDtsaJeVIrJT",
    "outputId": "0eeb1cb2-e308-493b-807e-532eeae5f4fe",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encoded_dataset = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Some functions required for training and exporting the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    if task != \"stsb\":\n",
    "        predictions = np.argmax(predictions, axis=1)\n",
    "    else:\n",
    "        predictions = predictions[:, 0]\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "\n",
    "def calibrate(model: PreTrainedModel, encoded_dataset: DatasetDict, nb_sample: int = 128) -> PreTrainedModel:\n",
    "    # Find the TensorQuantizer and enable calibration\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, quant_nn.TensorQuantizer):\n",
    "            if module._calibrator is not None:\n",
    "                module.disable_quant()\n",
    "                module.enable_calib()\n",
    "            else:\n",
    "                module.disable()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for start_index in tqdm(range(0, nb_sample, batch_size)):\n",
    "            end_index = start_index + batch_size\n",
    "            data = encoded_dataset[\"train\"][start_index:end_index]\n",
    "            input_torch = {\n",
    "                k: torch.tensor(v, dtype=torch.long, device=\"cpu\")\n",
    "                for k, v in data.items()\n",
    "                if k in [\"input_ids\", \"attention_mask\", \"token_type_ids\"]\n",
    "            }\n",
    "            model(**input_torch)\n",
    "\n",
    "    # Finalize calibration\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, quant_nn.TensorQuantizer):\n",
    "            if module._calibrator is not None:\n",
    "                if isinstance(module._calibrator, calib.MaxCalibrator):\n",
    "                    module.load_calib_amax()\n",
    "                else:\n",
    "                    module.load_calib_amax(\"percentile\", percentile=99.99)\n",
    "                module.enable_quant()\n",
    "                module.disable_calib()\n",
    "            else:\n",
    "                module.enable()\n",
    "\n",
    "    model.cuda()\n",
    "    return model\n",
    "\n",
    "\n",
    "def convert_tensor(data: OD[str, List[List[int]]], output: str) -> OD[str, Union[np.ndarray, torch.Tensor]]:\n",
    "    input: OD[str, Union[np.ndarray, torch.Tensor]] = OrderedDict()\n",
    "    for k in [\"input_ids\", \"attention_mask\", \"token_type_ids\"]:\n",
    "        if k in data:\n",
    "            v = data[k]\n",
    "            if output == \"torch\":\n",
    "                value = torch.tensor(v, dtype=torch.long, device=\"cuda\")\n",
    "            elif output == \"np\":\n",
    "                value = np.asarray(v, dtype=np.int32)\n",
    "            else:\n",
    "                raise Exception(f\"unknown output type: {output}\")\n",
    "            input[k] = value\n",
    "    return input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some `TensorRT` reused variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime: Runtime = trt.Runtime(trt_logger)\n",
    "profile_index = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measure accuracy for ONNX Runtime and TensorRT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_labels = [item['label'] for item in encoded_dataset[validation_key]]\n",
    "def measure_accuracy(infer, int64: bool) -> float:\n",
    "    outputs = list()\n",
    "    for start_index in tqdm(range(0, len(encoded_dataset[validation_key]), batch_size)):\n",
    "        end_index = start_index + batch_size\n",
    "        data = encoded_dataset[validation_key][start_index:end_index]\n",
    "        inputs: OD[str, np.ndarray] = convert_tensor(data=data, output=\"np\")\n",
    "        if int64:\n",
    "            for k, v in inputs.items():\n",
    "                inputs[k] = v.astype(np.int64)\n",
    "        output = infer(inputs)\n",
    "        output = np.argmax(output[0], axis=1).astype(int).tolist()\n",
    "        outputs.extend(output)\n",
    "    return np.mean(np.array(outputs) == np.array(validation_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning model\n",
    "\n",
    "Now that our data are ready, we can download the pretrained model and fine-tune it.\n",
    "\n",
    "Default parameters to be used for the training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_step = 1000\n",
    "strategy = IntervalStrategy.STEPS\n",
    "args = TrainingArguments(\n",
    "    f\"{model_checkpoint}-{task}\",\n",
    "    evaluation_strategy=strategy,\n",
    "    eval_steps=nb_step,\n",
    "    logging_steps=nb_step,\n",
    "    save_steps=nb_step,\n",
    "    save_strategy=strategy,\n",
    "    learning_rate=1e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size * 2,\n",
    "    num_train_epochs=1,\n",
    "    fp16=True,\n",
    "    group_by_length=True,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=[],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1: `Transplantation` of weights from a source model to an optimized architecture\n",
    "\n",
    "Transplantation idea is to export weights from one model and use them in another one.\n",
    "In our case, the source are `Roberta` weights and the target is `Bert` archtecture which is highly optimized on `TensorRT` for GPU quantization.\n",
    "\n",
    "Indeed, not all models are quantization compliant. The optimization engine (`TensorRT`) search for some patterns and will fail to opimize the model if it doesn't find them. It requires the Pytorch code to be written in a certain way and use certain operations. For that reason, it's a good idea to reuse an architecture highly optimized.\n",
    "\n",
    "We will leverage the fact that since `Bert` have been released, very few improvements have been brought to the transformer architecture (at least for encoder only models).\n",
    "Better models appeared, and most of the work has been done to improve the pretraining step (aka the weights).\n",
    "So the idea will be to take the weights from those new models and put them inside `Bert` architecture.\n",
    "\n",
    "The process described below should work for most architectures.\n",
    "\n",
    "**steps**:\n",
    "\n",
    "* load `Bert` model\n",
    "* retrieve layer/weight names\n",
    "* load target model (here `Roberta`)\n",
    "* replace weight/layer names with those from `Roberta`\n",
    "* override the architecture name in model configuration\n",
    "\n",
    "If there is no 1 to 1 correspondance (it happens), try to keep at least token embeddings and self attention. Of course, it's possible that if a model is very different, the transplant may cost some accuracy. In our experience, if your trainset is big enough it should not happen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_bert: PreTrainedModel = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", num_labels=num_labels\n",
    ")\n",
    "bert_keys = list(model_bert.state_dict().keys())\n",
    "del model_bert\n",
    "\n",
    "model_roberta: PreTrainedModel = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, num_labels=num_labels\n",
    ")\n",
    "model_roberta.save_pretrained(\"roberta-in-bert\")\n",
    "del model_roberta\n",
    "model_weights: OD[str, Tensor] = torch.load(\"roberta-in-bert/pytorch_model.bin\")\n",
    "\n",
    "# Roberta -> Bert, there is 1 to 1 correspondance, for other models, you may need to create your own mapping.\n",
    "for bert_key in bert_keys:\n",
    "    # pop remove the first weights from the Ordered dict ...\n",
    "    _, weight = model_weights.popitem(last=False)\n",
    "    # ... and we re-insert them, in order, with a new key\n",
    "    model_weights[bert_key] = weight\n",
    "\n",
    "# we re-export the weights\n",
    "torch.save(model_weights, \"roberta-in-bert/pytorch_model.bin\")\n",
    "del model_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We override the architecture name to make `transformers` believe it is `Bert`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====> change architecture to bert base <======\n",
    "import json\n",
    "\n",
    "with open(\"roberta-in-bert/config.json\") as f:\n",
    "    content = json.load(f)\n",
    "    content[\"architectures\"] = [\"bert\"]\n",
    "\n",
    "with open(\"roberta-in-bert/config.json\", mode=\"w\") as f:\n",
    "    json.dump(content, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training\n",
    "\n",
    "The goal of this first training is to update weights to the new architecture to help the next step, the calibration.\n",
    "Indeed, `Roberta` architecture is a bit different from vanilla `Bert`, for instance position embeddings are not managed the same way, as they are at the very bottom of the model, they impact all model layers.\n",
    "If we skip this step, the value ranges computed during the calibration step may be very wrong and the `QAT` would provide low accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:437] 2021-12-09 19:48:11,412 >> Using amp half precision backend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7474, 'learning_rate': 9.1875814863103e-06, 'epoch': 0.08}\n",
      "{'eval_loss': 0.5083153247833252, 'eval_accuracy': 0.8007131940906775, 'eval_runtime': 18.9412, 'eval_samples_per_second': 518.182, 'eval_steps_per_second': 8.13, 'epoch': 0.08}\n",
      "{'loss': 0.5457, 'learning_rate': 8.372718383311604e-06, 'epoch': 0.16}\n",
      "{'eval_loss': 0.47982481122016907, 'eval_accuracy': 0.8163015792154865, 'eval_runtime': 19.417, 'eval_samples_per_second': 505.486, 'eval_steps_per_second': 7.931, 'epoch': 0.16}\n",
      "{'loss': 0.5075, 'learning_rate': 7.557855280312908e-06, 'epoch': 0.24}\n",
      "{'eval_loss': 0.4634084105491638, 'eval_accuracy': 0.8218033622007132, 'eval_runtime': 19.6824, 'eval_samples_per_second': 498.67, 'eval_steps_per_second': 7.824, 'epoch': 0.24}\n",
      "{'loss': 0.483, 'learning_rate': 6.743807040417211e-06, 'epoch': 0.33}\n",
      "{'eval_loss': 0.42370399832725525, 'eval_accuracy': 0.8344370860927153, 'eval_runtime': 19.5405, 'eval_samples_per_second': 502.29, 'eval_steps_per_second': 7.881, 'epoch': 0.33}\n",
      "{'loss': 0.4652, 'learning_rate': 5.9289439374185145e-06, 'epoch': 0.41}\n",
      "{'eval_loss': 0.4242672026157379, 'eval_accuracy': 0.8365766683647479, 'eval_runtime': 18.8626, 'eval_samples_per_second': 520.343, 'eval_steps_per_second': 8.164, 'epoch': 0.41}\n",
      "{'loss': 0.451, 'learning_rate': 5.114080834419818e-06, 'epoch': 0.49}\n",
      "{'eval_loss': 0.42570847272872925, 'eval_accuracy': 0.8365766683647479, 'eval_runtime': 18.9979, 'eval_samples_per_second': 516.636, 'eval_steps_per_second': 8.106, 'epoch': 0.49}\n",
      "{'loss': 0.4505, 'learning_rate': 4.299217731421121e-06, 'epoch': 0.57}\n",
      "{'eval_loss': 0.4005618989467621, 'eval_accuracy': 0.8451349974528782, 'eval_runtime': 18.8952, 'eval_samples_per_second': 519.443, 'eval_steps_per_second': 8.15, 'epoch': 0.57}\n",
      "{'loss': 0.4422, 'learning_rate': 3.4859843546284226e-06, 'epoch': 0.65}\n",
      "{'eval_loss': 0.3936935365200043, 'eval_accuracy': 0.8445236882322975, 'eval_runtime': 18.9752, 'eval_samples_per_second': 517.253, 'eval_steps_per_second': 8.116, 'epoch': 0.65}\n",
      "{'loss': 0.4332, 'learning_rate': 2.6711212516297265e-06, 'epoch': 0.73}\n",
      "{'eval_loss': 0.3954601585865021, 'eval_accuracy': 0.8470708099847173, 'eval_runtime': 18.7912, 'eval_samples_per_second': 522.32, 'eval_steps_per_second': 8.195, 'epoch': 0.73}\n",
      "{'loss': 0.4254, 'learning_rate': 1.8570730117340288e-06, 'epoch': 0.81}\n",
      "{'eval_loss': 0.39208605885505676, 'eval_accuracy': 0.8492103922567499, 'eval_runtime': 19.1256, 'eval_samples_per_second': 513.185, 'eval_steps_per_second': 8.052, 'epoch': 0.81}\n",
      "{'loss': 0.4263, 'learning_rate': 1.0422099087353325e-06, 'epoch': 0.9}\n",
      "{'eval_loss': 0.384700208902359, 'eval_accuracy': 0.851044319918492, 'eval_runtime': 19.1997, 'eval_samples_per_second': 511.207, 'eval_steps_per_second': 8.021, 'epoch': 0.9}\n",
      "{'loss': 0.4263, 'learning_rate': 2.2816166883963498e-07, 'epoch': 0.98}\n",
      "{'eval_loss': 0.38375720381736755, 'eval_accuracy': 0.8508405501782985, 'eval_runtime': 18.5961, 'eval_samples_per_second': 527.8, 'eval_steps_per_second': 8.281, 'epoch': 0.98}\n",
      "{'train_runtime': 2701.3089, 'train_samples_per_second': 145.375, 'train_steps_per_second': 4.543, 'train_loss': 0.48233796906751014, 'epoch': 1.0}\n",
      "{'eval_loss': 0.384700208902359, 'eval_accuracy': 0.851044319918492, 'eval_runtime': 18.5921, 'eval_samples_per_second': 527.911, 'eval_steps_per_second': 8.283, 'epoch': 1.0}\n",
      "{'eval_loss': 0.384700208902359, 'eval_accuracy': 0.851044319918492, 'eval_runtime': 18.5921, 'eval_samples_per_second': 527.911, 'eval_steps_per_second': 8.283, 'epoch': 1.0}\n"
     ]
    }
   ],
   "source": [
    "transformers.logging.set_verbosity_error()\n",
    "model_bert = BertForSequenceClassification.from_pretrained(\"roberta-in-bert\", num_labels=num_labels)\n",
    "model_bert = model_bert.cuda()\n",
    "\n",
    "trainer = Trainer(\n",
    "    model_bert,\n",
    "    args,\n",
    "    train_dataset=encoded_dataset[\"train\"],\n",
    "    eval_dataset=encoded_dataset[validation_key],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "transformers.logging.set_verbosity_error()\n",
    "trainer.train()\n",
    "print(trainer.evaluate())\n",
    "model_bert.save_pretrained(\"roberta-in-bert-trained\")\n",
    "del trainer\n",
    "del model_bert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we will start the quantization process.\n",
    "It follow those steps:\n",
    "\n",
    "* perform the calibration\n",
    "* perform a quantization aware training\n",
    "\n",
    "By passing validation values to the model, we will calibrate it, meaning it will get the right range / scale to convert FP32 weights to int-8 ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activate histogram calibration\n",
    "\n",
    "There are several kinds of calbrators, below we use the percentile one (99.99p) (`histogram`), basically, its purpose is to just remove the most extreme values before computing range / scale.\n",
    "The other option in NLP is `max`, it's much faster but expect lower accuracy.\n",
    "\n",
    "Second calibration option, choose between calibration done at the tensor level or per channel (finer grained value ranges, a bit slower).\n",
    "Calibration is based on few samples (in our case 128 sequences)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can also use \"max\" instead of \"historgram\"\n",
    "input_desc = QuantDescriptor(num_bits=8, calib_method=\"histogram\")\n",
    "# below we do per-channel quantization for weights, set axis to None to get a per tensor calibration\n",
    "weight_desc = QuantDescriptor(num_bits=8, axis=(0,))\n",
    "quant_nn.QuantLinear.set_default_quant_desc_input(input_desc)\n",
    "quant_nn.QuantLinear.set_default_quant_desc_weight(weight_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform calibration\n",
    "\n",
    "During this step we will enable the calibration nodes, and pass some representative data to the model.\n",
    "It will then be used to compute the scale/range.\n",
    "\n",
    "Official recommendations from Nvidia is to calibrate over thousands of examples from the validation set.\n",
    "Here we use 128 examples because it's a slow process. It's enough to be close from the original accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "776c4daba3a04b34a72210697ad37e6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# keep it on CPU\n",
    "model_q = QDQBertForSequenceClassification.from_pretrained(\"roberta-in-bert-trained\", num_labels=num_labels)\n",
    "model_q = calibrate(model=model_q, encoded_dataset=encoded_dataset)\n",
    "model_q.save_pretrained(\"roberta-in-bert-trained-quantized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantization Aware Training (QAT)\n",
    "\n",
    "The query aware training is not a mandatory step, but **highly** recommended to get the best accuracy. Basically we will redo the training with the quantization enabled and a low learning rate to avoid overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "imY1oC3SIrJf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:437] 2021-12-09 20:39:35,717 >> Using amp half precision backend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4307818114757538, 'eval_accuracy': 0.8327050433010698, 'eval_runtime': 45.8394, 'eval_samples_per_second': 214.117, 'eval_steps_per_second': 3.36}\n",
      "{'eval_loss': 0.4307818114757538, 'eval_accuracy': 0.8327050433010698, 'eval_runtime': 45.8394, 'eval_samples_per_second': 214.117, 'eval_steps_per_second': 3.36}\n",
      "{'loss': 0.4542, 'learning_rate': 9.187581486310299e-07, 'epoch': 0.08}\n",
      "{'eval_loss': 0.4258573651313782, 'eval_accuracy': 0.8376974019358125, 'eval_runtime': 46.5114, 'eval_samples_per_second': 211.023, 'eval_steps_per_second': 3.311, 'epoch': 0.08}\n",
      "{'loss': 0.4422, 'learning_rate': 8.372718383311604e-07, 'epoch': 0.16}\n",
      "{'eval_loss': 0.4214017987251282, 'eval_accuracy': 0.8395313295975547, 'eval_runtime': 46.5334, 'eval_samples_per_second': 210.924, 'eval_steps_per_second': 3.309, 'epoch': 0.16}\n",
      "{'loss': 0.4268, 'learning_rate': 7.557855280312907e-07, 'epoch': 0.24}\n",
      "{'eval_loss': 0.41808152198791504, 'eval_accuracy': 0.8423841059602649, 'eval_runtime': 46.5578, 'eval_samples_per_second': 210.813, 'eval_steps_per_second': 3.308, 'epoch': 0.24}\n",
      "{'loss': 0.4223, 'learning_rate': 6.742992177314211e-07, 'epoch': 0.33}\n",
      "{'eval_loss': 0.42257484793663025, 'eval_accuracy': 0.838920020376974, 'eval_runtime': 46.599, 'eval_samples_per_second': 210.627, 'eval_steps_per_second': 3.305, 'epoch': 0.33}\n",
      "{'loss': 0.4282, 'learning_rate': 5.928943937418513e-07, 'epoch': 0.41}\n",
      "{'eval_loss': 0.41137370467185974, 'eval_accuracy': 0.8409577177789098, 'eval_runtime': 46.5435, 'eval_samples_per_second': 210.878, 'eval_steps_per_second': 3.309, 'epoch': 0.41}\n",
      "{'loss': 0.4234, 'learning_rate': 5.114895697522817e-07, 'epoch': 0.49}\n",
      "{'eval_loss': 0.41403627395629883, 'eval_accuracy': 0.841874681609781, 'eval_runtime': 46.5743, 'eval_samples_per_second': 210.739, 'eval_steps_per_second': 3.307, 'epoch': 0.49}\n",
      "{'loss': 0.4202, 'learning_rate': 4.3000325945241197e-07, 'epoch': 0.57}\n",
      "{'eval_loss': 0.4175918698310852, 'eval_accuracy': 0.8417727967396842, 'eval_runtime': 46.5654, 'eval_samples_per_second': 210.779, 'eval_steps_per_second': 3.307, 'epoch': 0.57}\n",
      "{'loss': 0.4289, 'learning_rate': 3.4859843546284223e-07, 'epoch': 0.65}\n",
      "{'eval_loss': 0.41122177243232727, 'eval_accuracy': 0.8441161487519103, 'eval_runtime': 46.5376, 'eval_samples_per_second': 210.905, 'eval_steps_per_second': 3.309, 'epoch': 0.65}\n",
      "{'loss': 0.4283, 'learning_rate': 2.6711212516297263e-07, 'epoch': 0.73}\n",
      "{'eval_loss': 0.4128565490245819, 'eval_accuracy': 0.8426897605705552, 'eval_runtime': 46.7511, 'eval_samples_per_second': 209.942, 'eval_steps_per_second': 3.294, 'epoch': 0.73}\n",
      "{'loss': 0.4174, 'learning_rate': 1.8570730117340285e-07, 'epoch': 0.81}\n",
      "{'eval_loss': 0.40628135204315186, 'eval_accuracy': 0.8441161487519103, 'eval_runtime': 46.6972, 'eval_samples_per_second': 210.184, 'eval_steps_per_second': 3.298, 'epoch': 0.81}\n",
      "{'loss': 0.4191, 'learning_rate': 1.0422099087353324e-07, 'epoch': 0.9}\n",
      "{'eval_loss': 0.41109439730644226, 'eval_accuracy': 0.8451349974528782, 'eval_runtime': 46.5565, 'eval_samples_per_second': 210.819, 'eval_steps_per_second': 3.308, 'epoch': 0.9}\n",
      "{'loss': 0.4178, 'learning_rate': 2.2734680573663624e-08, 'epoch': 0.98}\n",
      "{'eval_loss': 0.409859836101532, 'eval_accuracy': 0.8464595007641366, 'eval_runtime': 46.5572, 'eval_samples_per_second': 210.816, 'eval_steps_per_second': 3.308, 'epoch': 0.98}\n",
      "{'train_runtime': 4943.333, 'train_samples_per_second': 79.441, 'train_steps_per_second': 2.483, 'train_loss': 0.4271986904169155, 'epoch': 1.0}\n",
      "{'eval_loss': 0.409859836101532, 'eval_accuracy': 0.8464595007641366, 'eval_runtime': 46.5126, 'eval_samples_per_second': 211.018, 'eval_steps_per_second': 3.311, 'epoch': 1.0}\n",
      "{'eval_loss': 0.409859836101532, 'eval_accuracy': 0.8464595007641366, 'eval_runtime': 46.5126, 'eval_samples_per_second': 211.018, 'eval_steps_per_second': 3.311, 'epoch': 1.0}\n"
     ]
    }
   ],
   "source": [
    "model_q = QDQBertForSequenceClassification.from_pretrained(\"roberta-in-bert-trained-quantized\", num_labels=num_labels)\n",
    "model_q = model_q.cuda()\n",
    "\n",
    "args.learning_rate = 1e-6\n",
    "\n",
    "trainer = Trainer(\n",
    "    model_q,\n",
    "    args,\n",
    "    train_dataset=encoded_dataset[\"train\"],\n",
    "    eval_dataset=encoded_dataset[validation_key],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "transformers.logging.set_verbosity_error()\n",
    "print(trainer.evaluate())\n",
    "trainer.train()\n",
    "print(trainer.evaluate())\n",
    "model_q.save_pretrained(\"roberta-in-bert-trained-quantized-bis\")\n",
    "del model_q\n",
    "del trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export a `QDQ Pytorch` model on `ONNX`, we need to enable fake quantization mode from Pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/geantvert/.local/share/virtualenvs/fast_transformer/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:285: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/geantvert/.local/share/virtualenvs/fast_transformer/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:291: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n"
     ]
    }
   ],
   "source": [
    "data = encoded_dataset[\"train\"][0:3]\n",
    "input_torch = convert_tensor(data, output=\"torch\")\n",
    "\n",
    "model_q = QDQBertForSequenceClassification.from_pretrained(\n",
    "    \"roberta-in-bert-trained-quantized-bis\", num_labels=num_labels\n",
    ")\n",
    "model_q = model_q.cuda()\n",
    "from pytorch_quantization.nn import TensorQuantizer\n",
    "\n",
    "TensorQuantizer.use_fb_fake_quant = True\n",
    "convert_to_onnx(model_q, output_path=\"model_q.onnx\", inputs_pytorch=input_torch, opset=13)\n",
    "TensorQuantizer.use_fb_fake_quant = False\n",
    "# del model_q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Convert `ONNX` graph to `TensorRT` engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "engine = build_engine(\n",
    "    runtime=runtime,\n",
    "    onnx_file_path=\"model_q.onnx\",\n",
    "    logger=trt_logger,\n",
    "    min_shape=(1, max_seq_len),  # 1 in batch size to support batch from size 1 to 32\n",
    "    optimal_shape=(batch_size, max_seq_len),\n",
    "    max_shape=(batch_size, max_seq_len),\n",
    "    workspace_size=10000 * 1024 * 1024,\n",
    "    fp16=False,\n",
    "    int8=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# same thing from command line\n",
    "# !/usr/src/tensorrt/bin/trtexec --onnx=model_q.onnx --shapes=input_ids:32x256,attention_mask:32x256 --int8 --workspace=10000 --saveEngine=\"test.plan\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Prepare input and output buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "stream: Stream = pycuda.driver.Stream()\n",
    "context: IExecutionContext = engine.create_execution_context()\n",
    "context.set_optimization_profile_async(profile_index=profile_index, stream_handle=stream.handle)\n",
    "input_binding_idxs, output_binding_idxs = get_binding_idxs(engine, profile_index)  # type: List[int], List[int]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = encoded_dataset[\"train\"][0:batch_size]\n",
    "input_np: Dict[str, np.ndarray] = convert_tensor(data, output=\"np\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Inference on `TensorRT`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first check that inference is working correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 0.74428475,  0.92069125, -1.8263749 ],\n",
      "       [ 1.851499  , -1.0653014 , -1.4172065 ],\n",
      "       [ 1.7828548 , -1.1306885 , -1.1852558 ],\n",
      "       [ 1.6740881 , -0.7420906 , -1.5647126 ],\n",
      "       [ 2.2817519 ,  0.01615529, -2.7685544 ],\n",
      "       [ 3.1013348 , -0.48788828, -3.3121827 ],\n",
      "       [-3.0679533 ,  2.708288  ,  0.70968   ],\n",
      "       [ 3.1545656 , -1.0913979 , -2.6073706 ],\n",
      "       [-0.3026344 , -1.7703965 ,  1.6011946 ],\n",
      "       [-3.2131557 , -0.5275665 ,  3.786335  ],\n",
      "       [ 2.2266033 , -1.2310914 , -1.523544  ],\n",
      "       [-1.5110059 , -0.46988845,  1.7940781 ],\n",
      "       [-2.4409676 ,  3.7142613 , -0.73455316],\n",
      "       [-1.8158143 ,  1.9259161 , -0.05558195],\n",
      "       [-0.33427513, -0.48280472,  0.6140785 ],\n",
      "       [ 2.3686104 , -1.4665173 , -1.5184819 ],\n",
      "       [ 3.58267   , -1.1251179 , -3.060151  ],\n",
      "       [-2.4983776 , -2.0526152 ,  4.5359097 ],\n",
      "       [-3.441052  , -0.6358736 ,  4.1798487 ],\n",
      "       [-2.2326443 ,  4.032728  , -1.1005057 ],\n",
      "       [ 3.4742196 , -0.98982847, -3.2408576 ],\n",
      "       [ 1.7075734 ,  0.56745094, -2.7780871 ],\n",
      "       [-2.6132822 ,  0.45791242,  2.1319566 ],\n",
      "       [ 3.498353  , -0.68513054, -3.4510155 ],\n",
      "       [ 3.394199  , -1.578492  , -2.5097256 ],\n",
      "       [-1.5231444 ,  0.22112232,  1.1882032 ],\n",
      "       [-2.7878394 ,  1.368547  ,  1.5938892 ],\n",
      "       [-2.263415  ,  2.5507202 , -0.16721557],\n",
      "       [-2.716222  ,  0.03395515,  2.6644425 ],\n",
      "       [ 2.663493  , -0.7295195 , -2.7137947 ],\n",
      "       [ 2.6217816 , -0.7861772 , -2.417176  ],\n",
      "       [ 2.506748  , -0.09974011, -3.0284772 ]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "tensorrt_output = infer_tensorrt(\n",
    "    context=context,\n",
    "    host_inputs=input_np,\n",
    "    input_binding_idxs=input_binding_idxs,\n",
    "    output_binding_idxs=output_binding_idxs,\n",
    "    stream=stream,\n",
    ")\n",
    "print(tensorrt_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measure of the accuracy when `TensorRT` is the engine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3123eb9ee20476aa55e70b181c124d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/307 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8444218033622007"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infer_trt = lambda inputs: infer_tensorrt(\n",
    "        context=context,\n",
    "        host_inputs=inputs,\n",
    "        input_binding_idxs=input_binding_idxs,\n",
    "        output_binding_idxs=output_binding_idxs,\n",
    "        stream=stream,\n",
    "    )\n",
    "\n",
    "measure_accuracy(infer=infer_trt, int64=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Latency measures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TensorRT (INT-8)] mean=14.63ms, sd=0.33ms, min=13.94ms, max=17.54ms, median=14.58ms, 95p=14.76ms, 99p=15.38ms\n"
     ]
    }
   ],
   "source": [
    "time_buffer = list()\n",
    "for _ in range(100):\n",
    "    with track_infer_time(time_buffer):\n",
    "        _ = infer_tensorrt(\n",
    "            context=context,\n",
    "            host_inputs=input_np,\n",
    "            input_binding_idxs=input_binding_idxs,\n",
    "            output_binding_idxs=output_binding_idxs,\n",
    "            stream=stream,\n",
    "        )\n",
    "\n",
    "print_timings(name=\"TensorRT (INT-8)\", timings=time_buffer)\n",
    "del engine, context  # delete all tensorrt objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Method 2: use a dedicated QDQ model\n",
    "\n",
    "In method 2, the idea is to take the source code of a specific model and add manually in the source code `QDQ` nodes. That way, quantization will work out of the box for this architecture.\n",
    "We have started with `QDQRoberta` a quantization compliant `Roberta` model.\n",
    "\n",
    "To adapt to another architecture, one need to:\n",
    "\n",
    "* replace linear layers with their quantized version\n",
    "* replace operations not supported out of the box by `TensorRT` by a similar code supporting the operation.\n",
    "\n",
    "> concrete examples on `Roberta` architecture: in HF library, there is a `cumsum` in the position embedding generation. Something very simple. It takes as input an integer tensor and output an integer tensor. It happens that the `cumsum` operator from TensorRT supports float but not integer (https://github.com/onnx/onnx-tensorrt/blob/master/docs/operators.md). It leads to a crash during the model conversion with a strange error message. Converting the input to float tensor fix the issue. Not complex, but requires some knowledge.\n",
    "\n",
    "The process below is a bit simpler than the method 1:\n",
    "\n",
    "* Calibrate\n",
    "* Quantization Aware training (QAT)\n",
    "\n",
    "> there are many ways to get a QDQ model, you can modify Pytorch source code like here, patch ONNX graph (this approach is used at Microsoft for instance) or leverage the new FX Pytorch interface. Modifying the source code is the most straight forward so we choosed to do it that way.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3d2a85cc8674f6db9ccc11bdb52794a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_desc = QuantDescriptor(num_bits=8, calib_method=\"histogram\")\n",
    "# below we do per-channel quantization for weights, set axis to None to get a per tensor calibration\n",
    "weight_desc = QuantDescriptor(num_bits=8, axis=(0,))\n",
    "quant_nn.QuantLinear.set_default_quant_desc_input(input_desc)\n",
    "quant_nn.QuantLinear.set_default_quant_desc_weight(weight_desc)\n",
    "\n",
    "# keep it on CPU\n",
    "model_roberta: PreTrainedModel = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, num_labels=num_labels\n",
    ")\n",
    "model_roberta.save_pretrained(\"roberta-untrained-quantized\")\n",
    "del model_roberta\n",
    "\n",
    "model_roberta_q: PreTrainedModel = QDQRobertaForSequenceClassification.from_pretrained(\"roberta-untrained-quantized\")\n",
    "model_roberta_q = calibrate(model=model_roberta_q, encoded_dataset=encoded_dataset)\n",
    "model_roberta_q.save_pretrained(\"roberta-untrained-quantized\")\n",
    "del model_roberta_q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "### Quantization Aware Training (QAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:437] 2021-12-09 22:10:02,417 >> Using amp half precision backend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7446, 'learning_rate': 9.1875814863103e-06, 'epoch': 0.08}\n",
      "{'eval_loss': 0.5072791576385498, 'eval_accuracy': 0.8059093224656139, 'eval_runtime': 47.7062, 'eval_samples_per_second': 205.738, 'eval_steps_per_second': 3.228, 'epoch': 0.08}\n",
      "{'loss': 0.5424, 'learning_rate': 8.372718383311604e-06, 'epoch': 0.16}\n",
      "{'eval_loss': 0.4495479464530945, 'eval_accuracy': 0.8264900662251655, 'eval_runtime': 46.5832, 'eval_samples_per_second': 210.698, 'eval_steps_per_second': 3.306, 'epoch': 0.16}\n",
      "{'loss': 0.5071, 'learning_rate': 7.558670143415907e-06, 'epoch': 0.24}\n",
      "{'eval_loss': 0.4541535973548889, 'eval_accuracy': 0.8242485990830362, 'eval_runtime': 50.0162, 'eval_samples_per_second': 196.236, 'eval_steps_per_second': 3.079, 'epoch': 0.24}\n",
      "{'loss': 0.4854, 'learning_rate': 6.743807040417211e-06, 'epoch': 0.33}\n",
      "{'eval_loss': 0.4110897183418274, 'eval_accuracy': 0.8425878757004585, 'eval_runtime': 47.5433, 'eval_samples_per_second': 206.443, 'eval_steps_per_second': 3.239, 'epoch': 0.33}\n",
      "{'loss': 0.4656, 'learning_rate': 5.929758800521513e-06, 'epoch': 0.41}\n",
      "{'eval_loss': 0.4083874821662903, 'eval_accuracy': 0.8410596026490066, 'eval_runtime': 47.486, 'eval_samples_per_second': 206.693, 'eval_steps_per_second': 3.243, 'epoch': 0.41}\n",
      "{'loss': 0.4547, 'learning_rate': 5.1148956975228174e-06, 'epoch': 0.49}\n",
      "{'eval_loss': 0.40900033712387085, 'eval_accuracy': 0.8411614875191035, 'eval_runtime': 48.7052, 'eval_samples_per_second': 201.518, 'eval_steps_per_second': 3.162, 'epoch': 0.49}\n",
      "{'loss': 0.4503, 'learning_rate': 4.30003259452412e-06, 'epoch': 0.57}\n",
      "{'eval_loss': 0.391275018453598, 'eval_accuracy': 0.8503311258278146, 'eval_runtime': 47.4931, 'eval_samples_per_second': 206.662, 'eval_steps_per_second': 3.243, 'epoch': 0.57}\n",
      "{'loss': 0.4433, 'learning_rate': 3.4851694915254244e-06, 'epoch': 0.65}\n",
      "{'eval_loss': 0.3878655731678009, 'eval_accuracy': 0.851044319918492, 'eval_runtime': 49.1368, 'eval_samples_per_second': 199.748, 'eval_steps_per_second': 3.134, 'epoch': 0.65}\n",
      "{'loss': 0.4323, 'learning_rate': 2.6711212516297265e-06, 'epoch': 0.73}\n",
      "{'eval_loss': 0.38398584723472595, 'eval_accuracy': 0.8541008660213958, 'eval_runtime': 48.2456, 'eval_samples_per_second': 203.438, 'eval_steps_per_second': 3.192, 'epoch': 0.73}\n",
      "{'loss': 0.4238, 'learning_rate': 1.8570730117340288e-06, 'epoch': 0.81}\n",
      "{'eval_loss': 0.38184261322021484, 'eval_accuracy': 0.8535914416709118, 'eval_runtime': 47.2522, 'eval_samples_per_second': 207.715, 'eval_steps_per_second': 3.259, 'epoch': 0.81}\n",
      "{'loss': 0.4253, 'learning_rate': 1.0422099087353325e-06, 'epoch': 0.9}\n",
      "{'eval_loss': 0.37562793493270874, 'eval_accuracy': 0.856953642384106, 'eval_runtime': 47.5902, 'eval_samples_per_second': 206.24, 'eval_steps_per_second': 3.236, 'epoch': 0.9}\n",
      "{'loss': 0.4248, 'learning_rate': 2.2734680573663624e-07, 'epoch': 0.98}\n",
      "{'eval_loss': 0.37268802523612976, 'eval_accuracy': 0.8588894549159449, 'eval_runtime': 48.7185, 'eval_samples_per_second': 201.463, 'eval_steps_per_second': 3.161, 'epoch': 0.98}\n",
      "{'train_runtime': 5103.4383, 'train_samples_per_second': 76.949, 'train_steps_per_second': 2.405, 'train_loss': 0.4821581125570245, 'epoch': 1.0}\n",
      "{'eval_loss': 0.37268802523612976, 'eval_accuracy': 0.8588894549159449, 'eval_runtime': 47.6115, 'eval_samples_per_second': 206.148, 'eval_steps_per_second': 3.235, 'epoch': 1.0}\n",
      "{'eval_loss': 0.37268802523612976, 'eval_accuracy': 0.8588894549159449, 'eval_runtime': 47.6115, 'eval_samples_per_second': 206.148, 'eval_steps_per_second': 3.235, 'epoch': 1.0}\n"
     ]
    }
   ],
   "source": [
    "model_roberta_q: PreTrainedModel = QDQRobertaForSequenceClassification.from_pretrained(\n",
    "    \"roberta-untrained-quantized\", num_labels=num_labels\n",
    ")\n",
    "model_roberta_q = model_roberta_q.cuda()\n",
    "\n",
    "args.learning_rate = 1e-5\n",
    "\n",
    "trainer = Trainer(\n",
    "    model_roberta_q,\n",
    "    args,\n",
    "    train_dataset=encoded_dataset[\"train\"],\n",
    "    eval_dataset=encoded_dataset[validation_key],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "transformers.logging.set_verbosity_error()\n",
    "trainer.train()\n",
    "print(trainer.evaluate())\n",
    "model_roberta_q.save_pretrained(\"roberta-trained-quantized\")\n",
    "del model_roberta_q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export a `QDQ Pytorch` model on `ONNX`, we need to enable fake quantization mode from Pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/geantvert/.local/share/virtualenvs/fast_transformer/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:285: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/geantvert/.local/share/virtualenvs/fast_transformer/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:291: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n"
     ]
    }
   ],
   "source": [
    "model_roberta_q: PreTrainedModel = QDQRobertaForSequenceClassification.from_pretrained(\n",
    "    \"roberta-trained-quantized\", num_labels=num_labels\n",
    ")\n",
    "model_roberta_q = model_roberta_q.cuda()\n",
    "\n",
    "data = encoded_dataset[\"train\"][1:3]\n",
    "input_torch = convert_tensor(data, output=\"torch\")\n",
    "\n",
    "from pytorch_quantization.nn import TensorQuantizer\n",
    "\n",
    "TensorQuantizer.use_fb_fake_quant = True\n",
    "convert_to_onnx(model_pytorch=model_roberta_q, output_path=\"roberta_q.onnx\", inputs_pytorch=input_torch, opset=13)\n",
    "TensorQuantizer.use_fb_fake_quant = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert `ONNX` graph to `TensorRT` engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "engine = build_engine(\n",
    "    runtime=runtime,\n",
    "    onnx_file_path=\"roberta_q.onnx\",\n",
    "    logger=trt_logger,\n",
    "    min_shape=(1, max_seq_len),\n",
    "    optimal_shape=(batch_size, max_seq_len),\n",
    "    max_shape=(batch_size, max_seq_len),\n",
    "    workspace_size=10000 * 1024 * 1024,\n",
    "    fp16=False,\n",
    "    int8=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# same conversion from the terminal\n",
    "#!/usr/src/tensorrt/bin/trtexec --onnx=roberta_q.onnx --shapes=input_ids:32x256,attention_mask:32x256 --int8 --workspace=10000 --saveEngine=\"test.plan\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare input and output buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "stream: Stream = pycuda.driver.Stream()\n",
    "context: IExecutionContext = engine.create_execution_context()\n",
    "context.set_optimization_profile_async(profile_index=profile_index, stream_handle=stream.handle)\n",
    "input_binding_idxs, output_binding_idxs = get_binding_idxs(engine, profile_index)  # type: List[int], List[int]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = encoded_dataset[\"train\"][0:batch_size]\n",
    "input_torch: OD[str, torch.Tensor] = convert_tensor(data=data, output=\"torch\")\n",
    "input_np: OD[str, np.ndarray] = convert_tensor(data=data, output=\"np\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference on `TensorRT`\n",
    "\n",
    "We first check that inference is working correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-0.51485693,  1.7172506 , -1.5262733 ],\n",
      "       [ 2.353083  , -1.1611496 , -1.5365003 ],\n",
      "       [ 1.7413325 , -0.5790743 , -1.659783  ],\n",
      "       [ 1.564936  , -0.49288243, -1.3157034 ],\n",
      "       [ 1.625774  , -0.06960616, -2.3415694 ],\n",
      "       [ 3.4986691 , -1.4058641 , -2.909094  ],\n",
      "       [-2.8577392 ,  2.3696911 ,  0.9519228 ],\n",
      "       [ 3.3248267 , -1.3577703 , -2.7853382 ],\n",
      "       [ 0.24115235, -1.2206222 ,  1.9764783 ],\n",
      "       [-2.1684752 , -0.5929435 ,  4.1980004 ],\n",
      "       [ 2.7209766 , -0.85320175, -2.54238   ],\n",
      "       [-1.4474616 , -0.5539231 ,  3.543574  ],\n",
      "       [-2.4900246 ,  2.5807233 ,  0.29105982],\n",
      "       [-2.5218582 ,  2.4110076 ,  0.4147416 ],\n",
      "       [-0.17686448,  0.19154471,  0.5593225 ],\n",
      "       [ 2.7820387 , -0.92807496, -2.466081  ],\n",
      "       [ 3.279974  , -1.1566027 , -3.082859  ],\n",
      "       [-2.0141928 , -1.5038209 ,  4.759576  ],\n",
      "       [-2.8134325 , -0.09846646,  4.3754187 ],\n",
      "       [-2.4098513 ,  3.2899659 , -1.0759622 ],\n",
      "       [ 3.3163776 , -1.0768431 , -3.2254322 ],\n",
      "       [ 1.8269717 ,  0.69882363, -3.383636  ],\n",
      "       [-2.5522573 , -0.6264023 ,  4.348268  ],\n",
      "       [ 3.4143322 , -1.0857687 , -3.3268075 ],\n",
      "       [ 3.418143  , -1.5472901 , -2.7069504 ],\n",
      "       [-0.9896777 ,  0.2267024 ,  1.1920347 ],\n",
      "       [-1.9947617 ,  0.58624893,  2.7530055 ],\n",
      "       [-2.328186  ,  3.3224452 , -1.4264905 ],\n",
      "       [-2.8432767 ,  0.7639467 ,  3.400511  ],\n",
      "       [ 2.8967564 , -0.8297742 , -3.1207962 ],\n",
      "       [ 3.0185122 , -1.3341582 , -2.4004488 ],\n",
      "       [ 3.050612  , -1.0362974 , -2.8093874 ]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "tensorrt_output = infer_tensorrt(\n",
    "    context=context,\n",
    "    host_inputs=input_np,\n",
    "    input_binding_idxs=input_binding_idxs,\n",
    "    output_binding_idxs=output_binding_idxs,\n",
    "    stream=stream,\n",
    ")\n",
    "print(tensorrt_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measure of the accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39a7ce7f07b34049a82b0721dcb0322e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/307 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8577687213448802"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infer_trt = lambda inputs: infer_tensorrt(\n",
    "        context=context,\n",
    "        host_inputs=inputs,\n",
    "        input_binding_idxs=input_binding_idxs,\n",
    "        output_binding_idxs=output_binding_idxs,\n",
    "        stream=stream,\n",
    "    )\n",
    "\n",
    "measure_accuracy(infer=infer_trt, int64=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Latency measures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TensorRT (INT-8)] mean=15.52ms, sd=0.62ms, min=14.49ms, max=17.17ms, median=15.15ms, 95p=16.67ms, 99p=17.03ms\n"
     ]
    }
   ],
   "source": [
    "time_buffer = list()\n",
    "for _ in range(100):\n",
    "    with track_infer_time(time_buffer):\n",
    "        _ = infer_tensorrt(\n",
    "            context=context,\n",
    "            host_inputs=input_np,\n",
    "            input_binding_idxs=input_binding_idxs,\n",
    "            output_binding_idxs=output_binding_idxs,\n",
    "            stream=stream,\n",
    "        )\n",
    "\n",
    "print_timings(name=\"TensorRT (INT-8)\", timings=time_buffer)\n",
    "del engine, context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch baseline\n",
    "\n",
    "### Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:437] 2021-12-09 23:38:27,822 >> Using amp half precision backend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6612, 'learning_rate': 9.1875814863103e-06, 'epoch': 0.08}\n",
      "{'eval_loss': 0.4690713882446289, 'eval_accuracy': 0.8217014773306164, 'eval_runtime': 19.0461, 'eval_samples_per_second': 515.328, 'eval_steps_per_second': 8.086, 'epoch': 0.08}\n",
      "{'loss': 0.4984, 'learning_rate': 8.372718383311604e-06, 'epoch': 0.16}\n",
      "{'eval_loss': 0.4219346344470978, 'eval_accuracy': 0.835048395313296, 'eval_runtime': 18.9872, 'eval_samples_per_second': 516.928, 'eval_steps_per_second': 8.111, 'epoch': 0.16}\n",
      "{'loss': 0.4664, 'learning_rate': 7.558670143415907e-06, 'epoch': 0.24}\n",
      "{'eval_loss': 0.4248501658439636, 'eval_accuracy': 0.835048395313296, 'eval_runtime': 18.5315, 'eval_samples_per_second': 529.639, 'eval_steps_per_second': 8.31, 'epoch': 0.24}\n",
      "{'loss': 0.4471, 'learning_rate': 6.743807040417211e-06, 'epoch': 0.33}\n",
      "{'eval_loss': 0.3851495087146759, 'eval_accuracy': 0.853998981151299, 'eval_runtime': 18.5175, 'eval_samples_per_second': 530.039, 'eval_steps_per_second': 8.316, 'epoch': 0.33}\n",
      "{'loss': 0.4291, 'learning_rate': 5.9289439374185145e-06, 'epoch': 0.41}\n",
      "{'eval_loss': 0.3886096775531769, 'eval_accuracy': 0.8529801324503311, 'eval_runtime': 19.2048, 'eval_samples_per_second': 511.07, 'eval_steps_per_second': 8.019, 'epoch': 0.41}\n",
      "{'loss': 0.4198, 'learning_rate': 5.114080834419818e-06, 'epoch': 0.49}\n",
      "{'eval_loss': 0.3939703404903412, 'eval_accuracy': 0.8499235863474274, 'eval_runtime': 19.079, 'eval_samples_per_second': 514.44, 'eval_steps_per_second': 8.072, 'epoch': 0.49}\n",
      "{'loss': 0.417, 'learning_rate': 4.30003259452412e-06, 'epoch': 0.57}\n",
      "{'eval_loss': 0.36645272374153137, 'eval_accuracy': 0.8580743759551707, 'eval_runtime': 18.5783, 'eval_samples_per_second': 528.305, 'eval_steps_per_second': 8.289, 'epoch': 0.57}\n",
      "{'loss': 0.4117, 'learning_rate': 3.4851694915254244e-06, 'epoch': 0.65}\n",
      "{'eval_loss': 0.3587413430213928, 'eval_accuracy': 0.860825267447784, 'eval_runtime': 18.6272, 'eval_samples_per_second': 526.919, 'eval_steps_per_second': 8.267, 'epoch': 0.65}\n",
      "{'loss': 0.4014, 'learning_rate': 2.670306388526728e-06, 'epoch': 0.73}\n",
      "{'eval_loss': 0.3596762418746948, 'eval_accuracy': 0.8618441161487519, 'eval_runtime': 18.5056, 'eval_samples_per_second': 530.379, 'eval_steps_per_second': 8.322, 'epoch': 0.73}\n",
      "{'loss': 0.394, 'learning_rate': 1.8554432855280313e-06, 'epoch': 0.81}\n",
      "{'eval_loss': 0.35547441244125366, 'eval_accuracy': 0.8645950076413652, 'eval_runtime': 18.5169, 'eval_samples_per_second': 530.056, 'eval_steps_per_second': 8.317, 'epoch': 0.81}\n",
      "{'loss': 0.3967, 'learning_rate': 1.0422099087353325e-06, 'epoch': 0.9}\n",
      "{'eval_loss': 0.350873202085495, 'eval_accuracy': 0.8677534386143657, 'eval_runtime': 18.5202, 'eval_samples_per_second': 529.963, 'eval_steps_per_second': 8.315, 'epoch': 0.9}\n",
      "{'loss': 0.3971, 'learning_rate': 2.2734680573663624e-07, 'epoch': 0.98}\n",
      "{'eval_loss': 0.350557416677475, 'eval_accuracy': 0.866225165562914, 'eval_runtime': 18.4974, 'eval_samples_per_second': 530.616, 'eval_steps_per_second': 8.326, 'epoch': 0.98}\n",
      "{'train_runtime': 2679.9953, 'train_samples_per_second': 146.531, 'train_steps_per_second': 4.579, 'train_loss': 0.44397361524101964, 'epoch': 1.0}\n",
      "{'eval_loss': 0.350873202085495, 'eval_accuracy': 0.8677534386143657, 'eval_runtime': 18.5374, 'eval_samples_per_second': 529.471, 'eval_steps_per_second': 8.308, 'epoch': 1.0}\n",
      "{'eval_loss': 0.350873202085495, 'eval_accuracy': 0.8677534386143657, 'eval_runtime': 18.5374, 'eval_samples_per_second': 529.471, 'eval_steps_per_second': 8.308, 'epoch': 1.0}\n"
     ]
    }
   ],
   "source": [
    "model_roberta: PreTrainedModel = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, num_labels=num_labels\n",
    ")\n",
    "model_roberta = model_roberta.cuda()\n",
    "\n",
    "args.learning_rate = 1e-5\n",
    "\n",
    "trainer = Trainer(\n",
    "    model_roberta,\n",
    "    args,\n",
    "    train_dataset=encoded_dataset[\"train\"],\n",
    "    eval_dataset=encoded_dataset[validation_key],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "transformers.logging.set_verbosity_error()\n",
    "trainer.train()\n",
    "print(trainer.evaluate())\n",
    "# {'eval_loss': 0.3559744358062744, 'eval_accuracy': 0.8655119714722364, 'eval_runtime': 19.6678, 'eval_samples_per_second': 499.04, 'eval_steps_per_second': 7.83, 'epoch': 0.98}\n",
    "trainer.save_model(\"roberta-baseline\")\n",
    "del model_roberta\n",
    "del trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To finish, we will measure vanilla Pytorch inference on both FP32 and FP16 precision, it will be our baseline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pytorch (FP32)] mean=79.48ms, sd=0.84ms, min=78.64ms, max=82.72ms, median=79.26ms, 95p=81.66ms, 99p=82.47ms\n"
     ]
    }
   ],
   "source": [
    "baseline_model = AutoModelForSequenceClassification.from_pretrained(\"roberta-baseline\", num_labels=num_labels)\n",
    "baseline_model = baseline_model.cuda()\n",
    "baseline_model = baseline_model.eval()\n",
    "\n",
    "data = encoded_dataset[\"train\"][0:batch_size]\n",
    "input_torch: OD[str, torch.Tensor] = convert_tensor(data=data, output=\"torch\")\n",
    "\n",
    "with torch.inference_mode():\n",
    "    for _ in range(30):\n",
    "        _ = baseline_model(**input_torch)\n",
    "        torch.cuda.synchronize()\n",
    "    time_buffer = list()\n",
    "    for _ in range(100):\n",
    "        with track_infer_time(time_buffer):\n",
    "            _ = baseline_model(**input_torch)\n",
    "            torch.cuda.synchronize()\n",
    "print_timings(name=\"Pytorch (FP32)\", timings=time_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pytorch (FP16)] mean=58.02ms, sd=0.59ms, min=57.46ms, max=60.90ms, median=57.80ms, 95p=59.52ms, 99p=60.49ms\n"
     ]
    }
   ],
   "source": [
    "with torch.inference_mode():\n",
    "    with torch.cuda.amp.autocast():\n",
    "        for _ in range(30):\n",
    "            _ = baseline_model(**input_torch)\n",
    "            torch.cuda.synchronize()\n",
    "        time_buffer = []\n",
    "        for _ in range(100):\n",
    "            with track_infer_time(time_buffer):\n",
    "                _ = baseline_model(**input_torch)\n",
    "                torch.cuda.synchronize()\n",
    "print_timings(name=\"Pytorch (FP16)\", timings=time_buffer)\n",
    "del baseline_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPU execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pytorch (FP32) - CPU] mean=3999.80ms, sd=27.86ms, min=3946.75ms, max=4042.56ms, median=4000.13ms, 95p=4037.90ms, 99p=4041.63ms\n"
     ]
    }
   ],
   "source": [
    "baseline_model = AutoModelForSequenceClassification.from_pretrained(\"roberta-baseline\", num_labels=num_labels)\n",
    "baseline_model = baseline_model.eval()\n",
    "data = encoded_dataset[\"train\"][0:batch_size]\n",
    "input_torch: OD[str, torch.Tensor] = convert_tensor(data=data, output=\"torch\")\n",
    "input_torch_cpu = {k: v.to(\"cpu\") for k, v in input_torch.items()}\n",
    "\n",
    "import os\n",
    "torch.set_num_threads(os.cpu_count())\n",
    "\n",
    "with torch.inference_mode():\n",
    "    for _ in range(3):\n",
    "        _ = baseline_model(**input_torch_cpu)\n",
    "        torch.cuda.synchronize()\n",
    "    time_buffer = list()\n",
    "    for _ in range(10):\n",
    "        with track_infer_time(time_buffer):\n",
    "            _ = baseline_model(**input_torch_cpu)\n",
    "            torch.cuda.synchronize()\n",
    "print_timings(name=\"Pytorch (FP32) - CPU\", timings=time_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pytorch (FP16) - CPU] mean=4005.57ms, sd=46.34ms, min=3922.37ms, max=4095.30ms, median=4010.20ms, 95p=4071.75ms, 99p=4090.59ms\n"
     ]
    }
   ],
   "source": [
    "with torch.inference_mode():\n",
    "    with torch.cuda.amp.autocast():\n",
    "        for _ in range(3):\n",
    "            _ = baseline_model(**input_torch_cpu)\n",
    "            torch.cuda.synchronize()\n",
    "        time_buffer = []\n",
    "        for _ in range(10):\n",
    "            with track_infer_time(time_buffer):\n",
    "                _ = baseline_model(**input_torch_cpu)\n",
    "                torch.cuda.synchronize()\n",
    "print_timings(name=\"Pytorch (FP16) - CPU\", timings=time_buffer)\n",
    "del baseline_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we will perform dynamic quantization on CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pytorch (INT-8) - CPU] mean=3669.84ms, sd=25.49ms, min=3633.48ms, max=3712.22ms, median=3670.07ms, 95p=3706.98ms, 99p=3711.17ms\n"
     ]
    }
   ],
   "source": [
    "quantized_baseline_model = AutoModelForSequenceClassification.from_pretrained(\"roberta-baseline\", num_labels=num_labels)\n",
    "quantized_baseline_model = quantized_baseline_model.eval()\n",
    "quantized_baseline_model = torch.quantization.quantize_dynamic(quantized_baseline_model, {torch.nn.Linear}, dtype=torch.qint8)\n",
    "\n",
    "with torch.inference_mode():\n",
    "    for _ in range(3):\n",
    "        _ = quantized_baseline_model(**input_torch_cpu)\n",
    "        torch.cuda.synchronize()\n",
    "    time_buffer = list()\n",
    "    for _ in range(10):\n",
    "        with track_infer_time(time_buffer):\n",
    "            _ = quantized_baseline_model(**input_torch_cpu)\n",
    "            torch.cuda.synchronize()\n",
    "print_timings(name=\"Pytorch (INT-8) - CPU\", timings=time_buffer)\n",
    "del quantized_baseline_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorRT baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we export a randomly initialized `Roberta` model, the purpose is to only check the performance on mixed precision (FP16, no quantization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "baseline_model = AutoModelForSequenceClassification.from_pretrained(\"roberta-baseline\", num_labels=num_labels)\n",
    "baseline_model = baseline_model.cuda()\n",
    "convert_to_onnx(baseline_model, output_path=\"baseline.onnx\", inputs_pytorch=input_torch, opset=12)\n",
    "del baseline_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TensorRT (FP16)] mean=30.23ms, sd=0.49ms, min=29.73ms, max=32.67ms, median=30.06ms, 95p=30.82ms, 99p=32.38ms\n"
     ]
    }
   ],
   "source": [
    "engine = build_engine(\n",
    "    runtime=runtime,\n",
    "    onnx_file_path=\"baseline.onnx\",\n",
    "    logger=trt_logger,\n",
    "    min_shape=(batch_size, max_seq_len),\n",
    "    optimal_shape=(batch_size, max_seq_len),\n",
    "    max_shape=(batch_size, max_seq_len),\n",
    "    workspace_size=10000 * 1024 * 1024,\n",
    "    fp16=True,\n",
    "    int8=False,\n",
    ")\n",
    "stream: Stream = pycuda.driver.Stream()\n",
    "context: IExecutionContext = engine.create_execution_context()\n",
    "context.set_optimization_profile_async(profile_index=profile_index, stream_handle=stream.handle)\n",
    "input_binding_idxs, output_binding_idxs = get_binding_idxs(engine, profile_index)  # type: List[int], List[int]\n",
    "for _ in range(30):\n",
    "    _ = infer_tensorrt(\n",
    "        context=context,\n",
    "        host_inputs=input_np,\n",
    "        input_binding_idxs=input_binding_idxs,\n",
    "        output_binding_idxs=output_binding_idxs,\n",
    "        stream=stream,\n",
    "    )\n",
    "time_buffer = list()\n",
    "for _ in range(100):\n",
    "    with track_infer_time(time_buffer):\n",
    "        _ = infer_tensorrt(\n",
    "            context=context,\n",
    "            host_inputs=input_np,\n",
    "            input_binding_idxs=input_binding_idxs,\n",
    "            output_binding_idxs=output_binding_idxs,\n",
    "            stream=stream,\n",
    "        )\n",
    "\n",
    "print_timings(name=\"TensorRT (FP16)\", timings=time_buffer)\n",
    "del engine, context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ONNX Runtime baseline\n",
    "\n",
    "ONNX Runtime is the go to inference solution from Microsoft.\n",
    "\n",
    "The recent 1.10 version of ONNX Runtime (with TensorRT support) is still a bit buggy on transformer models, that is why we use the 1.9.0 version in the measures below.\n",
    "\n",
    "As before, CPU quantization is dynamic.\n",
    "Function `create_model_for_provider` will set ONNX Runtime to use all cores available and enable any possible optimizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Unsupported operator Attention. No schema registered for this operator.\n",
      "Warning: Unsupported operator SkipLayerNormalization. No schema registered for this operator.\n",
      "Warning: Unsupported operator SkipLayerNormalization. No schema registered for this operator.\n",
      "Warning: Unsupported operator Attention. No schema registered for this operator.\n",
      "Warning: Unsupported operator SkipLayerNormalization. No schema registered for this operator.\n",
      "Warning: Unsupported operator SkipLayerNormalization. No schema registered for this operator.\n",
      "Warning: Unsupported operator Attention. No schema registered for this operator.\n",
      "Warning: Unsupported operator SkipLayerNormalization. No schema registered for this operator.\n",
      "Warning: Unsupported operator SkipLayerNormalization. No schema registered for this operator.\n",
      "Warning: Unsupported operator Attention. No schema registered for this operator.\n",
      "Warning: Unsupported operator SkipLayerNormalization. No schema registered for this operator.\n",
      "Warning: Unsupported operator SkipLayerNormalization. No schema registered for this operator.\n",
      "Warning: Unsupported operator Attention. No schema registered for this operator.\n",
      "Warning: Unsupported operator SkipLayerNormalization. No schema registered for this operator.\n",
      "Warning: Unsupported operator SkipLayerNormalization. No schema registered for this operator.\n",
      "Warning: Unsupported operator Attention. No schema registered for this operator.\n",
      "Warning: Unsupported operator SkipLayerNormalization. No schema registered for this operator.\n",
      "Warning: Unsupported operator SkipLayerNormalization. No schema registered for this operator.\n",
      "Warning: Unsupported operator Attention. No schema registered for this operator.\n",
      "Warning: Unsupported operator SkipLayerNormalization. No schema registered for this operator.\n",
      "Warning: Unsupported operator SkipLayerNormalization. No schema registered for this operator.\n",
      "Warning: Unsupported operator Attention. No schema registered for this operator.\n",
      "Warning: Unsupported operator SkipLayerNormalization. No schema registered for this operator.\n",
      "Warning: Unsupported operator SkipLayerNormalization. No schema registered for this operator.\n",
      "Warning: Unsupported operator Attention. No schema registered for this operator.\n",
      "Warning: Unsupported operator SkipLayerNormalization. No schema registered for this operator.\n",
      "Warning: Unsupported operator SkipLayerNormalization. No schema registered for this operator.\n",
      "Warning: Unsupported operator Attention. No schema registered for this operator.\n",
      "Warning: Unsupported operator SkipLayerNormalization. No schema registered for this operator.\n",
      "Warning: Unsupported operator SkipLayerNormalization. No schema registered for this operator.\n",
      "Warning: Unsupported operator Attention. No schema registered for this operator.\n",
      "Warning: Unsupported operator SkipLayerNormalization. No schema registered for this operator.\n",
      "Warning: Unsupported operator SkipLayerNormalization. No schema registered for this operator.\n",
      "Warning: Unsupported operator Attention. No schema registered for this operator.\n",
      "Warning: Unsupported operator SkipLayerNormalization. No schema registered for this operator.\n",
      "Warning: Unsupported operator SkipLayerNormalization. No schema registered for this operator.\n"
     ]
    }
   ],
   "source": [
    "from transformer_deploy.backends.ort_utils import optimize_onnx, create_model_for_provider\n",
    "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
    "\n",
    "optimize_onnx(\n",
    "    onnx_path=\"baseline.onnx\",\n",
    "    onnx_optim_fp16_path=\"baseline-optimized.onnx\",\n",
    "    use_cuda=True,\n",
    ")\n",
    "onnx_model = create_model_for_provider(path=\"baseline-optimized.onnx\", provider_to_use=\"CUDAExecutionProvider\")\n",
    "quantize_dynamic(\"baseline-optimized.onnx\", \"baseline-quantized.onnx\", weight_type=QuantType.QUInt8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [item['label'] for item in encoded_dataset[validation_key]]\n",
    "data = encoded_dataset[validation_key][0:batch_size]\n",
    "inputs_onnx: OD[str, np.ndarray] = convert_tensor(data=data, output=\"np\")\n",
    "for k, v in inputs_onnx.items():\n",
    "    inputs_onnx[k] = v.astype(np.int64)\n",
    "\n",
    "model = create_model_for_provider(path=\"baseline-optimized.onnx\", provider_to_use=\"CUDAExecutionProvider\")\n",
    "output = model.run(None, inputs_onnx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ONNX Runtime GPU (FP32)] mean=74.48ms, sd=0.55ms, min=73.87ms, max=76.61ms, median=74.36ms, 95p=75.89ms, 99p=76.34ms\n",
      "[ONNX Runtime GPU (FP16)] mean=33.50ms, sd=0.62ms, min=32.90ms, max=37.58ms, median=33.39ms, 95p=34.42ms, 99p=35.47ms\n",
      "[ONNX Runtime CPU (FP32)] mean=3767.02ms, sd=32.02ms, min=3720.72ms, max=3831.88ms, median=3766.35ms, 95p=3816.04ms, 99p=3828.71ms\n",
      "[ONNX Runtime CPU (FP16)] mean=4607.67ms, sd=121.41ms, min=4513.24ms, max=4950.20ms, median=4573.18ms, 95p=4822.23ms, 99p=4924.61ms\n",
      "[ONNX Runtime CPU (INT-8)] mean=3712.67ms, sd=45.19ms, min=3656.30ms, max=3827.99ms, median=3709.21ms, 95p=3788.00ms, 99p=3819.99ms\n"
     ]
    }
   ],
   "source": [
    "data = encoded_dataset[\"train\"][0:batch_size]\n",
    "inputs_onnx: OD[str, np.ndarray] = convert_tensor(data=data, output=\"np\")\n",
    "for k, v in inputs_onnx.items():\n",
    "    inputs_onnx[k] = v.astype(np.int64)\n",
    "\n",
    "for provider, model_path, benchmark_name, warmup, nb_inference in [\n",
    "    (\"CUDAExecutionProvider\", \"baseline.onnx\", \"ONNX Runtime GPU (FP32)\", 10, 100),\n",
    "    (\"CUDAExecutionProvider\", \"baseline-optimized.onnx\", \"ONNX Runtime GPU (FP16)\", 10, 100),\n",
    "    (\"CPUExecutionProvider\", \"baseline.onnx\", \"ONNX Runtime CPU (FP32)\", 3, 10),\n",
    "    (\"CPUExecutionProvider\", \"baseline-optimized.onnx\", \"ONNX Runtime CPU (FP16)\", 3, 10),\n",
    "    (\"CPUExecutionProvider\", \"baseline-quantized.onnx\", \"ONNX Runtime CPU (INT-8)\", 3, 10),\n",
    "]:\n",
    "    model = create_model_for_provider(path=model_path, provider_to_use=provider)\n",
    "    for _ in range(warmup):\n",
    "        _ = model.run(None, inputs_onnx)\n",
    "    time_buffer = []\n",
    "    for _ in range(nb_inference):\n",
    "        with track_infer_time(time_buffer):\n",
    "            _ = model.run(None, inputs_onnx)\n",
    "    print_timings(name=benchmark_name, timings=time_buffer)\n",
    "    del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measure of the accuracy with ONNX Runtime engine and CUDA provider:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee60729e561d492f82a7db2c93fc44ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/307 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8678553234844626"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_model_for_provider(path=\"baseline.onnx\", provider_to_use=\"CUDAExecutionProvider\")\n",
    "infer_ort = lambda tokens: model.run(None, tokens)\n",
    "measure_accuracy(infer=infer_ort, int64=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c78489324dc4d8f9206543d59061f9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/307 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8675496688741722"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_model_for_provider(path=\"baseline-optimized.onnx\", provider_to_use=\"CUDAExecutionProvider\")\n",
    "infer_ort = lambda tokens: model.run(None, tokens)\n",
    "measure_accuracy(infer=infer_ort, int64=True)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "whPRbBNbIrIl",
    "n9qywopnIrJH",
    "7k8ge1L1IrJk"
   ],
   "name": "Copie de Text Classification on GLUE",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0022faf286b44e858e638ccd5ded38b0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "023900ca566446eab5905b25b16a3de7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "08286a6371584b4186014ecb5d5f164d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2d3a08166846438db79b0f89314fe76a",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_d1ecc3d380fc4758b03190b23686a2f1",
      "value": " 481/481 [00:00&lt;00:00, 10.9kB/s]"
     }
    },
    "092db03992f24951b494fbb81da5b9d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_994cf2338c7c4899952e25723445693c",
       "IPY_MODEL_6aa2f5d46f1f454198d8e69517549ff1",
       "IPY_MODEL_72b8f11065254e5ca488cd346b5add54"
      ],
      "layout": "IPY_MODEL_023900ca566446eab5905b25b16a3de7"
     }
    },
    "0dab554959dc44b3b313ee8ae91ca88d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e1f08cf954ae4aea818c90d893486c77",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_f01fdef82047471e8c1b780cae5379cc",
      "value": " 420M/420M [00:13&lt;00:00, 33.6MB/s]"
     }
    },
    "10678736bd534c63aebda414da01b4db": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "14648b8262944f5faac134a7c0184e47": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "154200a8bc0b44fe8d0419fd56c6539d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "15aae23369674f82888ed9fbd99739f2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "163146c2f23440bcbf782116a35b5684": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cf9597523c024514b9b3e66bc77e3fa8",
      "max": 440473133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cced5f1cccc2400a8fbfd7a6eaedc666",
      "value": 440473133
     }
    },
    "167874df55014291be95cd390b1e60d3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "17b83e0d0fb947d7bf20319ff930e8fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_854cfd13416543fba8221093b903658b",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_cbbb20b5d01a4450bfb8dfbf8048d64f",
      "value": "Downloading: 100%"
     }
    },
    "17bd5357081d41c6b0161d63bd00820a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "196ffc99ad5a40109d9b1cfe12032b62": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1bea379404df429b9852b62a938661ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a4c444f06c0847c09a44917084d3908d",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_300f01e3547648f3983a83d3d3118c54",
      "value": 1
     }
    },
    "1da1d80871f545bbb21bf5a84d2120a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8585eab4b3fe4992bd7e7c4596e2483b",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7ec6da801d0d45c4bb80eeab5518e124",
      "value": 570
     }
    },
    "21ef195fa88f49c4a2c057f8028177a2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "26bc2038bed74279813ab5af09a2724c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0022faf286b44e858e638ccd5ded38b0",
      "max": 456318,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7ff32d18c9f0473893a6a6b2941c54b0",
      "value": 456318
     }
    },
    "28b7346a9b8c4b198dd9dbea1be013b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2d3a08166846438db79b0f89314fe76a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2eac6b4817e14d7fae396e6458b940fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_927ad6ade85a402594074fa90ab558c2",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_cae29b9c6d45412fab70977fcd0f3234",
      "value": "Downloading: 100%"
     }
    },
    "300f01e3547648f3983a83d3d3118c54": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "30646fa2c0dc494e9dbcbd4dc598410e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "360d6eb0e41543dba6d457912e32a77d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "37cda4cae81a4d94aa831fb40b5c3b26": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_56fd7584b0844590936519ec3851922e",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_5b1ad9f5d02c4b298a02ce6041692057",
      "value": " 4/4 [00:00&lt;00:00,  5.97ba/s]"
     }
    },
    "3bfff454943b4b04a12ec29bbe28e0aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cedca6e55b84443e82f3d01471d61048",
       "IPY_MODEL_a7d355f456eb4d3995dd91c5917a72c1",
       "IPY_MODEL_b264b220d9c444bd9da46a7e6c8fd5ed"
      ],
      "layout": "IPY_MODEL_154200a8bc0b44fe8d0419fd56c6539d"
     }
    },
    "3e7fbd1c0e534cb8abca18d1edfc9277": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4320b12de9d14c459cc88319e2d7622a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4552ee8ca6bd4a0b956651cc23f4ff3c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4b13c3b3435f4689b29d48e0a35bebd6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4e91efae49b64f038fd3fbfcfd2be510": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4fae966b76844c869cdea1e53891e26f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "54c0ad5ab737433190c4a824be128a48": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "561b1ede331a40c1a2bff9422e8eea0e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "56fd7584b0844590936519ec3851922e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "59418bbeb20547e5b5e1a5728262c757": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5b1ad9f5d02c4b298a02ce6041692057": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5e2185bd6e4f4a10b89ac606868a43bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2eac6b4817e14d7fae396e6458b940fa",
       "IPY_MODEL_af16284f77594397a69ad0e322b5e736",
       "IPY_MODEL_a20579a9e7364fb485d79bdc4feb54dc"
      ],
      "layout": "IPY_MODEL_f44d2beebfe44186b0ac8016e89e4b49"
     }
    },
    "5f032f56105f463a8680aa2482d0b162": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "65017db07d7f4e798ede741cc92488f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_86cc326e574a4fada7224e6f0c209e9a",
       "IPY_MODEL_af5b646f89024c139c695a1f058fb772",
       "IPY_MODEL_37cda4cae81a4d94aa831fb40b5c3b26"
      ],
      "layout": "IPY_MODEL_6fa74604c68543a38392fa0e1587f707"
     }
    },
    "68c4c867096d41a78740fdee30edcadb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6aa2f5d46f1f454198d8e69517549ff1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7b483d17d1d14fdd922600f0c906fc2f",
      "max": 1355863,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4320b12de9d14c459cc88319e2d7622a",
      "value": 1355863
     }
    },
    "6d48e5ce9a854a3bb0506d774665f428": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fbdb7c7250d846b2880005a9012c484b",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_17bd5357081d41c6b0161d63bd00820a",
      "value": " 478M/478M [00:15&lt;00:00, 34.7MB/s]"
     }
    },
    "6e54ce781ca54ad283911fa4774e3361": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6e604307427a466cab51d50d363ee86d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6fa74604c68543a38392fa0e1587f707": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "728a9dcc79824e1eb2bfa49d915a8f08": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d314c0bb87e04893b96de0e18766d3ab",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_fa35b3acd9ce4cb098fcd69bb405db00",
      "value": "Downloading: 100%"
     }
    },
    "72b8f11065254e5ca488cd346b5add54": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_10678736bd534c63aebda414da01b4db",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_14648b8262944f5faac134a7c0184e47",
      "value": " 1.29M/1.29M [00:00&lt;00:00, 2.22MB/s]"
     }
    },
    "7701ec898fd443f1b35b187aea3651e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "78601982b0e04b80adaa502db2ef685a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d6426fea2eda41dd9a31cb3f35b0877e",
       "IPY_MODEL_163146c2f23440bcbf782116a35b5684",
       "IPY_MODEL_0dab554959dc44b3b313ee8ae91ca88d"
      ],
      "layout": "IPY_MODEL_167874df55014291be95cd390b1e60d3"
     }
    },
    "788badadfd834f61926a39a43ef1d517": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7a75099f99054645bf3fc1b778dac7e6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7b483d17d1d14fdd922600f0c906fc2f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7bb3b69a2f814e60b0cec253c759a16b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d731cfb34124448bbd8baab3d27b75db",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_cbb3e9bf5d07406d9768a98a6f0b5b64",
      "value": "100%"
     }
    },
    "7c875ecd9cb54405a6c45969bcb4b4c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7d520bdde27742abb42803843721d101": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7ec6da801d0d45c4bb80eeab5518e124": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7ff32d18c9f0473893a6a6b2941c54b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8399339998564d21ba5db6f0514c02c6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "854cfd13416543fba8221093b903658b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8585eab4b3fe4992bd7e7c4596e2483b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "86cc326e574a4fada7224e6f0c209e9a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_561b1ede331a40c1a2bff9422e8eea0e",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_28b7346a9b8c4b198dd9dbea1be013b6",
      "value": "100%"
     }
    },
    "87d85ac2d3104f68b99db880b1089638": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_728a9dcc79824e1eb2bfa49d915a8f08",
       "IPY_MODEL_c815bfd265f4480298c39c76b9eaf770",
       "IPY_MODEL_6d48e5ce9a854a3bb0506d774665f428"
      ],
      "layout": "IPY_MODEL_6e604307427a466cab51d50d363ee86d"
     }
    },
    "8a11c8fed672470b8335dc575a4a220e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_93dbcc6d23a743bab0da8af6ee5e2825",
      "max": 481,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f8a0053903c64e75ac25eab5b24d5871",
      "value": 481
     }
    },
    "8defdddee0e64a20b101e6c50bd7c60b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7bb3b69a2f814e60b0cec253c759a16b",
       "IPY_MODEL_d25cca081db3469b80163d6707f5a37d",
       "IPY_MODEL_f8abc3e44ae3428885aafbea2b37384c"
      ],
      "layout": "IPY_MODEL_f485d2b19ffa4585a1da20986f28af29"
     }
    },
    "927ad6ade85a402594074fa90ab558c2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "93dbcc6d23a743bab0da8af6ee5e2825": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "969b6fdac1d6418d89a683db1e6ec6b2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "990482eebca2424bb5ecbd114007e02c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "994cf2338c7c4899952e25723445693c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d9a0852554284d36b6b121f579b06b41",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_c7bd52ef524c4d279dfcaa3aebe4a2c5",
      "value": "Downloading: 100%"
     }
    },
    "99e94791043b4499b06601f7524f9b14": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d5c8ff9e3bd849059fa7b30eab5fc940",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_196ffc99ad5a40109d9b1cfe12032b62",
      "value": "Downloading: 100%"
     }
    },
    "9bc6e14b912249e3b7d02f31bcc74667": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_969b6fdac1d6418d89a683db1e6ec6b2",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_6e54ce781ca54ad283911fa4774e3361",
      "value": " 446k/446k [00:00&lt;00:00, 650kB/s]"
     }
    },
    "a02624219ee84f50b1a3032eaa030a39": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a0a2918e9772475cac51124b3b83fcaf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a20579a9e7364fb485d79bdc4feb54dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4b13c3b3435f4689b29d48e0a35bebd6",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_d5d015711ae04d2f801577fc50af6c15",
      "value": " 878k/878k [00:00&lt;00:00, 1.33MB/s]"
     }
    },
    "a3e2c73d393d4e58a371f3da3dd80e6d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a4c444f06c0847c09a44917084d3908d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a51b461c062f4636bfa4b48823d0709b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a61d366d91c34697a55f62b754e1f3a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a9b98fd93fcd4fc4a2b2aa88c82835d0",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_b8722dc10d4447fe9630cbf169260cc8",
      "value": "100%"
     }
    },
    "a7d355f456eb4d3995dd91c5917a72c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5f032f56105f463a8680aa2482d0b162",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a02624219ee84f50b1a3032eaa030a39",
      "value": 2
     }
    },
    "a9b98fd93fcd4fc4a2b2aa88c82835d0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ac14ba24dcf3404db9fd303dbb24d7a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_17b83e0d0fb947d7bf20319ff930e8fc",
       "IPY_MODEL_1da1d80871f545bbb21bf5a84d2120a0",
       "IPY_MODEL_c593f2e45e244637821cc5721788bf2c"
      ],
      "layout": "IPY_MODEL_4e91efae49b64f038fd3fbfcfd2be510"
     }
    },
    "aecf7f063234416abf3f24766481cb89": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "af16284f77594397a69ad0e322b5e736": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7a75099f99054645bf3fc1b778dac7e6",
      "max": 898823,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_30646fa2c0dc494e9dbcbd4dc598410e",
      "value": 898823
     }
    },
    "af5b646f89024c139c695a1f058fb772": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_21ef195fa88f49c4a2c057f8028177a2",
      "max": 4,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_aecf7f063234416abf3f24766481cb89",
      "value": 4
     }
    },
    "b264b220d9c444bd9da46a7e6c8fd5ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8399339998564d21ba5db6f0514c02c6",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_7701ec898fd443f1b35b187aea3651e9",
      "value": " 2/2 [00:00&lt;00:00,  6.46ba/s]"
     }
    },
    "b4d3f284fc4c4061b58d43a738f9bc78": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7d520bdde27742abb42803843721d101",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_68c4c867096d41a78740fdee30edcadb",
      "value": "Downloading: 100%"
     }
    },
    "b6be028de2ae4ff691538eedb33793af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b4d3f284fc4c4061b58d43a738f9bc78",
       "IPY_MODEL_8a11c8fed672470b8335dc575a4a220e",
       "IPY_MODEL_08286a6371584b4186014ecb5d5f164d"
      ],
      "layout": "IPY_MODEL_a3e2c73d393d4e58a371f3da3dd80e6d"
     }
    },
    "b8722dc10d4447fe9630cbf169260cc8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bbe3a471efb04ea8b5aabc4be819d585": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a61d366d91c34697a55f62b754e1f3a5",
       "IPY_MODEL_1bea379404df429b9852b62a938661ae",
       "IPY_MODEL_c801e1727de44b67aa7cb1c3d970e1fe"
      ],
      "layout": "IPY_MODEL_59418bbeb20547e5b5e1a5728262c757"
     }
    },
    "be4affe852b348de8fe1362582b08da9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_99e94791043b4499b06601f7524f9b14",
       "IPY_MODEL_26bc2038bed74279813ab5af09a2724c",
       "IPY_MODEL_9bc6e14b912249e3b7d02f31bcc74667"
      ],
      "layout": "IPY_MODEL_c6c100b71f26405fb960598feb5eee03"
     }
    },
    "c593f2e45e244637821cc5721788bf2c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c92a19dfa84142af91522bc22f21fca6",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_990482eebca2424bb5ecbd114007e02c",
      "value": " 570/570 [00:00&lt;00:00, 13.1kB/s]"
     }
    },
    "c6c100b71f26405fb960598feb5eee03": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c7bd52ef524c4d279dfcaa3aebe4a2c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c801e1727de44b67aa7cb1c3d970e1fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4552ee8ca6bd4a0b956651cc23f4ff3c",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_7c875ecd9cb54405a6c45969bcb4b4c6",
      "value": " 1/1 [00:00&lt;00:00,  7.22ba/s]"
     }
    },
    "c815bfd265f4480298c39c76b9eaf770": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_15aae23369674f82888ed9fbd99739f2",
      "max": 501200538,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3e7fbd1c0e534cb8abca18d1edfc9277",
      "value": 501200538
     }
    },
    "c92a19dfa84142af91522bc22f21fca6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cae29b9c6d45412fab70977fcd0f3234": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cbb3e9bf5d07406d9768a98a6f0b5b64": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cbbb20b5d01a4450bfb8dfbf8048d64f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cced5f1cccc2400a8fbfd7a6eaedc666": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cedca6e55b84443e82f3d01471d61048": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a0a2918e9772475cac51124b3b83fcaf",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_4fae966b76844c869cdea1e53891e26f",
      "value": "100%"
     }
    },
    "cf9597523c024514b9b3e66bc77e3fa8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d1ecc3d380fc4758b03190b23686a2f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d25cca081db3469b80163d6707f5a37d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_360d6eb0e41543dba6d457912e32a77d",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_788badadfd834f61926a39a43ef1d517",
      "value": 3
     }
    },
    "d314c0bb87e04893b96de0e18766d3ab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d5c8ff9e3bd849059fa7b30eab5fc940": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d5d015711ae04d2f801577fc50af6c15": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d6426fea2eda41dd9a31cb3f35b0877e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a51b461c062f4636bfa4b48823d0709b",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_f651eecbb6d44c24820cf6fe5ab92e7b",
      "value": "Downloading: 100%"
     }
    },
    "d731cfb34124448bbd8baab3d27b75db": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d9a0852554284d36b6b121f579b06b41": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e1f08cf954ae4aea818c90d893486c77": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f01fdef82047471e8c1b780cae5379cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f237ed04039945e9aa224d1b9d04e1b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f44d2beebfe44186b0ac8016e89e4b49": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f485d2b19ffa4585a1da20986f28af29": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f651eecbb6d44c24820cf6fe5ab92e7b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f8a0053903c64e75ac25eab5b24d5871": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f8abc3e44ae3428885aafbea2b37384c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_54c0ad5ab737433190c4a824be128a48",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_f237ed04039945e9aa224d1b9d04e1b5",
      "value": " 3/3 [00:00&lt;00:00, 52.79it/s]"
     }
    },
    "fa35b3acd9ce4cb098fcd69bb405db00": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fbdb7c7250d846b2880005a9012c484b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}