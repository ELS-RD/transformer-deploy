{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from time import time\n",
    "from typing import Callable, Dict, Set\n",
    "\n",
    "import numpy as np\n",
    "import onnx\n",
    "import tensorrt as trt\n",
    "import torch\n",
    "from onnx import ModelProto\n",
    "from tensorrt import ICudaEngine\n",
    "from tensorrt.tensorrt import Logger, Runtime\n",
    "from torch.nn import Linear\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, PretrainedConfig, T5ForConditionalGeneration, TensorType\n",
    "from transformers.generation_utils import GenerationMixin\n",
    "from transformers.modeling_outputs import BaseModelOutputWithPastAndCrossAttentions, Seq2SeqLMOutput\n",
    "from transformers.models.t5.modeling_t5 import T5Stack\n",
    "\n",
    "from transformer_deploy.backends.ort_utils import create_model_for_provider, inference_onnx_binding, optimize_onnx\n",
    "from transformer_deploy.backends.pytorch_utils import convert_to_onnx\n",
    "from transformer_deploy.backends.trt_utils import (\n",
    "    TensorRTShape,\n",
    "    add_output_nodes,\n",
    "    build_engine,\n",
    "    get_adjency_dict,\n",
    "    get_fix_fp16_network_func,\n",
    "    get_list_fp32_nodes,\n",
    "    load_engine,\n",
    "    save_engine,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "model_name = \"t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "input_ids: torch.Tensor = tokenizer(\"Studies show that\", return_tensors=TensorType.PYTORCH).input_ids\n",
    "input_ids = input_ids.to(\"cuda\")\n",
    "model: T5ForConditionalGeneration = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "model = model.eval()\n",
    "model = model.to(\"cuda\")\n",
    "out_enc: BaseModelOutputWithPastAndCrossAttentions = model.encoder(input_ids=input_ids)\n",
    "out_full: Seq2SeqLMOutput = model(input_ids=input_ids, decoder_input_ids=input_ids)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class ExportT5(torch.nn.Module):\n",
    "    def __init__(self, decoder: T5Stack, lm_head: Linear):\n",
    "        super(ExportT5, self).__init__()\n",
    "        self.decoder = decoder\n",
    "        self.lm_head = lm_head\n",
    "\n",
    "    def forward(self, input_ids: torch.Tensor, encoder_hidden_states: torch.Tensor):\n",
    "        out_dec = self.decoder.forward(input_ids=input_ids, encoder_hidden_states=encoder_hidden_states)\n",
    "        # Rescale output before projecting on vocab\n",
    "        out_dec = out_dec[\"last_hidden_state\"] * (model.model_dim**-0.5)\n",
    "        out_lm = self.lm_head(out_dec)\n",
    "        return out_lm\n",
    "\n",
    "model = model.to(\"cuda\")\n",
    "\n",
    "convert_to_onnx(\n",
    "    model_pytorch=model.encoder,\n",
    "    output_path=\"test-enc.onnx\",\n",
    "    inputs_pytorch={\"input_ids\": input_ids},\n",
    "    var_output_seq=True,\n",
    "    quantization=False,\n",
    ")\n",
    "optimize_onnx(\n",
    "    onnx_path=\"test-enc.onnx\", onnx_optim_model_path=\"test-enc-opt.onnx\", architecture=\"bert\", use_cuda=True, fp16=True\n",
    ")\n",
    "\n",
    "enc_onnx = create_model_for_provider(\"test-enc-opt.onnx\", \"CUDAExecutionProvider\")\n",
    "enc_onnx_out = inference_onnx_binding(\n",
    "    model_onnx=enc_onnx,\n",
    "    inputs={\"input_ids\": input_ids},\n",
    "    device=input_ids.device.type,\n",
    "    output_shape=tuple(input_ids.shape) + (int(model.encoder.config.d_model),),\n",
    ")[\"output\"]\n",
    "assert np.allclose(enc_onnx_out.detach().cpu().numpy(), out_enc.last_hidden_state.detach().cpu().numpy(), atol=1e-2)\n",
    "\n",
    "model_to_export = ExportT5(decoder=model.decoder, lm_head=model.lm_head).eval()\n",
    "out_model_export: torch.Tensor = model_to_export(input_ids=input_ids, encoder_hidden_states=out_enc.last_hidden_state)\n",
    "assert np.allclose(out_model_export.detach().cpu().numpy(), out_full.logits.detach().cpu().numpy(), atol=1e-5)\n",
    "\n",
    "inputs_onnx = OrderedDict({\"input_ids\": input_ids, \"encoder_hidden_states\": out_enc.last_hidden_state})\n",
    "\n",
    "convert_to_onnx(\n",
    "    model_pytorch=model_to_export,\n",
    "    output_path=\"test-dec.onnx\",\n",
    "    inputs_pytorch=inputs_onnx,\n",
    "    var_output_seq=False,\n",
    "    quantization=False,\n",
    "    fix_output_dim_size=False,  # specific to decoder part\n",
    ")\n",
    "optimize_onnx(\n",
    "    onnx_path=\"test-dec.onnx\",\n",
    "    onnx_optim_model_path=\"test-dec-opt.onnx\",\n",
    "    architecture=\"bert\",\n",
    "    use_cuda=True,\n",
    "    fp16=True,\n",
    "    num_attention_heads=model.config.num_heads,\n",
    "    hidden_size=model.config.d_model,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> Studien studies show that</s>\n",
      "<pad> Studien studies show that</s>\n",
      "10.57511854171753\n",
      "14.16351842880249\n"
     ]
    }
   ],
   "source": [
    "model = model.to(\"cuda\")\n",
    "enc_onnx = create_model_for_provider(\"test-enc-opt.onnx\", \"CUDAExecutionProvider\")\n",
    "dec_onnx = create_model_for_provider(\"test-dec-opt.onnx\", \"CUDAExecutionProvider\")\n",
    "\n",
    "\n",
    "def decoder_pytorch_inference(input_ids: torch.Tensor, last_hidden_state: torch.Tensor):\n",
    "    out_dec = model.decoder(input_ids=input_ids, encoder_hidden_states=last_hidden_state)[\"last_hidden_state\"]\n",
    "    # Rescale output before projecting on vocab\n",
    "    out_dec = out_dec * (model.model_dim**-0.5)\n",
    "    out_lm = model.lm_head(out_dec)\n",
    "    return out_lm\n",
    "\n",
    "\n",
    "def decoder_onnx_inference(input_ids: torch.Tensor, last_hidden_state: torch.Tensor):\n",
    "    result_dict = inference_onnx_binding(\n",
    "        model_onnx=dec_onnx,\n",
    "        inputs={\"input_ids\": input_ids, \"encoder_hidden_states\": last_hidden_state},\n",
    "        device=input_ids.device.type,\n",
    "        output_shape=tuple(input_ids.shape) + (int(model.config.vocab_size),),\n",
    "    )\n",
    "    return result_dict[\"output\"]\n",
    "\n",
    "\n",
    "def decoder_onnx_standard_inference(input_ids: torch.Tensor, last_hidden_state: torch.Tensor):\n",
    "    result_list = dec_onnx.run(\n",
    "        None, {\"input_ids\": input_ids.type(torch.int32).numpy(), \"encoder_hidden_states\": last_hidden_state.numpy()}\n",
    "    )\n",
    "    return torch.from_numpy(result_list[0])\n",
    "\n",
    "\n",
    "dec_onnx_out = decoder_onnx_inference(input_ids=input_ids, last_hidden_state=out_enc.last_hidden_state)\n",
    "assert np.allclose(dec_onnx_out.detach().cpu().numpy(), out_full.logits.detach().cpu().numpy(), atol=1e-1)\n",
    "\n",
    "\n",
    "def encoder_onnx_inference(input_ids: torch.Tensor, **_) -> BaseModelOutputWithPastAndCrossAttentions:\n",
    "    result = inference_onnx_binding(\n",
    "        model_onnx=enc_onnx,  # noqa: F821\n",
    "        inputs={\"input_ids\": input_ids},\n",
    "        output_shape=tuple(input_ids.shape) + (int(model.encoder.config.d_model),),\n",
    "        device=input_ids.device.type,\n",
    "    )\n",
    "    return BaseModelOutputWithPastAndCrossAttentions(last_hidden_state=result[\"output\"])\n",
    "\n",
    "\n",
    "def encoder_pytorch_inference(input_ids, **_) -> BaseModelOutputWithPastAndCrossAttentions:\n",
    "    return model.encoder(input_ids=input_ids)\n",
    "\n",
    "\n",
    "# https://github.com/NVIDIA/TensorRT/blob/main/demo/HuggingFace/T5/export.py\n",
    "class ExtT5(torch.nn.Module, GenerationMixin):\n",
    "    def __init__(self, config: PretrainedConfig, device: torch.device, encoder_func: Callable, decoder_func: Callable):\n",
    "        super(ExtT5, self).__init__()\n",
    "        self.main_input_name = \"input_ids\"  # https://github.com/huggingface/transformers/pull/14803\n",
    "        self.config: PretrainedConfig = config\n",
    "        self.device: torch.device = device\n",
    "\n",
    "        self.encoder_func = encoder_func\n",
    "        self.decoder_func = decoder_func\n",
    "\n",
    "    def get_encoder(self):\n",
    "        return self.encoder_func\n",
    "\n",
    "    def get_decoder(self):\n",
    "        return self.decoder_func\n",
    "\n",
    "    def prepare_inputs_for_generation(self, input_ids, **kwargs):\n",
    "        return {\n",
    "            self.main_input_name: input_ids,\n",
    "            \"encoder_hidden_states\": kwargs[\"encoder_outputs\"][\"last_hidden_state\"],\n",
    "        }\n",
    "\n",
    "    def forward(self, input_ids: torch.Tensor, encoder_hidden_states: torch.Tensor, **_):\n",
    "        dec_output = self.get_decoder()(input_ids=input_ids, last_hidden_state=encoder_hidden_states)\n",
    "        return Seq2SeqLMOutput(logits=dec_output)\n",
    "\n",
    "\n",
    "model_gen = (\n",
    "    ExtT5(\n",
    "        config=model.config,\n",
    "        device=model.device,\n",
    "        encoder_func=encoder_onnx_inference,  # encoder_pytorch_inference\n",
    "        decoder_func=decoder_onnx_inference,  # decoder_pytorch_inference\n",
    "    )\n",
    "    .cuda()\n",
    "    .eval()\n",
    ")\n",
    "\n",
    "# model = model.eval()\n",
    "with torch.inference_mode():\n",
    "    out_enc: BaseModelOutputWithPastAndCrossAttentions = model.encoder(input_ids=input_ids)\n",
    "    a = model_gen(input_ids=input_ids, encoder_hidden_states=out_enc.last_hidden_state).logits\n",
    "    b = model(input_ids=input_ids, decoder_input_ids=input_ids).logits\n",
    "    assert np.allclose(a.detach().cpu().numpy(), b.detach().cpu().numpy(), atol=1e-1)\n",
    "\n",
    "    print(\n",
    "        tokenizer.decode(\n",
    "            model_gen.generate(inputs=input_ids, max_length=20, num_beams=7, no_repeat_ngram_size=2)[0],\n",
    "            skip_special_tokens=False,\n",
    "        )\n",
    "    )\n",
    "    print(\n",
    "        tokenizer.decode(\n",
    "            model.generate(inputs=input_ids, max_length=20, num_beams=7, no_repeat_ngram_size=2)[0],\n",
    "            skip_special_tokens=False,\n",
    "        )\n",
    "    )\n",
    "\n",
    "start = time()\n",
    "for _ in range(3):\n",
    "    model_gen.generate(inputs=input_ids, max_length=500, num_beams=5, no_repeat_ngram_size=2, min_length=500)\n",
    "print(time() - start)\n",
    "\n",
    "model.config.use_cache = True\n",
    "with torch.inference_mode():\n",
    "    start = time()\n",
    "    for _ in range(3):\n",
    "        model.generate(inputs=input_ids, max_length=500, num_beams=5, no_repeat_ngram_size=2, min_length=500)\n",
    "    print(time() - start)\n",
    "\n",
    "model = model.cpu()\n",
    "del enc_onnx\n",
    "del dec_onnx\n",
    "\n",
    "trt_logger: Logger = trt.Logger(trt.Logger.ERROR)\n",
    "runtime: Runtime = trt.Runtime(trt_logger)\n",
    "trt_model_name = \"trt-t5-dec.plan\"\n",
    "\n",
    "# create only of does not exist because it's slow to run...\n",
    "\n",
    "# 768 for base model, 512 for small, make it dependent from the Pytorch model configuration\n",
    "input_id_shape = TensorRTShape(min_shape=[5, 1], optimal_shape=[5, 500], max_shape=[5, 500], input_name=\"input_ids\")\n",
    "encoder_hidden_states_shape = TensorRTShape(\n",
    "    min_shape=[5, 1, 512], optimal_shape=[5, 500 // 2, 512], max_shape=[5, 500, 512], input_name=\"encoder_hidden_states\"\n",
    ")\n",
    "\n",
    "\n",
    "model = model.cuda()\n",
    "model_onnx: ModelProto = onnx.load(\"test-dec.onnx\")\n",
    "model_onnx_all_nodes = add_output_nodes(model=model_onnx)\n",
    "onnx_graph: Dict[str, Set[str]] = get_adjency_dict(model=model_onnx)\n",
    "ort_model_all_nodes = create_model_for_provider(model_onnx_all_nodes.SerializeToString(), \"CUDAExecutionProvider\")\n",
    "\n",
    "\n",
    "# use info from tokenizer size and max shape provided through the command line\n",
    "def get_random_input():\n",
    "    input = torch.randint(high=tokenizer.vocab_size, size=(5, 500), dtype=torch.int32, device=\"cuda\")\n",
    "    hidden_state = model.encoder(input_ids=input).last_hidden_state.detach().cpu().numpy()\n",
    "    return {\"input_ids\": input.detach().cpu().numpy(), \"encoder_hidden_states\": hidden_state}\n",
    "\n",
    "\n",
    "keep_fp32 = get_list_fp32_nodes(\n",
    "    onnx_graph=onnx_graph, model=ort_model_all_nodes, get_input=get_random_input, nb_try=200\n",
    ")\n",
    "model = model.cpu()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "engine: ICudaEngine = build_engine(\n",
    "    runtime=runtime,\n",
    "    onnx_file_path=\"test-dec.onnx\",\n",
    "    logger=trt_logger,\n",
    "    workspace_size=20000 * 1024**2,\n",
    "    fp16=True,\n",
    "    int8=False,\n",
    "    input_shapes=[input_id_shape, encoder_hidden_states_shape],\n",
    "    fp16_fix=get_fix_fp16_network_func(keep_fp32=keep_fp32),\n",
    ")\n",
    "save_engine(engine, trt_model_name)\n",
    "\n",
    "tensorrt_model = load_engine(runtime=runtime, engine_file_path=trt_model_name)\n",
    "a = tensorrt_model(\n",
    "    {\n",
    "        \"input_ids\": input_ids.type(torch.int32).repeat((5, 1)),\n",
    "        \"encoder_hidden_states\": out_enc.last_hidden_state.repeat((5, 1, 1)),\n",
    "    }\n",
    ")\n",
    "print(a[0])\n",
    "\n",
    "benchmark_input = torch.ones((5, 500), dtype=torch.int32, device=\"cuda\")\n",
    "benchmark_enc_output = out_enc.last_hidden_state.repeat((5, 1, 1))\n",
    "for _ in range(10):\n",
    "    tensorrt_model(\n",
    "        {\n",
    "            \"input_ids\": benchmark_input,\n",
    "            \"encoder_hidden_states\": benchmark_enc_output,\n",
    "        }\n",
    "    )\n",
    "start = time()\n",
    "for _ in range(100):\n",
    "    tensorrt_model(\n",
    "        {\n",
    "            \"input_ids\": benchmark_input,\n",
    "            \"encoder_hidden_states\": benchmark_enc_output,\n",
    "        }\n",
    "    )\n",
    "print(time() - start)\n",
    "\n",
    "dec_onnx = create_model_for_provider(\"test-dec-opt.onnx\", \"CUDAExecutionProvider\")\n",
    "dec_onnx_out = decoder_onnx_inference(input_ids=input_ids, last_hidden_state=out_enc.last_hidden_state)\n",
    "\n",
    "\n",
    "for _ in range(10):\n",
    "    decoder_onnx_inference(input_ids=benchmark_input, last_hidden_state=benchmark_enc_output)\n",
    "start = time()\n",
    "for _ in range(100):\n",
    "    decoder_onnx_inference(input_ids=benchmark_input, last_hidden_state=benchmark_enc_output)\n",
    "print(time() - start)\n",
    "\n",
    "model.cuda()\n",
    "for _ in range(10):\n",
    "    model.decoder(input_ids=benchmark_input, encoder_hidden_states=benchmark_enc_output)\n",
    "start = time()\n",
    "for _ in range(100):\n",
    "    model.decoder(input_ids=benchmark_input, encoder_hidden_states=benchmark_enc_output)\n",
    "print(time() - start)\n",
    "\n",
    "# TensorRT, ONNX Runtime, Pytorch\n",
    "\n",
    "# sequence 500\n",
    "# 0.8640644550323486\n",
    "# 0.6695075035095215\n",
    "# 1.1308434009552002\n",
    "\n",
    "# sequence 250\n",
    "# 0.9177014827728271\n",
    "# 0.6861860752105713\n",
    "# 1.1923034191131592"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 4, 512])"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_enc: BaseModelOutputWithPastAndCrossAttentions = model.encoder(input_ids=input_ids)\n",
    "model.decoder(input_ids=input_ids, encoder_hidden_states=out_enc.last_hidden_state, past_key_values=None).last_hidden_state.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 1, 512])"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_dec_pytorch = model.decoder(input_ids=input_ids[:, :-1], encoder_hidden_states=out_enc.last_hidden_state)\n",
    "model.decoder(input_ids=input_ids[:, -1:], encoder_hidden_states=out_enc.last_hidden_state, past_key_values=out_dec_pytorch.past_key_values).last_hidden_state.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 8, 3, 64])"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_dec_pytorch.past_key_values[0][0].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6536,  504,   24,    1]], device='cuda:0')\n",
      "tensor([[6536,  504,   24]], device='cuda:0')\n",
      "tensor([[1]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(input_ids)\n",
    "print(input_ids[:, :-1])\n",
    "print(input_ids[:, -1:])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[6536,  504,   24,    1,    1]], device='cuda:0')"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[6536,  504,   24,    1, 1]], device=\"cuda\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 8, 4, 64])"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_dec_pytorch.past_key_values[0][0].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "((tensor([[[[ 1.3416,  1.0303, -1.1058,  ...,  0.4328, -0.6218, -0.5854],\n            [ 2.6922, -0.3062,  0.6622,  ...,  0.3361,  2.2621, -2.3631],\n            [ 2.3044,  1.6747, -1.5347,  ..., -0.7960, -0.8685, -0.7486]],\n  \n           [[ 2.1050,  0.3592, -0.1216,  ..., -0.6567,  0.0303, -1.4926],\n            [ 1.8790, -0.3769,  0.0772,  ..., -0.0882, -0.0667,  0.3396],\n            [ 0.6978, -1.4310,  0.0747,  ...,  0.9703,  1.5697, -0.2471]],\n  \n           [[-1.9993, -0.5561,  0.4198,  ..., -1.2903,  1.8639,  0.2006],\n            [ 0.8222,  0.1162, -1.0901,  ..., -1.0259,  0.2069,  0.1699],\n            [ 0.5397, -0.8146,  0.0076,  ..., -0.3202, -0.3298, -0.7070]],\n  \n           ...,\n  \n           [[ 1.5321, -1.3107, -0.1120,  ...,  0.8826,  2.4943,  0.6758],\n            [-0.0612, -0.2983, -1.7837,  ..., -0.9534,  0.2336, -0.3940],\n            [-0.0531, -0.9719,  0.6107,  ...,  0.5673,  0.0988, -0.5013]],\n  \n           [[-2.0004, -1.4008, -1.1703,  ..., -1.1139, -1.1067, -2.0596],\n            [-1.2807,  0.6913, -2.1444,  ...,  0.5861,  0.0604,  0.2580],\n            [-1.8379, -0.2797, -2.8484,  ...,  0.3213,  2.9190,  0.1616]],\n  \n           [[ 0.8150, -0.8560, -0.1998,  ..., -0.8927,  1.3496,  0.2405],\n            [ 0.0272, -0.5541, -0.6199,  ..., -0.6943,  0.5490,  0.9191],\n            [ 0.5297, -0.0251,  0.4972,  ...,  0.0769,  0.8496,  0.2250]]]],\n         device='cuda:0', grad_fn=<TransposeBackward0>),\n  tensor([[[[-1.2028, -0.0799, -0.8356,  ...,  0.1297,  0.4526,  2.5504],\n            [ 0.3420,  0.1387,  0.9327,  ..., -1.0253,  0.6241, -0.0830],\n            [ 0.2137, -0.1219,  0.0263,  ...,  0.1559,  0.2917,  1.1967]],\n  \n           [[ 0.2749,  0.5528, -0.5893,  ...,  0.1462,  0.9068, -0.9723],\n            [ 0.6590,  0.4362, -0.7002,  ...,  0.2978, -0.6403,  0.0997],\n            [ 0.2338, -0.3462,  0.3773,  ...,  1.0578, -0.7465, -0.0490]],\n  \n           [[-1.5746, -0.4144,  0.9656,  ...,  0.5600,  0.4878,  0.1638],\n            [-0.0747, -1.2655, -0.6200,  ...,  1.0615,  0.0835,  0.0664],\n            [-0.1423, -1.1653, -1.4649,  ...,  0.2464, -0.8252,  1.7841]],\n  \n           ...,\n  \n           [[ 0.3740, -0.4283, -0.9549,  ..., -1.6375, -1.4011, -0.2158],\n            [-1.7586, -0.6537, -0.2351,  ..., -0.6830, -0.7053, -0.8860],\n            [-0.7675,  0.4081,  0.1270,  ..., -0.5773, -1.0285, -0.8179]],\n  \n           [[-1.6322,  0.4656, -1.0861,  ...,  1.1180, -0.8835,  0.5494],\n            [-0.5849,  0.0054, -0.6307,  ...,  0.3195,  0.1716,  0.0111],\n            [-1.0271, -1.8103,  1.2702,  ...,  1.6425, -0.7124, -1.7598]],\n  \n           [[ 1.0568, -1.7580,  0.9833,  ..., -0.0834,  0.4463,  0.0769],\n            [-1.9568, -2.1043,  0.2592,  ..., -1.4887,  2.7089, -0.9148],\n            [ 1.4027, -1.4261, -1.2641,  ..., -1.0277, -0.7672,  0.8467]]]],\n         device='cuda:0', grad_fn=<TransposeBackward0>),\n  tensor([[[[ 0.6785, -0.4747, -2.2564,  ..., -1.5642,  3.4867,  1.7121],\n            [-1.3643, -0.5485, -1.0667,  ..., -0.0195,  2.4405,  0.0358],\n            [-1.5689, -0.6163,  0.8701,  ...,  0.7591,  0.0354,  0.3101],\n            [-0.9370, -0.2669,  0.2573,  ...,  1.4131, -0.1317, -0.5060]],\n  \n           [[-1.8393, -1.5013, -3.0152,  ..., -2.1590,  0.7469,  4.2582],\n            [ 1.0073,  3.4592,  0.1454,  ..., -4.0766, -0.5183,  2.4832],\n            [ 0.7409,  1.5114,  0.8894,  ..., -6.3685,  0.6908,  0.0826],\n            [-1.6104, -0.2118,  2.0255,  ...,  0.9144,  0.5168, -0.1656]],\n  \n           [[-0.3960,  2.5924, -2.6742,  ..., -1.4239, -1.0241, -0.9933],\n            [ 0.2559,  2.2181, -2.2028,  ...,  0.5321, -0.7104, -0.8206],\n            [ 1.5369,  1.4277, -0.0239,  ...,  1.6737, -0.3471, -0.7639],\n            [ 0.2333,  0.7189, -0.6169,  ...,  0.0537,  0.4827,  0.4578]],\n  \n           ...,\n  \n           [[-0.3361, -1.8035, -0.6215,  ...,  2.0505, -1.4031, -1.2000],\n            [-1.2258, -0.2976, -0.9273,  ..., -0.3640, -0.9724, -0.7110],\n            [ 2.7714,  0.8847, -1.7869,  ...,  0.7775, -2.0425,  0.7674],\n            [ 0.8587,  1.5963, -1.5394,  ..., -0.4051, -2.3719,  1.0038]],\n  \n           [[-0.9017, -1.7088, -0.7878,  ...,  0.9778,  0.3755,  0.3466],\n            [ 0.5948,  0.2253, -0.7793,  ...,  1.5844, -0.2175, -1.4800],\n            [ 1.4452, -0.1263, -3.2911,  ...,  3.1522, -0.9879, -0.9466],\n            [-0.1367, -1.1768, -1.7118,  ...,  0.4522,  0.9889, -1.8495]],\n  \n           [[ 0.5205, -0.9689,  0.6697,  ...,  0.5361,  0.2421,  1.4327],\n            [ 0.5313,  0.8859,  2.7315,  ...,  0.4364, -1.3425,  1.6998],\n            [ 1.1177,  0.4765,  1.3283,  ...,  0.7439, -2.5944,  0.5300],\n            [-0.1397,  0.4469, -0.1920,  ..., -1.2894,  1.0697,  0.5623]]]],\n         device='cuda:0', grad_fn=<TransposeBackward0>),\n  tensor([[[[ 4.0691e+00,  5.6825e-02,  3.2746e+00,  ...,  5.7043e-01,\n             -3.8776e-01, -2.6245e+00],\n            [ 1.3854e+00,  2.8957e-01,  7.2127e-01,  ...,  1.6997e+00,\n             -4.5125e-01, -1.5823e+00],\n            [-2.4081e+00, -3.8658e-01, -4.1036e-01,  ...,  8.8859e-01,\n              2.6565e+00, -1.2248e-01],\n            [ 8.2343e-01, -5.2337e-02,  8.0873e-02,  ..., -9.0336e-01,\n              4.1649e-01, -1.4193e+00]],\n  \n           [[-1.8227e+00,  5.2572e+00,  1.5067e+00,  ...,  9.1277e-01,\n             -4.3348e-01,  3.5884e+00],\n            [-1.1950e+00,  3.6570e+00,  3.1792e-01,  ..., -2.2973e+00,\n             -1.0971e+00,  1.2991e+00],\n            [-7.3739e-01,  1.9648e+00,  2.8704e+00,  ..., -2.0775e+00,\n             -2.4944e-01,  6.1527e-01],\n            [ 7.4571e-01, -5.1512e-01,  1.8288e+00,  ..., -3.2179e-01,\n              1.1328e+00,  9.5557e-01]],\n  \n           [[-2.3241e-02, -5.6935e+00,  4.6956e+00,  ..., -1.9248e+00,\n             -7.5951e-01,  2.1387e+00],\n            [-2.2725e+00, -3.4578e+00,  5.7374e+00,  ...,  1.3574e+00,\n              9.1168e-01,  2.4405e+00],\n            [-5.1528e-01,  1.3036e+00,  6.3984e+00,  ...,  3.1345e+00,\n             -6.8289e-01, -8.6648e-01],\n            [-3.2256e-01, -1.4795e-01,  7.0494e+00,  ...,  1.2148e+00,\n             -1.1325e+00, -6.9777e-01]],\n  \n           ...,\n  \n           [[-2.4369e+00, -2.1486e+00,  3.3851e+00,  ...,  6.7743e-01,\n              1.3418e+00, -1.6572e+00],\n            [ 1.2443e+00, -1.4702e+00,  2.0063e+00,  ...,  1.8192e+00,\n             -8.1447e-01,  4.6214e-01],\n            [ 1.3150e+00, -1.1387e+00,  2.9140e-03,  ...,  1.0959e+00,\n              3.3356e-01,  1.1447e+00],\n            [ 9.3011e-01, -1.4948e+00,  4.5995e-02,  ..., -3.3757e-02,\n              9.9317e-01,  1.3737e+00]],\n  \n           [[-2.1023e+00, -1.0047e+00,  1.9991e+00,  ...,  2.2364e+00,\n              1.6482e+00,  1.8465e+00],\n            [-1.5452e+00, -3.7644e+00, -1.0970e+00,  ...,  3.4001e-01,\n              6.6490e-01,  1.4608e+00],\n            [-5.9458e-01, -1.7371e+00,  3.3616e+00,  ..., -3.7741e-01,\n              2.9912e+00, -1.4148e+00],\n            [-1.4879e+00, -6.5817e-01,  2.6592e+00,  ...,  2.9166e-01,\n              4.9337e-01, -9.5067e-01]],\n  \n           [[ 2.1768e+00, -2.7993e+00,  1.2174e+00,  ..., -3.1573e+00,\n             -7.2839e-01,  5.8405e-01],\n            [ 4.2895e-01, -9.2040e-01,  2.5279e+00,  ..., -1.3244e+00,\n             -4.4093e-01,  1.7193e-01],\n            [-3.8359e-01, -8.2366e-02,  1.6144e+00,  ...,  2.7785e-01,\n             -1.0779e+00,  4.2871e-03],\n            [ 1.9028e+00, -7.7743e-01,  1.7163e+00,  ..., -2.0806e-01,\n             -1.0092e+00, -3.1153e+00]]]], device='cuda:0',\n         grad_fn=<TransposeBackward0>)),\n (tensor([[[[-0.3044,  0.8072,  1.1381,  ...,  0.3645, -0.5250, -1.5760],\n            [-1.1957,  1.2144,  1.4583,  ..., -0.0816, -0.8150, -0.6672],\n            [ 0.1940, -0.2896,  1.1161,  ...,  0.4002, -0.3330, -1.1559]],\n  \n           [[-0.1248, -0.5533,  0.1917,  ...,  1.9538,  0.1593, -0.1686],\n            [ 0.2058, -0.5244, -0.3832,  ...,  1.2022, -0.3167,  0.4535],\n            [ 0.2234, -0.7876, -1.8220,  ...,  1.3581, -1.5082,  0.2022]],\n  \n           [[ 1.9204,  0.4541,  0.0514,  ..., -1.6720, -0.5580, -0.5298],\n            [ 2.5028, -0.1577, -0.2627,  ..., -1.7091,  0.7297, -1.3474],\n            [ 0.8868,  0.0713,  0.0638,  ..., -1.1049, -0.7177, -0.9028]],\n  \n           ...,\n  \n           [[ 1.0556, -0.3889, -1.2002,  ..., -1.3566, -1.3314, -0.2260],\n            [ 1.2874, -0.9067, -0.2750,  ..., -0.7378, -2.0487, -0.3183],\n            [ 1.1137, -0.7851, -0.6536,  ..., -0.7474, -1.0416, -1.0802]],\n  \n           [[ 0.6459,  0.7710, -0.2098,  ..., -0.8418,  0.4573, -0.1582],\n            [-0.8244,  0.6433, -0.5945,  ...,  0.9295,  0.1887, -0.2609],\n            [-1.3066,  0.8290, -0.4816,  ..., -0.5879, -0.2974,  0.1118]],\n  \n           [[ 0.2177, -0.7943, -0.7839,  ...,  0.6001,  0.1731,  0.3472],\n            [-0.2650,  0.6019, -0.2712,  ...,  0.5017,  0.3760,  0.2796],\n            [-0.7800,  1.0128, -0.7450,  ...,  0.6612,  0.8207, -0.5956]]]],\n         device='cuda:0', grad_fn=<TransposeBackward0>),\n  tensor([[[[ 1.5405, -0.8256,  1.1318,  ...,  0.2273, -1.6494, -0.7074],\n            [ 1.6476,  1.2933,  0.8110,  ...,  0.4173,  0.2390,  1.9007],\n            [ 0.3087,  0.4889, -0.4305,  ...,  1.7423,  0.0327,  1.2772]],\n  \n           [[-0.6367,  0.6256, -2.5604,  ..., -2.8376,  0.9172, -0.5303],\n            [ 0.0129, -0.2944, -1.6988,  ..., -0.3115,  0.7749, -2.0740],\n            [-0.5301, -0.7025, -0.9534,  ...,  1.5532, -0.5329, -1.9814]],\n  \n           [[-1.2702,  2.1027,  0.1820,  ..., -0.3718,  0.3776, -1.4703],\n            [ 1.0755,  2.2253, -2.3659,  ...,  0.1148,  0.1141, -1.2085],\n            [ 0.9212,  2.1332, -0.6169,  ..., -1.4042,  1.0402, -0.4511]],\n  \n           ...,\n  \n           [[ 1.9421,  2.4300, -3.7774,  ..., -1.7068, -0.3678,  0.1064],\n            [-0.6136,  0.5811, -2.7562,  ...,  0.8140,  1.0230,  0.3888],\n            [-1.7775, -0.2264, -0.3673,  ...,  3.4459,  0.9511,  1.2429]],\n  \n           [[ 1.3725, -4.1719, -0.9627,  ...,  0.3494, -0.9333, -1.4905],\n            [ 1.2849,  0.8136, -0.6543,  ..., -2.8592, -1.6240, -2.1472],\n            [ 1.8623,  0.8044, -1.6136,  ..., -3.9953, -1.4178, -0.5769]],\n  \n           [[ 3.5306,  0.9942,  2.6663,  ..., -0.5381,  1.9028, -1.7634],\n            [ 2.1342,  4.0383,  1.9983,  ..., -2.9075,  1.2342,  0.7052],\n            [ 3.7897,  2.0495, -2.4822,  ..., -4.8624, -2.2584,  0.7466]]]],\n         device='cuda:0', grad_fn=<TransposeBackward0>),\n  tensor([[[[-1.3147,  1.0517, -1.4631,  ..., -0.4914,  1.2128, -0.5787],\n            [-1.8949,  0.8859,  0.1445,  ..., -0.1653,  1.2322,  1.0274],\n            [-0.6065, -0.5989, -0.7056,  ..., -0.8347, -0.0518,  0.0546],\n            [-0.2665, -0.1293, -0.4946,  ...,  0.2924, -0.3047,  0.9504]],\n  \n           [[-0.8082, -2.4103,  0.6291,  ...,  0.7333, -1.6198, -1.0921],\n            [-0.2569, -1.5204, -0.8376,  ..., -2.3116,  1.0490,  0.2425],\n            [-0.1946, -2.0696,  1.6125,  ..., -1.8111,  1.1906,  0.8191],\n            [-0.9087,  0.1041,  0.1124,  ...,  0.0624, -0.8382,  0.2327]],\n  \n           [[ 0.9632, -1.4264,  0.7217,  ..., -1.0689, -0.5215, -1.8430],\n            [ 0.6395, -0.9076, -0.2392,  ..., -1.2877, -0.8456, -1.2115],\n            [ 0.7853,  0.5005, -1.4915,  ..., -0.9482, -1.1297,  0.1650],\n            [ 0.0134,  0.6438, -1.2574,  ..., -1.6567, -0.8996,  0.5163]],\n  \n           ...,\n  \n           [[-0.1611, -1.0828,  1.2211,  ..., -0.4552, -1.4782, -0.2561],\n            [-2.1354, -1.0535,  0.4591,  ..., -2.0166, -1.3949,  0.8046],\n            [-1.1528,  0.3893,  1.0175,  ..., -1.1153, -1.8250, -0.5477],\n            [-0.1991,  0.0681,  1.2142,  ..., -1.2727,  0.0226,  0.9001]],\n  \n           [[ 1.7739,  1.6333,  1.3513,  ...,  0.8372,  0.3806,  0.5133],\n            [ 1.0609,  2.2734, -1.1297,  ...,  1.5876, -0.9885,  0.7679],\n            [ 2.5745,  0.9184, -1.7239,  ...,  1.8418, -0.7512,  2.0017],\n            [ 1.6395,  0.9414, -1.1421,  ..., -1.3647, -0.7465,  2.4119]],\n  \n           [[ 1.6812,  0.1679,  1.6913,  ..., -0.9623,  0.5013,  2.9538],\n            [-0.0532,  0.9585, -0.9424,  ...,  0.4015,  1.8249,  0.9139],\n            [-1.7732, -0.7658,  0.1374,  ..., -1.1347,  2.2229,  4.2945],\n            [ 0.7663,  0.4660,  0.5069,  ..., -0.9546, -0.2196,  5.7192]]]],\n         device='cuda:0', grad_fn=<TransposeBackward0>),\n  tensor([[[[-0.2279,  1.8831,  2.3706,  ..., -1.2887,  0.9180,  0.4342],\n            [-0.8680,  0.2803,  5.5051,  ...,  0.6443, -1.5974, -1.4994],\n            [-1.5727, -1.4352, -0.1713,  ..., -1.8816, -1.0610, -0.1703],\n            [-3.7970,  0.1225,  0.0453,  ..., -1.0004, -0.3347,  1.2103]],\n  \n           [[ 0.1371,  1.6849,  2.6770,  ...,  5.3751,  2.5298,  0.5914],\n            [-1.2482,  2.0456,  2.4177,  ...,  5.0222,  0.5968,  5.2444],\n            [-3.0463, -1.1699, -2.8720,  ...,  5.7317, -1.7409,  1.2998],\n            [ 0.6855, -1.9928,  0.6576,  ...,  0.3996, -3.6342,  5.1682]],\n  \n           [[-2.1303,  0.3061, -4.2122,  ..., -2.1401,  3.6255,  0.7198],\n            [-0.1480, -1.9627, -1.3867,  ..., -5.7249,  3.6395,  4.3975],\n            [ 0.0327, -3.2628, -2.2504,  ..., -2.0441,  0.7835,  1.7086],\n            [-2.2447, -3.2335,  0.4326,  ...,  2.3127,  2.2164,  0.3387]],\n  \n           ...,\n  \n           [[ 3.0143,  0.9602,  0.3372,  ..., -0.9892,  1.4283,  0.8267],\n            [-0.2875, -2.1864, -0.5871,  ...,  1.3862, -3.2602,  0.4965],\n            [-2.9047, -2.9794, -2.3295,  ...,  1.6610,  2.3822, -0.7009],\n            [-0.3231,  0.7903, -1.3077,  ...,  0.2752,  0.3866, -1.3159]],\n  \n           [[-0.3608, -2.0604,  1.8466,  ...,  1.0093,  1.3583,  0.8108],\n            [-0.5726, -0.8913, -0.9970,  ...,  1.7457, -0.6033,  2.2718],\n            [ 0.1229, -1.2123, -2.4421,  ..., -0.5846,  2.5922,  0.1856],\n            [ 1.7207,  2.1629, -1.7061,  ...,  1.7549,  1.1659, -2.5737]],\n  \n           [[-0.6102,  3.8940,  0.1703,  ..., -0.8571,  2.9295, -1.4188],\n            [-3.4220,  1.3365, -0.1247,  ..., -1.7154,  3.1643, -1.4226],\n            [-0.7224,  2.0251,  0.8684,  ..., -4.0683, -0.3329,  1.6532],\n            [ 0.8443, -1.6668,  2.3025,  ..., -2.5185,  0.7509,  1.1943]]]],\n         device='cuda:0', grad_fn=<TransposeBackward0>)),\n (tensor([[[[-3.0592, -0.3978,  2.4741,  ..., -0.0525, -0.0655, -0.1144],\n            [-2.2541, -0.6336,  1.3141,  ..., -1.0644, -1.8493, -0.0259],\n            [-1.6790, -0.0878,  0.6658,  ..., -0.2588, -2.2927, -1.1063]],\n  \n           [[-0.3186, -0.5897, -1.6481,  ...,  1.3728, -0.4630,  1.0491],\n            [-0.2865,  0.2029, -2.0080,  ...,  0.7412, -0.9889, -0.3378],\n            [-1.1473, -0.4536, -2.2500,  ...,  0.7509, -1.1941,  0.5428]],\n  \n           [[-1.1222,  1.8788,  1.6937,  ...,  0.9322,  0.4090,  2.1007],\n            [-0.6972,  2.6572,  0.8533,  ...,  0.4440, -0.3032,  0.9717],\n            [-1.6148,  1.8443,  0.6988,  ...,  0.7556,  0.2982,  0.5065]],\n  \n           ...,\n  \n           [[-0.3824, -1.2074, -1.5674,  ...,  0.2474,  0.3416,  2.4707],\n            [ 0.1180, -2.4590, -1.0983,  ..., -0.4459,  0.9709,  1.1775],\n            [ 0.9997, -1.3480, -1.3519,  ...,  0.0567,  1.2406,  1.0664]],\n  \n           [[ 0.9349, -0.9318,  0.9030,  ..., -1.5067,  1.2601,  0.7944],\n            [ 2.1394, -0.4344,  0.8701,  ..., -2.5438,  1.7848,  1.2362],\n            [ 1.2317, -0.8318, -0.1579,  ..., -2.1732,  1.5853, -0.4072]],\n  \n           [[-0.1095,  1.1640, -1.7532,  ...,  0.2695,  1.7267, -0.7816],\n            [ 0.1220,  0.8411, -0.9697,  ...,  1.1518,  1.8962, -1.6549],\n            [ 0.0283,  0.9975, -1.5482,  ...,  1.3859,  0.5114, -2.0683]]]],\n         device='cuda:0', grad_fn=<TransposeBackward0>),\n  tensor([[[[ 6.9605e+00, -6.2150e-01, -8.7210e-01,  ...,  4.1547e-01,\n              5.5605e-01, -2.6252e+00],\n            [ 5.2513e-01,  1.0061e+00, -2.9232e+00,  ..., -7.3441e-02,\n             -3.8858e-02, -1.6110e+00],\n            [ 9.8108e-01,  3.7008e-01,  1.0474e+00,  ...,  1.7844e-01,\n              2.6605e+00, -3.0617e+00]],\n  \n           [[-7.0435e-01, -3.4109e+00, -2.1629e+00,  ...,  1.0287e+00,\n             -9.7466e-01,  4.9676e-01],\n            [-5.0800e+00, -2.5069e-03, -1.5785e+00,  ...,  1.2260e+00,\n             -4.8315e-01,  1.2004e+00],\n            [-3.5324e+00, -7.9276e-01, -4.0795e-01,  ..., -3.2938e+00,\n              2.0828e+00,  2.0834e+00]],\n  \n           [[-1.8893e+00, -3.1964e+00,  7.1565e-01,  ..., -1.4224e+00,\n             -3.9960e+00, -2.5611e+00],\n            [-1.5770e+00,  1.6517e+00,  5.5854e-01,  ..., -2.6345e+00,\n             -1.0795e+00, -1.2637e+00],\n            [-4.9461e-02,  1.1270e+00, -1.3063e+00,  ..., -1.9431e-02,\n              5.6480e-01,  5.4538e+00]],\n  \n           ...,\n  \n           [[-1.5148e-01, -1.1512e-01,  1.0725e+00,  ..., -2.0716e+00,\n             -4.1197e+00, -6.6213e-01],\n            [ 2.3737e+00,  1.7616e+00,  2.2111e+00,  ..., -2.0830e+00,\n             -2.8664e+00, -2.0036e-01],\n            [ 2.5093e+00,  2.6008e+00, -1.9076e-01,  ..., -9.1044e-01,\n             -4.6610e+00,  1.0568e+00]],\n  \n           [[-2.1461e-01, -2.9408e+00, -5.6785e-01,  ...,  1.8484e+00,\n              1.8770e+00,  1.3828e-01],\n            [ 1.5928e+00, -1.0971e+00,  9.2929e-01,  ...,  1.9778e+00,\n              2.6807e+00,  1.3973e+00],\n            [ 2.4980e+00, -6.1367e-01,  7.2722e-02,  ..., -4.7961e-01,\n              6.3659e-01,  1.0904e+00]],\n  \n           [[-6.7968e-01,  3.9465e+00,  1.4056e+00,  ..., -5.8665e-01,\n              1.2953e+00, -3.6149e-01],\n            [-2.6283e+00,  3.3236e+00,  2.4178e+00,  ..., -8.9598e-01,\n             -3.5246e-01,  1.2240e-01],\n            [-7.8055e-01,  4.2036e+00,  3.2387e+00,  ..., -2.9234e-01,\n             -1.7238e+00, -5.3550e-01]]]], device='cuda:0',\n         grad_fn=<TransposeBackward0>),\n  tensor([[[[ 0.8290, -1.8654, -1.5570,  ..., -1.3292, -1.3620,  1.1480],\n            [-1.1788, -0.9847, -0.0516,  ...,  0.5931,  0.3144,  0.2116],\n            [-1.9297, -1.0656,  1.6972,  ...,  0.9050, -1.2576,  0.7434],\n            [-1.7674,  0.5175, -1.0006,  ...,  0.4549, -0.6766, -0.8747]],\n  \n           [[ 0.7296, -0.1485,  1.2811,  ...,  0.1744, -1.2113, -0.6189],\n            [-1.0831,  0.6459, -1.0823,  ..., -1.3893, -1.6769,  2.0346],\n            [-3.4390, -0.3243, -1.1260,  ..., -1.2684, -1.7139,  1.2541],\n            [ 0.6987,  0.0912, -1.2799,  ..., -0.1885, -0.6864, -0.6787]],\n  \n           [[ 1.4389, -1.1240,  2.1718,  ...,  1.8792,  1.6919, -2.5485],\n            [ 0.7599,  1.7319,  1.3075,  ...,  1.4057, -1.2175, -1.9935],\n            [ 0.3213,  0.7913, -0.4087,  ...,  3.4761, -0.2557, -1.7197],\n            [-0.5846,  1.0312,  0.3081,  ...,  2.5339,  0.0555, -2.4643]],\n  \n           ...,\n  \n           [[-2.3458,  1.6233, -0.9006,  ...,  1.0529, -0.9032,  1.0214],\n            [-0.7276, -1.1994,  0.1443,  ...,  0.4825, -1.6032, -0.1101],\n            [-1.4555, -0.5029,  1.7382,  ...,  1.0702, -2.9458,  0.5353],\n            [-2.2285, -1.0908, -0.0695,  ...,  0.8152, -1.7399,  2.9807]],\n  \n           [[ 0.4254,  1.0388,  2.3745,  ...,  2.2068,  0.1022, -2.4774],\n            [ 1.2358,  0.3664,  1.5532,  ..., -2.0003, -2.7208, -2.9148],\n            [-1.5989,  0.9442,  1.8156,  ...,  0.8362, -2.0150, -0.1430],\n            [-3.0063,  3.7740,  0.5191,  ..., -0.5815,  0.2174, -3.5186]],\n  \n           [[-1.2605, -0.3136,  1.0273,  ...,  1.0047, -0.4218,  1.9472],\n            [ 0.7109, -1.7250, -2.2592,  ...,  1.2746,  1.1783,  3.0221],\n            [ 2.2299,  0.3944, -1.9835,  ...,  1.8912,  1.3248,  2.7992],\n            [-0.4329, -0.6136, -0.7583,  ...,  1.7840,  1.8677,  2.4108]]]],\n         device='cuda:0', grad_fn=<TransposeBackward0>),\n  tensor([[[[-4.0073e+00,  7.7132e+00, -7.8855e+00,  ...,  4.6314e+00,\n             -3.3957e-01, -1.6808e+00],\n            [ 1.5950e+00,  4.4900e+00, -1.4301e+00,  ...,  3.7386e+00,\n             -3.2464e-01,  5.6719e+00],\n            [ 4.9268e+00,  1.1388e+00,  8.5458e+00,  ..., -6.8930e+00,\n             -2.8348e+00,  1.0035e+01],\n            [ 3.0644e+00,  1.3654e+00,  3.9042e+00,  ..., -3.2944e+00,\n              1.8855e-01,  2.1188e+00]],\n  \n           [[ 1.4435e+00,  4.6818e+00,  1.6455e-01,  ...,  6.2666e-01,\n             -1.4967e+00,  2.4630e+00],\n            [ 4.8889e-01,  2.6127e+00, -8.0847e-01,  ..., -1.3832e+00,\n             -4.4161e-01, -6.1442e-01],\n            [-4.7039e-01,  2.6503e+00, -2.8070e+00,  ..., -1.5276e-01,\n             -1.8878e+00, -5.0098e-02],\n            [ 4.8549e-01,  4.1797e+00, -2.3967e+00,  ...,  3.5887e-01,\n              2.0217e+00,  2.7771e+00]],\n  \n           [[-1.6532e+00, -3.8097e+00,  1.0134e+00,  ...,  9.1480e-01,\n              3.5959e-04, -6.0623e+00],\n            [-3.7536e+00, -1.0092e+00,  2.6546e+00,  ..., -9.5005e-01,\n             -6.2668e-01, -6.2570e+00],\n            [ 5.5425e+00, -7.7881e-01, -1.7319e+00,  ...,  1.4897e+00,\n             -2.9686e+00, -1.8405e+00],\n            [ 3.4174e+00, -1.7014e+00, -8.7864e-01,  ...,  7.9461e-01,\n             -8.1151e-01, -3.3537e-01]],\n  \n           ...,\n  \n           [[ 8.1614e-02, -2.0523e+00, -3.1740e+00,  ..., -1.8546e+00,\n              5.2447e-01, -2.7914e+00],\n            [-2.2176e-01, -1.3302e+00, -2.8559e+00,  ...,  2.7321e+00,\n              4.3197e+00, -3.3834e+00],\n            [ 4.8471e-01,  1.8430e-01, -1.5376e+00,  ...,  3.1581e+00,\n              6.4113e-01, -1.9977e+00],\n            [ 5.2366e-01, -7.0549e-01,  1.6068e+00,  ..., -4.2533e-01,\n             -2.1019e+00,  7.5995e-01]],\n  \n           [[-4.9057e-01,  2.3210e+00,  3.0896e-02,  ...,  7.1822e-02,\n             -1.3221e-01, -7.3057e-01],\n            [-4.2858e+00,  9.5478e-01,  1.6880e+00,  ..., -2.4229e+00,\n             -3.5717e-01,  2.2550e+00],\n            [-2.1459e+00,  1.8222e-01, -1.2881e-02,  ..., -3.7511e+00,\n             -1.4982e+00,  9.3183e-01],\n            [ 1.7990e+00, -8.5690e-01, -3.8339e-01,  ..., -4.5899e-01,\n              1.8272e+00,  1.9009e+00]],\n  \n           [[-4.4336e-01,  2.2361e+00,  3.3394e+00,  ..., -3.9473e+00,\n              1.9308e+00,  2.4900e+00],\n            [ 1.5247e+00, -3.0648e+00,  8.3976e-01,  ..., -3.3714e+00,\n              1.6154e-01, -9.7560e-01],\n            [ 3.0445e+00, -1.2195e+00, -2.8001e-01,  ...,  1.8884e+00,\n             -3.2455e+00, -4.3370e+00],\n            [ 1.7951e+00, -6.8489e-01, -5.2939e-01,  ..., -6.9555e-01,\n             -1.1591e+00,  1.2735e+00]]]], device='cuda:0',\n         grad_fn=<TransposeBackward0>)),\n (tensor([[[[-0.2628,  3.3093, -2.4039,  ...,  3.7025, -4.1175,  2.9629],\n            [ 0.4514,  4.7602, -2.1159,  ...,  2.9896, -3.2151,  3.2136],\n            [ 1.7591,  3.3070, -1.3501,  ...,  3.0540, -2.6840,  3.4543]],\n  \n           [[ 1.7216,  4.0274, -1.7548,  ...,  1.4417,  0.0912,  2.7284],\n            [ 2.0701,  3.6724, -2.3089,  ...,  1.2676, -0.0362,  2.2553],\n            [ 1.1431,  3.8382, -1.4644,  ...,  1.2151, -0.5829,  1.3232]],\n  \n           [[-0.4733,  0.2241, -0.2592,  ...,  0.7847,  2.4723,  0.6808],\n            [ 0.0258, -0.7278,  0.5667,  ...,  0.9387,  1.6926,  2.6080],\n            [ 1.5921, -1.6327, -0.4676,  ...,  2.0684,  0.3435,  2.8100]],\n  \n           ...,\n  \n           [[ 0.7531,  0.8675, -0.6244,  ..., -2.9769,  2.7337, -2.5236],\n            [-0.6348,  0.8334, -1.0844,  ..., -2.7822,  2.4493, -2.8121],\n            [-0.2667,  1.7964, -1.6891,  ..., -4.3012,  0.5295, -3.0163]],\n  \n           [[-0.4404,  0.1522, -0.1155,  ..., -1.7947,  0.7998, -0.1580],\n            [-0.4592, -0.5553,  0.7541,  ..., -0.4148,  2.4639, -0.2543],\n            [-0.6217, -1.5966,  0.4304,  ..., -0.1609,  2.9349,  0.4978]],\n  \n           [[ 1.5973,  1.1494, -3.0339,  ...,  1.6093,  1.5531,  2.9104],\n            [-0.0232,  1.0741, -3.2655,  ...,  2.2959,  1.6197,  2.2177],\n            [-1.6206, -0.3344, -3.2774,  ...,  0.0714,  0.3389,  1.3438]]]],\n         device='cuda:0', grad_fn=<TransposeBackward0>),\n  tensor([[[[-1.1568,  1.6305,  2.3378,  ...,  1.1844,  0.8537,  0.4108],\n            [ 0.2153,  2.5784,  1.2980,  ...,  1.3875, -0.0077,  0.9412],\n            [-0.8773,  1.1025,  0.8985,  ..., -1.3023,  2.3454,  0.5937]],\n  \n           [[ 0.2976,  4.5524, -4.9899,  ...,  2.7045, -1.4828, -4.4687],\n            [ 1.7540,  4.3754, -4.5417,  ...,  4.5424, -3.4397, -1.6415],\n            [ 3.3023,  0.4507, -3.1774,  ...,  5.1488, -0.0247,  2.1087]],\n  \n           [[-1.6583,  5.6051, -2.1055,  ..., -0.5285,  6.6067, -0.1277],\n            [-1.8259,  2.7142, -1.3428,  ...,  1.8240,  5.3473, -0.7308],\n            [-2.7659,  0.5007,  0.5505,  ...,  1.8468,  4.0048,  0.6084]],\n  \n           ...,\n  \n           [[ 1.0941,  3.2674,  3.3812,  ...,  3.9034,  2.1050, -0.2596],\n            [ 0.7827,  3.0405,  3.2340,  ...,  3.3237,  1.7038,  0.7173],\n            [ 0.9335,  2.1591,  2.1345,  ...,  4.2005,  1.0512,  2.3665]],\n  \n           [[-1.9176,  0.2518,  3.2079,  ..., -4.1373,  3.9867, -3.5042],\n            [ 0.2299, -2.9361,  2.2068,  ..., -4.3553,  0.6431, -5.2441],\n            [-0.3267, -1.7243,  0.0146,  ..., -0.7912,  3.4321, -4.7854]],\n  \n           [[ 4.2987, -1.0518, -0.8216,  ...,  0.7472,  1.6102,  2.2465],\n            [ 2.9069,  0.7946, -0.0126,  ..., -1.3637,  1.2375,  2.1842],\n            [ 2.0105,  4.1067, -2.3027,  ..., -1.2921, -1.2556,  0.3803]]]],\n         device='cuda:0', grad_fn=<TransposeBackward0>),\n  tensor([[[[ 0.9107, -1.7248,  0.8401,  ..., -2.5571, -1.8177,  0.7760],\n            [-0.4929, -3.7486,  0.1056,  ...,  0.2143, -1.0731, -0.5320],\n            [-1.8855, -2.8280,  0.8772,  ...,  0.3079, -0.2928, -0.7021],\n            [ 1.1978, -0.5830, -0.1564,  ...,  0.6121, -1.0291, -0.2893]],\n  \n           [[ 1.9275,  1.0091, -1.4142,  ..., -1.1676, -1.3512,  0.9060],\n            [ 1.7316, -2.0299, -1.8814,  ...,  0.6705, -3.7593,  2.4257],\n            [ 3.4156, -1.2721, -2.4620,  ...,  1.7249, -2.2805,  2.2770],\n            [ 2.1856, -1.0672, -0.0804,  ..., -3.1550, -1.8144,  0.8902]],\n  \n           [[-2.6041,  0.0693, -0.0917,  ..., -0.2125,  1.1084, -0.4290],\n            [ 0.1991,  1.1691, -0.6622,  ...,  1.3649,  0.9112,  0.5970],\n            [ 0.1168,  1.1042, -1.0020,  ..., -1.3692,  1.7089,  2.8790],\n            [ 0.4389,  1.9028,  1.2880,  ..., -0.0154,  1.5374, -0.0586]],\n  \n           ...,\n  \n           [[-0.6485,  1.7410, -1.1683,  ..., -1.2385,  0.5286,  2.4345],\n            [-0.2745,  0.8653,  1.2703,  ...,  0.3231,  1.2468,  1.1082],\n            [-0.6005,  1.2441,  1.1426,  ..., -0.5388, -0.0961,  0.0682],\n            [-2.6586, -1.5376,  2.1066,  ...,  1.4451, -1.5322,  0.4798]],\n  \n           [[-3.7253, -0.5215,  0.1507,  ...,  2.7097,  3.4474,  1.7477],\n            [-2.7928, -1.0497, -1.1289,  ...,  1.2515,  0.0925, -0.1761],\n            [-2.9887, -1.8911, -0.2657,  ...,  1.3734,  1.4486, -0.8041],\n            [-1.3222, -0.1039,  2.1009,  ...,  0.5247,  1.2197,  0.5385]],\n  \n           [[-0.7860,  0.9358,  0.2692,  ...,  2.1400, -1.2946,  2.1742],\n            [ 1.8720,  2.3053,  3.2038,  ...,  1.6697,  1.2380, -0.1175],\n            [ 0.5431, -1.5252, -0.0316,  ...,  0.7901,  0.4263,  2.5872],\n            [-1.2079,  0.9901, -1.1814,  ..., -0.8327,  0.6810,  1.5881]]]],\n         device='cuda:0', grad_fn=<TransposeBackward0>),\n  tensor([[[[ 3.1816, -4.8864,  6.4288,  ..., -4.3843, -0.2417,  0.2412],\n            [-2.6501, -2.4003,  1.1801,  ..., -0.2929, -0.0543, -4.0218],\n            [-0.3727,  0.1292,  0.5682,  ..., -0.5316,  2.3480, -3.5805],\n            [ 1.9395,  5.2415, -2.0771,  ..., -2.0245,  2.1866, -4.0826]],\n  \n           [[ 2.4436, -2.0394, -3.9029,  ...,  2.8822,  5.7948,  3.5429],\n            [ 4.6206, -1.3113, -2.2886,  ...,  7.8435, -0.4152, -3.4744],\n            [ 1.2818, -0.4934,  3.6858,  ...,  3.6771, -2.4688, -0.4983],\n            [ 0.0859,  2.3137,  3.3730,  ...,  0.3350, -0.2763, -1.1774]],\n  \n           [[-1.5007,  1.7863, -0.7974,  ..., -3.7305,  0.5699,  3.7830],\n            [-4.4604,  2.5497, -0.1668,  ...,  2.2323,  1.3328,  4.7980],\n            [-3.6981, -0.4494, -2.1061,  ..., -1.2008,  1.0976,  0.9990],\n            [-3.8243, -3.0931, -1.0910,  ...,  3.9779, -0.5668,  3.4856]],\n  \n           ...,\n  \n           [[ 2.0775,  1.3532,  3.7562,  ..., -1.4941, -4.8469,  2.0771],\n            [ 5.9593,  1.3348,  1.0386,  ...,  3.1597, -0.4760,  1.6407],\n            [ 2.9104,  4.5250, -4.1512,  ..., -1.9108, -0.4686,  1.6193],\n            [ 1.3453,  3.5371, -0.4209,  ...,  0.0128, -2.6799,  1.2157]],\n  \n           [[ 5.0822,  2.4461, -2.3727,  ..., -5.8957, -0.6284,  4.4616],\n            [ 0.4825,  1.3344, -9.3416,  ..., -5.4288, -0.5333,  3.3552],\n            [ 0.0716, -3.1216, -0.1905,  ...,  3.0531,  3.9369,  2.1797],\n            [-0.5657, -1.0873,  1.3498,  ..., -0.8859,  3.4139,  0.3445]],\n  \n           [[ 2.9016, -5.8688,  2.6368,  ..., -3.4761, -2.0346, -4.4252],\n            [-4.0629, -4.4005, -1.9692,  ...,  1.8420,  0.0709, -4.9814],\n            [ 0.9966,  2.3679, -1.2749,  ..., -1.2930, -0.8317, -2.5705],\n            [-1.8316, -1.7177,  1.2635,  ..., -2.8779, -0.3082, -0.3989]]]],\n         device='cuda:0', grad_fn=<TransposeBackward0>)),\n (tensor([[[[-0.7163,  2.8784, -2.7653,  ...,  1.1347, -0.4012, -0.3166],\n            [-0.4583,  3.1110, -3.1171,  ...,  1.4581, -0.1323, -0.4099],\n            [-0.8346,  2.4042, -4.5167,  ..., -0.5595, -0.1140,  0.6152]],\n  \n           [[ 0.0591, -1.4559,  1.0262,  ..., -2.8049,  4.8945, -0.4891],\n            [ 1.7709, -2.3960,  0.5573,  ..., -2.3868,  2.6620, -0.0432],\n            [ 1.4220, -1.6526,  0.2531,  ..., -0.1976,  3.2834,  0.9153]],\n  \n           [[ 1.1933,  0.7162, -0.0768,  ..., -2.7315, -0.5266,  0.1348],\n            [ 1.0943,  1.9047, -0.9231,  ..., -1.6551, -0.7790,  0.6943],\n            [ 1.1632,  1.9348, -2.0790,  ..., -0.7126,  0.9205,  0.6689]],\n  \n           ...,\n  \n           [[ 2.7014,  0.7988, -1.9671,  ..., -0.5895, -0.3480, -1.5179],\n            [ 2.7948,  1.6637, -1.2066,  ...,  0.4027, -0.7426, -2.1664],\n            [ 3.3297,  2.5330, -2.1559,  ...,  1.2764, -0.8651, -2.9180]],\n  \n           [[ 0.2062, -0.9453,  2.1070,  ...,  2.3201,  0.3593, -0.3779],\n            [-0.6177, -0.4917,  1.6594,  ...,  1.6771,  0.7294,  0.2815],\n            [-1.2448,  0.5687,  1.4912,  ...,  1.0382,  0.7888,  1.1200]],\n  \n           [[-1.5093,  0.8020,  0.2486,  ..., -2.3139, -1.2258,  0.2704],\n            [-2.3602,  1.2738,  0.3441,  ..., -2.3200, -0.0828,  0.4364],\n            [-1.1893,  1.5387,  1.3304,  ..., -0.3725,  1.0953,  2.3372]]]],\n         device='cuda:0', grad_fn=<TransposeBackward0>),\n  tensor([[[[-2.1916,  0.7350, -1.2715,  ...,  1.1188, -4.9373,  6.3352],\n            [-1.9881,  1.4119, -2.5394,  ...,  1.4887, -5.6680,  6.6745],\n            [-2.5879, -4.0708, -2.9961,  ..., -1.5537, -3.4264,  1.8839]],\n  \n           [[ 0.9771,  0.1524,  1.7549,  ...,  3.4736,  3.4133,  4.2756],\n            [ 2.0954, -1.4043, -0.0368,  ...,  4.2418,  2.7207,  6.4665],\n            [ 1.4647, -1.2976, -0.2233,  ...,  3.1563,  3.6385,  6.5431]],\n  \n           [[ 3.5081, -6.9862, -1.5324,  ...,  1.3523, -1.9307,  0.2605],\n            [ 3.0495, -4.6581, -0.8833,  ...,  3.1559, -1.9585,  2.6354],\n            [-2.4054, -3.7108, -0.8350,  ..., -0.0912, -2.3855,  2.6279]],\n  \n           ...,\n  \n           [[ 0.9034,  0.5019, -0.7762,  ...,  3.3506, -0.7278, -0.8286],\n            [ 1.3269,  0.3729, -0.6137,  ...,  2.4921, -1.8832,  0.5250],\n            [ 1.1217,  0.1231,  0.4585,  ..., -0.7462,  0.2855, -1.0437]],\n  \n           [[-2.3940,  2.8747, -0.4896,  ..., -4.3334,  3.1468,  1.8464],\n            [-1.9276,  0.6149, -0.7974,  ..., -4.3573,  1.5097,  0.4059],\n            [-1.3847, -0.8724,  1.0490,  ..., -0.5893,  1.6688,  2.3210]],\n  \n           [[-1.1321, -0.3781, -2.8957,  ..., -2.2012, -8.4522,  2.9299],\n            [-0.3185,  0.8355, -2.7537,  ..., -1.2472, -5.5662,  0.4327],\n            [ 1.1778,  0.5478, -2.5059,  ..., -3.4154, -3.7538, -0.4994]]]],\n         device='cuda:0', grad_fn=<TransposeBackward0>),\n  tensor([[[[ 2.3820, -4.7454, -0.5668,  ..., -3.8464, -0.6739,  0.6916],\n            [-1.6182, -2.8250, -2.2758,  ..., -2.0522, -1.8891,  1.1757],\n            [ 0.0057, -1.3855, -1.0905,  ..., -2.1061,  0.1996,  3.2356],\n            [ 2.6658, -1.8376,  1.2228,  ..., -2.8993,  0.3286,  4.0864]],\n  \n           [[-1.3614, -1.3767, -3.0190,  ..., -0.2290, -2.2826,  1.2962],\n            [-0.7047, -2.8214,  1.1290,  ...,  2.2985, -1.8171, -4.6136],\n            [ 0.0717, -3.9014,  2.6574,  ...,  2.1770, -3.8803, -0.6042],\n            [ 0.0392, -2.6928,  0.2317,  ...,  2.0532, -3.1875,  1.1458]],\n  \n           [[ 0.4984,  1.5814, -3.0334,  ...,  1.0503, -2.2171, -0.1312],\n            [ 2.1364, -0.5892, -0.4088,  ...,  1.7911,  1.0401,  1.1763],\n            [ 1.9780, -0.0419,  1.4352,  ...,  0.8779,  1.3004,  1.9706],\n            [ 2.3163,  1.1273,  0.9375,  ...,  0.2907, -3.2100,  1.9362]],\n  \n           ...,\n  \n           [[ 0.6621, -0.2077, -4.2339,  ..., -1.4852,  0.5080, -3.9619],\n            [-3.6708, -2.8594, -3.2423,  ..., -0.5106, -2.3421, -0.8498],\n            [-1.0135, -1.2917, -2.0142,  ...,  0.7896, -5.6672,  1.6421],\n            [-2.3594, -0.1706, -1.6057,  ..., -0.3291, -2.0083, -0.4414]],\n  \n           [[-1.5250,  0.8800,  0.7202,  ...,  2.0033,  2.2180,  4.1634],\n            [ 3.4559,  2.4108,  0.8621,  ...,  1.3167,  2.3947,  3.2952],\n            [-1.8375,  2.8145,  1.4070,  ..., -1.3466,  2.2551,  1.5108],\n            [ 1.0336,  2.3290, -0.4315,  ...,  0.4884,  2.9282,  0.2353]],\n  \n           [[-0.6667, -1.3264, -0.5554,  ...,  0.1551,  0.9014,  1.7855],\n            [ 1.1775, -0.5093, -3.4279,  ..., -1.8247, -0.2554,  2.0448],\n            [ 0.7523,  0.5971, -2.9410,  ..., -1.4367,  2.9388,  1.9714],\n            [-1.6783, -0.9924, -0.6550,  ..., -1.5187,  0.7157, -0.6023]]]],\n         device='cuda:0', grad_fn=<TransposeBackward0>),\n  tensor([[[[ 7.9006e-01, -3.4561e+00,  8.0009e+00,  ..., -5.8483e+00,\n             -8.5147e+00,  1.5997e+00],\n            [ 5.7776e+00, -4.0107e-01,  5.8173e+00,  ..., -2.9868e+00,\n             -3.8096e+00,  3.7790e+00],\n            [ 2.3784e+00, -1.0843e+00, -4.0370e-01,  ..., -1.4884e+00,\n             -2.3638e+00,  8.0968e-01],\n            [-3.9002e-01,  4.9480e+00, -1.9909e+00,  ...,  3.4901e-01,\n             -1.0781e-02, -1.2881e+00]],\n  \n           [[ 7.2037e+00,  1.5061e+00,  3.4510e+00,  ...,  3.0663e+00,\n             -1.4247e+00,  8.0649e-01],\n            [ 1.2747e+00,  5.3508e+00, -1.8247e+00,  ...,  2.2985e+00,\n             -4.9318e+00, -2.6781e+00],\n            [-2.1390e+00,  4.7758e-01, -1.7403e+00,  ...,  5.9781e-02,\n             -4.3416e+00, -1.0326e+00],\n            [ 1.3428e-01,  2.3108e+00, -1.1895e+00,  ...,  1.0365e+00,\n             -1.0692e+00, -5.1592e-01]],\n  \n           [[ 1.9787e+00,  1.7983e+00,  2.7923e+00,  ..., -2.1668e+00,\n             -6.8725e+00, -3.9065e+00],\n            [-1.5558e+00, -6.1819e+00,  3.5193e+00,  ..., -4.5160e-01,\n             -1.1596e+01,  2.4899e+00],\n            [-5.4480e-01, -1.0469e+00,  8.0085e+00,  ...,  8.0221e-01,\n              1.4023e+00, -9.5168e-01],\n            [-4.0408e+00,  3.3775e+00,  3.0289e+00,  ..., -2.7633e+00,\n             -7.0754e+00,  2.7439e+00]],\n  \n           ...,\n  \n           [[-7.2579e+00,  2.0507e+00,  6.9439e+00,  ...,  3.1066e+00,\n              6.5159e+00, -6.0971e-01],\n            [-4.4019e+00,  1.3739e+00,  5.7017e+00,  ...,  4.6631e+00,\n              4.0130e+00, -3.6686e+00],\n            [-4.7309e+00,  2.5924e+00,  9.4074e+00,  ...,  4.9802e-01,\n              2.2990e-01, -1.7268e+00],\n            [-6.3285e-01,  4.5794e+00,  5.8827e+00,  ..., -1.0596e+00,\n              3.7840e+00, -6.2172e-01]],\n  \n           [[-1.0061e+01,  9.1871e+00, -6.5390e+00,  ..., -1.0987e+01,\n              5.0187e+00,  3.7747e+00],\n            [-9.8048e+00,  1.5491e+00, -2.5271e+00,  ..., -1.7344e+00,\n              8.4191e-01, -1.8477e+00],\n            [-1.7328e+00,  2.0785e+00, -1.4781e-01,  ...,  3.1381e+00,\n              6.8230e-02,  5.2620e+00],\n            [-1.3214e+00,  1.0180e+00, -1.6560e+00,  ...,  1.5061e+00,\n              1.3802e+00, -1.5835e+00]],\n  \n           [[-9.1479e-01, -4.9352e+00,  4.5143e-01,  ..., -6.4140e-01,\n              8.1073e-01,  3.4696e-01],\n            [ 4.2861e+00,  3.6410e+00,  2.3558e+00,  ..., -1.9029e+00,\n              2.0793e+00, -2.4897e-01],\n            [-1.7459e+00,  1.4316e+00,  4.7652e+00,  ...,  5.9106e+00,\n              6.1030e+00,  1.9167e+00],\n            [-1.0654e+00, -1.1342e+00,  2.9652e+00,  ..., -1.5812e+00,\n              1.1995e-01,  1.5314e+00]]]], device='cuda:0',\n         grad_fn=<TransposeBackward0>)),\n (tensor([[[[-0.0906, -1.9741,  2.5600,  ..., -0.9763,  0.4701, -2.6325],\n            [-0.0708, -0.5256,  1.9499,  ..., -1.0015, -0.2858, -0.9906],\n            [-0.4313, -0.2523,  3.1705,  ..., -0.3349,  0.4314, -2.0267]],\n  \n           [[ 2.9624,  1.8541,  0.8036,  ...,  3.4430,  0.2106, -4.4715],\n            [ 2.7358,  3.0992, -0.6118,  ...,  2.6035,  0.9791, -2.8768],\n            [ 3.5253,  3.0582,  0.7191,  ...,  1.1813,  1.1814, -2.4838]],\n  \n           [[ 2.0179, -0.5638, -0.0330,  ...,  1.0294,  2.0350, -1.5718],\n            [ 1.7001,  1.0498,  2.4319,  ...,  1.6383,  2.6448, -0.8633],\n            [ 1.2854,  0.5618,  1.5180,  ...,  3.1632,  2.7383, -0.6272]],\n  \n           ...,\n  \n           [[ 5.0824, -1.6849,  1.9731,  ..., -0.8225, -2.5140,  3.4519],\n            [ 4.6169, -2.4689,  1.7755,  ...,  0.0595, -2.4688,  3.3615],\n            [ 2.8711, -1.5660,  2.8001,  ..., -2.3721, -3.4066,  2.7458]],\n  \n           [[ 1.2821,  0.4437, -1.1171,  ..., -0.0118,  4.3178,  2.5974],\n            [ 1.1006, -0.5830, -0.4458,  ..., -0.5152,  3.0557,  0.8678],\n            [ 0.9289,  2.4004,  0.4164,  ..., -1.8548,  2.6273,  1.7098]],\n  \n           [[ 1.1641,  3.0205, -2.3291,  ...,  0.4367, -2.8640,  3.0005],\n            [ 0.6392,  1.5381, -2.1643,  ...,  0.3751, -2.6017,  2.5334],\n            [-0.9613,  1.5574, -1.9016,  ..., -1.1929, -4.5700,  2.0952]]]],\n         device='cuda:0', grad_fn=<TransposeBackward0>),\n  tensor([[[[-2.3788,  0.9005, -2.8370,  ..., -3.6072,  3.2281,  6.6300],\n            [-2.5774,  1.8885, -0.9162,  ..., -3.5866,  5.1991,  6.7833],\n            [-3.0111,  1.5607, -0.6723,  ..., -1.3002,  5.9908,  3.0376]],\n  \n           [[-5.0697, -1.6130, -4.5540,  ...,  0.9186,  3.2565,  0.7737],\n            [-3.9387, -1.8894, -5.0809,  ...,  3.8433,  2.6232,  2.0273],\n            [-5.2847, -0.8816, -3.5825,  ...,  2.8785,  1.0876,  1.1462]],\n  \n           [[ 4.0810,  2.0067,  0.8249,  ..., -0.7371,  3.4490,  1.7210],\n            [ 3.1127,  3.7317, -1.0714,  ..., -0.8302,  3.8826,  4.6940],\n            [ 3.2049,  0.4150,  0.0532,  ..., -1.3829, -1.4387,  4.6948]],\n  \n           ...,\n  \n           [[ 1.4029,  7.7991,  3.3561,  ..., 12.6891, -1.1466, -1.0144],\n            [ 2.7889,  6.9503,  3.0959,  ...,  6.4049, -1.9454, -3.0788],\n            [ 5.8329,  5.9133,  4.1158,  ...,  3.7832,  1.0418, -0.9591]],\n  \n           [[-4.0786, -5.2033, -4.7540,  ...,  1.2680, -1.0054, -1.9917],\n            [-1.1285, -3.2424, -1.5293,  ...,  1.8913, -2.9191, -0.1631],\n            [ 1.6098, -3.4238, -0.2350,  ...,  1.0072, -0.1474,  0.6443]],\n  \n           [[ 3.0183,  3.4594, -2.5016,  ...,  3.4450,  3.7831, -1.2288],\n            [-2.7388,  1.5485, -2.0933,  ...,  5.2029,  4.3413, -2.9280],\n            [-1.6111,  5.5093, -4.1707,  ...,  2.2144,  1.3347, -2.9166]]]],\n         device='cuda:0', grad_fn=<TransposeBackward0>),\n  tensor([[[[ 9.4429e-01,  1.4043e+00,  3.3283e-01,  ...,  8.4606e-01,\n              2.3285e-01,  5.2879e-01],\n            [ 1.4601e-01,  1.5746e-01,  1.3417e-01,  ...,  2.2535e+00,\n             -8.9705e-01, -1.7441e-01],\n            [-1.4269e+00, -1.7537e+00, -3.6367e-01,  ...,  1.8764e+00,\n              2.0233e-01, -1.6706e+00],\n            [-8.2120e-01, -1.3220e+00, -5.1294e-01,  ...,  4.4890e-01,\n             -1.0498e+00,  1.6235e+00]],\n  \n           [[-7.8928e-01, -1.5432e+00,  9.7626e-01,  ...,  2.4258e-01,\n              1.9852e+00,  7.1361e-02],\n            [-6.1283e-01, -3.1032e+00, -7.9135e-01,  ..., -3.1877e+00,\n              1.2366e+00,  1.3009e+00],\n            [ 4.5953e-01, -3.7276e+00,  7.0925e-02,  ..., -1.9810e+00,\n              2.6981e+00, -1.2112e+00],\n            [ 4.7788e-02, -2.5271e+00, -1.2707e+00,  ...,  3.3102e-01,\n              6.9641e-01,  1.2772e+00]],\n  \n           [[ 1.3560e+00, -2.5984e+00, -2.5962e-01,  ..., -2.1743e+00,\n             -7.8924e-01,  1.0649e+00],\n            [-3.6824e-01, -1.5375e+00,  2.0153e+00,  ..., -1.1884e+00,\n              2.5091e+00, -2.2940e+00],\n            [ 1.8782e+00, -1.3397e+00, -4.3014e-01,  ...,  2.7569e+00,\n              1.8722e+00, -2.6457e+00],\n            [ 5.6586e-01, -2.4849e+00,  2.0236e+00,  ..., -1.7702e-01,\n              9.8091e-01, -6.4205e-01]],\n  \n           ...,\n  \n           [[-3.1137e+00, -6.1718e-01,  2.3998e+00,  ..., -1.0095e+00,\n              1.2988e-01,  3.7178e-01],\n            [ 4.4496e-01,  2.1823e+00, -6.2751e-01,  ...,  6.4725e-01,\n             -1.6894e-01, -9.0473e-01],\n            [ 1.6547e+00,  2.2698e+00, -1.1952e+00,  ...,  1.0146e+00,\n             -1.3476e+00, -9.7311e-01],\n            [ 1.3010e+00, -2.2591e-01,  6.5075e-01,  ..., -3.3016e+00,\n             -1.6057e+00, -3.7172e-03]],\n  \n           [[ 3.6379e-01,  5.2282e-01,  3.9077e-01,  ...,  4.3857e-01,\n             -1.4758e+00, -2.8099e+00],\n            [ 1.3174e+00, -5.1160e-01, -3.8369e+00,  ..., -4.6772e+00,\n              9.7496e-01, -4.8799e+00],\n            [-6.4194e-01,  3.6208e-02, -3.9546e+00,  ..., -6.3557e-01,\n              1.0265e+00, -4.5176e+00],\n            [ 2.0628e+00, -7.5243e-01,  2.5382e-01,  ..., -6.6033e-01,\n              2.7966e+00, -1.4512e+00]],\n  \n           [[-1.8950e+00,  9.6496e-01,  3.9784e-01,  ..., -1.9830e+00,\n             -1.4248e-01, -2.2939e-01],\n            [ 3.0694e-01,  1.7092e+00, -1.4777e+00,  ...,  1.4754e+00,\n             -1.1262e+00,  2.2773e-01],\n            [ 5.0012e-01,  1.3841e+00, -2.4222e+00,  ...,  2.2037e+00,\n             -1.9817e+00, -1.6323e-01],\n            [ 2.6741e-02,  8.4706e-01,  1.6237e-01,  ...,  1.4073e+00,\n              2.2449e-01,  2.5195e-01]]]], device='cuda:0',\n         grad_fn=<TransposeBackward0>),\n  tensor([[[[ 4.5963, -0.3278,  1.1463,  ..., -3.0171, -8.5700, -4.1038],\n            [-6.9453,  4.3780, -1.6484,  ...,  6.3529, -4.4819,  5.7920],\n            [ 1.2194,  3.8470, -2.8987,  ..., -0.1702, -3.9569,  3.3495],\n            [ 0.9501,  3.7596,  2.7060,  ...,  2.3507, -2.2009,  1.0965]],\n  \n           [[ 1.1763, -3.2789,  5.3937,  ...,  2.8982, -8.3268,  0.4043],\n            [-2.1751,  1.5270, -2.6904,  ..., -4.9731, -0.5596,  1.6661],\n            [-2.7984,  7.5215,  1.7800,  ..., -5.0061,  5.8303, -0.6362],\n            [-0.6813, -2.3437,  3.7774,  ..., -0.1583, -1.7529,  3.6890]],\n  \n           [[ 6.3863,  3.6095, -9.2501,  ..., -5.0483,  0.1562,  3.9203],\n            [-1.0995,  3.2434,  0.8908,  ..., -5.0695, -3.8194, -6.8877],\n            [ 4.5289,  5.4694, -3.2087,  ...,  8.4804,  0.4867,  0.7442],\n            [ 1.1323,  6.5855, -2.9533,  ...,  3.9479, -0.4810, -3.4769]],\n  \n           ...,\n  \n           [[-9.7314, -6.4608,  3.5360,  ..., -0.7509, -3.6474,  6.7832],\n            [-2.1905, -1.7529, -2.9458,  ..., -2.4281, -5.3339,  7.1493],\n            [ 0.9888, -0.2993, -1.4086,  ...,  3.8149,  1.6008,  4.0375],\n            [ 1.1658, -8.5379,  2.3707,  ..., -2.0678, -1.6100,  0.4307]],\n  \n           [[ 5.9716,  2.1252, -1.9850,  ..., -7.3891, -7.2913, 10.7064],\n            [-2.8263,  1.8397, -0.8228,  ..., -6.9686,  8.6363,  0.5202],\n            [ 0.9769,  3.9588,  3.5625,  ..., -3.8400,  0.8934,  5.2456],\n            [ 2.2491,  1.5833,  0.0900,  ..., -0.0281,  0.8262,  1.4806]],\n  \n           [[ 1.5987,  7.2946, 17.6657,  ..., -4.7001, -2.8895, -6.7054],\n            [ 2.3570,  6.1815, -1.9272,  ..., -5.2869, -2.8594, -1.6893],\n            [ 1.3086, -3.2602, -0.6926,  ..., -1.2896, -0.7923,  2.9235],\n            [-1.4661,  0.1048, -1.5816,  ...,  4.1206,  4.7691, -0.2683]]]],\n         device='cuda:0', grad_fn=<TransposeBackward0>)))"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_dec_pytorch.past_key_values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}